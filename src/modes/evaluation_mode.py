# src/modes/evaluation_mode.py
"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡å®Ÿé¨“ãƒ¢ãƒ¼ãƒ‰
è¢«é¨“è€…ã«ã‚ˆã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿç”¨æ€§èƒ½ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰
"""

import os
import cv2
import numpy as np
import torch
import time
import json
from collections import deque
from typing import List, Tuple, Optional, Dict
from datetime import datetime

# æ—¢å­˜ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from src.core.camera import Camera
from src.core.hand_tracker import HandTracker
from src.input.keyboard_map import KeyboardMap
from src.input.keyboard_tracker import KeyboardTracker
from src.processing.coordinate_transformer import WorkAreaTransformer
from src.processing.models.hand_lstm import BasicHandLSTM
from src.processing.feature_extractor import FeatureExtractor


class EvaluationMode:
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡å®Ÿé¨“ç”¨ãƒ¢ãƒ¼ãƒ‰
    è¢«é¨“è€…ã«å®Ÿéš›ã«ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ã£ã¦ã‚‚ã‚‰ã„ã€ç²¾åº¦ã‚’æ¸¬å®š
    """
    
    def __init__(self, model_path: str, keyboard_map_path: str = 'keyboard_map.json'):
        """
        åˆæœŸåŒ–
        - prediction_mode.py ã¨åŒã˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½¿ç”¨
        - è©•ä¾¡ãƒ­ã‚°ã‚’è¨˜éŒ²ã™ã‚‹æ©Ÿèƒ½ã‚’è¿½åŠ 
        """
        self.model_path = model_path
        self.keyboard_map_path = keyboard_map_path
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
        self.camera = None
        self.hand_tracker = None
        self.keyboard_tracker = None
        self.keyboard_map = None
        self.transformer = None
        self.model = None
        
        # äºˆæ¸¬ç”¨ã®ãƒãƒƒãƒ•ã‚¡ï¼ˆå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã¨çµ±ä¸€ï¼‰
        self.trajectory_buffer = deque(maxlen=60)  # 60ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã®è»Œè·¡ãƒ‡ãƒ¼ã‚¿
        
        # äºˆæ¸¬çµæœ
        self.current_prediction = None
        
        # ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ—ï¼ˆå­¦ç¿’æ™‚ã«ä¿å­˜ã—ãŸã‚‚ã®ã‚’ä½¿ç”¨ï¼‰
        self.KEY_CHARS = None
        self.label_map_loaded = False
        
        # ç‰¹å¾´é‡æŠ½å‡ºå™¨ï¼ˆå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã¨çµ±ä¸€ï¼‰
        self.feature_extractor = FeatureExtractor(sequence_length=60, fps=30.0)
        
        # è©•ä¾¡ãƒ­ã‚°
        self.evaluation_log = []
        self.current_task = None
        self.current_inputs = []
        self.start_time = None
        self.last_input_time = None
        
        print(f"ğŸ¯ è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰åˆæœŸåŒ–å®Œäº†")
        print(f"   ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {model_path}")
        print(f"   ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—: {keyboard_map_path}")
    
    def initialize_components(self) -> bool:
        """ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–"""
        try:
            print("ğŸ”§ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–ä¸­...")
            
            # ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–
            self.camera = Camera()
            if not self.camera.is_opened():
                print("âŒ ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            # ç”»é¢ã‚µã‚¤ã‚ºã‚’è¨­å®š
            frame = self.camera.read_frame()
            if frame is None:
                print("âŒ ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            height, width = frame.shape[:2]
            print(f"âœ… ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–å®Œäº†: {width}x{height}")
            
            # æ‰‹è¿½è·¡ã®åˆæœŸåŒ–
            self.hand_tracker = HandTracker()
            print("âœ… æ‰‹è¿½è·¡åˆæœŸåŒ–å®Œäº†")
            
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã®åˆæœŸåŒ–
            self.keyboard_tracker = KeyboardTracker()
            self.keyboard_tracker.start()
            print("âœ… ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒˆãƒ©ãƒƒã‚«ãƒ¼åˆæœŸåŒ–å®Œäº†")
            
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®åˆæœŸåŒ–
            self.keyboard_map = KeyboardMap(self.keyboard_map_path)
            
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã®ç¢ºèª
            if not self.keyboard_map.key_positions:
                print("âš ï¸ ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ãŒæœªè¨­å®šã§ã™")
                print("   ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...")
                if not self.keyboard_map.start_calibration(existing_camera=self.camera):
                    print("âŒ ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return False
            else:
                print("âœ… ä¿å­˜æ¸ˆã¿ã®ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰è¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™")
            
            # åº§æ¨™å¤‰æ›å™¨ã®åˆæœŸåŒ–
            self.transformer = WorkAreaTransformer(self.keyboard_map_path)
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‹ã‚‰ä½œæ¥­é ˜åŸŸã®4éš…ã‚’å–å¾—
            keyboard_corners = self.keyboard_map.get_work_area_corners()
            if keyboard_corners is not None:
                self.transformer.set_work_area_corners(keyboard_corners)
            print("âœ… åº§æ¨™å¤‰æ›å™¨åˆæœŸåŒ–å®Œäº†")
            
            # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
            if not self.load_model():
                print("âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            print("âœ… ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def load_model(self) -> bool:
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        try:
            print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            
            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿
            checkpoint = torch.load(self.model_path, map_location='cpu')
            
            # ãƒ¢ãƒ‡ãƒ«è¨­å®šã®å–å¾—
            model_config = checkpoint.get('model_config', {})
            input_size = model_config.get('input_size', 18)
            hidden_size = model_config.get('hidden_size', 128)
            num_classes = model_config.get('num_classes', 37)
            
            # ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ—ã®èª­ã¿è¾¼ã¿ï¼ˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ or JSONï¼‰
            self.KEY_CHARS = checkpoint.get('label_map')
            if self.KEY_CHARS is None:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®label_map.json
                label_map_path = os.path.join(os.path.dirname(self.model_path), 'label_map.json')
                if os.path.exists(label_map_path):
                    with open(label_map_path, 'r', encoding='utf-8') as f:
                        self.KEY_CHARS = json.load(f).get('labels')
            if self.KEY_CHARS is None:
                # æœ€å¾Œã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆå¾“æ¥å®šç¾©ï¼‰
                self.KEY_CHARS = (
                    'a','b','c','d','e','f','g','h','i','j','k','l','m',
                    'n','o','p','q','r','s','t','u','v','w','x','y','z',
                    '0','1','2','3','4','5','6','7','8','9',' '
                )
            else:
                self.label_map_loaded = True

            # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
            self.model = BasicHandLSTM(
                input_size=input_size,
                hidden_size=hidden_size,
                num_classes=num_classes
            )
            
            # é‡ã¿ã®èª­ã¿è¾¼ã¿
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            
            # ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            self.model = self.model.to(self.device)
            
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
            print(f"   å…¥åŠ›ã‚µã‚¤ã‚º: {input_size}")
            print(f"   éš ã‚Œå±¤ã‚µã‚¤ã‚º: {hidden_size}")
            print(f"   ã‚¯ãƒ©ã‚¹æ•°: {num_classes}")
            print(f"   ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def process_frame(self, frame: np.ndarray) -> Optional[Dict]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã—ã¦è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        try:
            # æ‰‹è¿½è·¡
            results = self.hand_tracker.detect_hands(frame)
            if not results.multi_hand_landmarks:
                return None
            
            # æœ€åˆã®æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’å–å¾—
            hand_landmarks = results.multi_hand_landmarks[0]
            
            # äººå·®ã—æŒ‡ã®åº§æ¨™ã‚’å–å¾—
            index_finger = hand_landmarks.landmark[8]  # äººå·®ã—æŒ‡å…ˆç«¯
            
            # ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ã‚’ä½œæ¥­é ˜åŸŸç©ºé–“ã«å¤‰æ›
            wa_coords = self.transformer.pixel_to_work_area(
                index_finger.x, index_finger.y
            )
            
            if wa_coords is None:
                return None
            
            wa_x, wa_y = wa_coords
            
            # æœ€è¿‘å‚3ã‚­ãƒ¼ã¸ã®ç›¸å¯¾åº§æ¨™ã‚’å–å¾—
            nearest_keys = self.transformer.get_nearest_keys_with_relative_coords(
                wa_x, wa_y, top_k=3
            )
            
            # è»Œè·¡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ§‹ç¯‰ï¼ˆå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã¨çµ±ä¸€ï¼‰
            frame_data = {
                'work_area_coords': {
                    'index_finger': {'x': wa_x, 'y': wa_y}
                },
                'nearest_keys_relative': [
                    {
                        'key': k.key,
                        'relative_x': k.relative_x,
                        'relative_y': k.relative_y,
                        'distance': np.sqrt(k.relative_x**2 + k.relative_y**2)
                    } for k in nearest_keys[:3]
                ]
            }
            
            return frame_data
            
        except Exception as e:
            print(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def predict_intent(self) -> Optional[List[Tuple[str, float]]]:
        """å…¥åŠ›æ„å›³ã‚’äºˆæ¸¬"""
        try:
            if len(self.trajectory_buffer) < 60:
                return None
            
            # è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’ç‰¹å¾´é‡ã«å¤‰æ›ï¼ˆå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã¨çµ±ä¸€ï¼‰
            trajectory_data = list(self.trajectory_buffer)
            features_np = self.feature_extractor.extract_from_trajectory(trajectory_data)
            
            # ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
            features_tensor = torch.FloatTensor(features_np).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(features_tensor)
                probabilities = torch.softmax(outputs, dim=1)
            
            # Top-3ã®äºˆæ¸¬çµæœã‚’å–å¾—
            top3_probs, top3_indices = torch.topk(probabilities, 3, dim=1)
            
            predictions = []
            for i in range(3):
                key = self.KEY_CHARS[top3_indices[0][i].item()]
                confidence = top3_probs[0][i].item() * 100
                predictions.append((key, confidence))
            
            return predictions
            
        except Exception as e:
            print(f"âš ï¸ äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def run_evaluation_session(self, participant_id: str, target_texts: List[str]):
        """
        è©•ä¾¡ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ
        
        Args:
            participant_id: è¢«é¨“è€…IDï¼ˆä¾‹: "P001", "P002"ï¼‰
            target_texts: å…¥åŠ›ã—ã¦ã‚‚ã‚‰ã†ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
                ä¾‹: ["hello world", "the quick brown fox jumps over the lazy dog"]
        """
        print(f"ğŸš€ è©•ä¾¡ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹")
        print(f"   è¢«é¨“è€…ID: {participant_id}")
        print(f"   ã‚¿ã‚¹ã‚¯æ•°: {len(target_texts)}")
        print("\næ“ä½œæ–¹æ³•:")
        print("   - æ‰‹ã‚’ã‚«ãƒ¡ãƒ©ã«æ˜ ã—ã¦ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã®æ„å›³ã‚’äºˆæ¸¬")
        print("   - ç”»é¢ã«è¡¨ç¤ºã•ã‚ŒãŸæ–‡å­—ã‚’ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã§å…¥åŠ›")
        print("   - ESC: ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†")
        
        try:
            # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
            if not self.initialize_components():
                print("âŒ åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            # å„ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ
            for task_idx, target_text in enumerate(target_texts):
                print(f"\nğŸ“ ã‚¿ã‚¹ã‚¯ {task_idx + 1}/{len(target_texts)}")
                print(f"   ç›®æ¨™ãƒ†ã‚­ã‚¹ãƒˆ: \"{target_text}\"")
                print("   æº–å‚™ãŒã§ããŸã‚‰ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„...")
                
                # ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼å¾…æ©Ÿ
                while True:
                    frame = self.camera.read_frame()
                    if frame is None:
                        continue
                    
                    self.draw_waiting_screen(frame, task_idx + 1, len(target_texts), target_text)
                    cv2.imshow('Evaluation Mode', frame)
                    
                    key = cv2.waitKey(1) & 0xFF
                    if key == 27:  # ESC
                        return False
                    elif key == 32:  # ã‚¹ãƒšãƒ¼ã‚¹
                        break
                
                # ã‚¿ã‚¹ã‚¯é–‹å§‹
                success = self.run_single_task(task_idx, target_text)
                if not success:
                    print("âš ï¸ ã‚¿ã‚¹ã‚¯ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
                    return False
            
            # è©•ä¾¡å®Œäº†
            print("\nâœ… å…¨ã¦ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸ")
            self.show_summary()
            self.save_results(participant_id)
            
            return True
            
        except KeyboardInterrupt:
            print("\nâš ï¸ è©•ä¾¡ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
            return False
        finally:
            self.cleanup()
    
    def run_single_task(self, task_idx: int, target_text: str) -> bool:
        """å˜ä¸€ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œ"""
        self.current_task = {
            'task_idx': task_idx,
            'target_text': target_text,
            'inputs': []
        }
        self.current_inputs = []
        
        # æ–‡å­—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        char_idx = 0
        self.start_time = time.time()
        self.last_input_time = self.start_time
        
        try:
            while char_idx < len(target_text):
                target_char = target_text[char_idx]
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
                frame = self.camera.read_frame()
                if frame is None:
                    continue
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
                frame_data = self.process_frame(frame)
                if frame_data is not None:
                    self.trajectory_buffer.append(frame_data)
                
                # äºˆæ¸¬å®Ÿè¡Œ
                if len(self.trajectory_buffer) >= 60:
                    predictions = self.predict_intent()
                    if predictions:
                        self.current_prediction = predictions
                
                # ã‚­ãƒ¼å…¥åŠ›ãƒã‚§ãƒƒã‚¯
                actual_input = self.keyboard_tracker.get_key_event()
                if actual_input is not None:
                    # å…¥åŠ›æ™‚é–“ã®è¨ˆç®—
                    current_time = time.time()
                    input_time = current_time - self.last_input_time
                    self.last_input_time = current_time
                    
                    # æ­£è§£/ä¸æ­£è§£ã®åˆ¤å®š
                    is_correct = (actual_input.lower() == target_char.lower())
                    
                    # äºˆæ¸¬çµæœã®è¨˜éŒ²
                    predicted_top3 = []
                    predicted_probs = []
                    if self.current_prediction:
                        for key, prob in self.current_prediction[:3]:
                            predicted_top3.append(key)
                            predicted_probs.append(prob)
                    
                    # å…¥åŠ›ãƒ­ã‚°ã‚’è¨˜éŒ²
                    input_log = {
                        'target_char': target_char,
                        'predicted_top3': predicted_top3,
                        'predicted_probs': predicted_probs,
                        'actual_input': actual_input,
                        'is_correct': is_correct,
                        'input_time': input_time,
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    self.current_inputs.append(input_log)
                    print(f"   {target_char} -> {actual_input} ({'âœ“' if is_correct else 'âœ—'}) [{input_time:.2f}s]")
                    
                    char_idx += 1
                
                # ç”»é¢æç”»
                self.draw_task_screen(frame, target_text, char_idx, len(target_text))
                cv2.imshow('Evaluation Mode', frame)
                
                # ESCã‚­ãƒ¼ã§çµ‚äº†
                key = cv2.waitKey(1) & 0xFF
                if key == 27:  # ESC
                    return False
            
            # ã‚¿ã‚¹ã‚¯å®Œäº†
            self.current_task['inputs'] = self.current_inputs
            self.evaluation_log.append(self.current_task)
            
            return True
            
        except Exception as e:
            print(f"âŒ ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def draw_waiting_screen(self, frame: np.ndarray, task_num: int, total_tasks: int, target_text: str):
        """å¾…æ©Ÿç”»é¢ã®æç”»"""
        h, w = frame.shape[:2]
        
        # èƒŒæ™¯
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (w, h), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        cv2.putText(frame, "EVALUATION MODE", (w//2 - 150, 100), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
        
        # ã‚¿ã‚¹ã‚¯æƒ…å ±
        cv2.putText(frame, f"Task {task_num}/{total_tasks}", (w//2 - 80, 150), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        # ç›®æ¨™ãƒ†ã‚­ã‚¹ãƒˆ
        cv2.putText(frame, "Target Text:", (w//2 - 100, 200), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(frame, f'"{target_text}"', (w//2 - len(target_text)*8, 230), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # æŒ‡ç¤º
        cv2.putText(frame, "Press SPACE to start", (w//2 - 120, 300), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        cv2.putText(frame, "Press ESC to exit", (w//2 - 100, 330), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    def draw_task_screen(self, frame: np.ndarray, target_text: str, current_char: int, total_chars: int):
        """ã‚¿ã‚¹ã‚¯å®Ÿè¡Œç”»é¢ã®æç”»"""
        # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®æç”»
        if self.keyboard_map:
            self.keyboard_map.visualize(frame)
        
        # æ‰‹è¿½è·¡ã®æç”»
        if self.hand_tracker:
            results = self.hand_tracker.detect_hands(frame)
            if results.multi_hand_landmarks:
                self.hand_tracker.draw_landmarks(frame, results)
        
        h, w = frame.shape[:2]
        
        # æƒ…å ±ãƒ‘ãƒãƒ«
        panel_width = 400
        panel_height = 200
        x1 = w - panel_width - 20
        y1 = 20
        x2 = w - 20
        y2 = y1 + panel_height
        
        # èƒŒæ™¯
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), -1)
        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 2)
        
        # ç›®æ¨™ãƒ†ã‚­ã‚¹ãƒˆ
        cv2.putText(frame, f"Target: \"{target_text}\"", (x1 + 10, y1 + 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        # ç¾åœ¨ã®æ–‡å­—
        if current_char < len(target_text):
            target_char = target_text[current_char]
            cv2.putText(frame, f"Next: '{target_char}' ({current_char + 1}/{total_chars})", 
                       (x1 + 10, y1 + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        else:
            cv2.putText(frame, "Task Complete!", (x1 + 10, y1 + 50), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        # é€²æ—ãƒãƒ¼
        progress = current_char / total_chars
        bar_width = panel_width - 20
        bar_height = 10
        bar_x = x1 + 10
        bar_y = y1 + 70
        
        cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), (100, 100, 100), -1)
        cv2.rectangle(frame, (bar_x, bar_y), (bar_x + int(bar_width * progress), bar_y + bar_height), (0, 255, 0), -1)
        
        # é€²æ—ãƒ†ã‚­ã‚¹ãƒˆ
        cv2.putText(frame, f"Progress: {progress*100:.0f}%", (x1 + 10, y1 + 100), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # äºˆæ¸¬çµæœ
        if self.current_prediction:
            cv2.putText(frame, "Predictions:", (x1 + 10, y1 + 125), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            for i, (key, prob) in enumerate(self.current_prediction[:3]):
                color = (0, 255, 0) if i == 0 else (255, 255, 0) if i == 1 else (0, 255, 255)
                cv2.putText(frame, f"{i+1}. {key} ({prob:.1f}%)", (x1 + 10, y1 + 145 + i*15), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        else:
            cv2.putText(frame, "Loading predictions...", (x1 + 10, y1 + 125), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
    
    def calculate_metrics(self) -> Dict:
        """
        è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
        
        Returns:
            {
                'top1_accuracy': float,      # Top-1æ­£è§£ç‡
                'top3_accuracy': float,      # Top-3æ­£è§£ç‡
                'avg_input_time': float,     # å¹³å‡å…¥åŠ›æ™‚é–“ï¼ˆç§’/æ–‡å­—ï¼‰
                'wpm': float,                # Words Per Minute
                'error_rate': float,         # ã‚¨ãƒ©ãƒ¼ç‡
                'total_inputs': int,         # ç·å…¥åŠ›æ•°
                'correct_inputs': int        # æ­£è§£æ•°
            }
        """
        if not self.evaluation_log:
            return {
                'top1_accuracy': 0.0,
                'top3_accuracy': 0.0,
                'avg_input_time': 0.0,
                'wpm': 0.0,
                'error_rate': 100.0,
                'total_inputs': 0,
                'correct_inputs': 0
            }
        
        total_inputs = 0
        correct_inputs = 0
        top3_correct = 0
        total_input_time = 0.0
        
        for task in self.evaluation_log:
            for input_log in task['inputs']:
                total_inputs += 1
                total_input_time += input_log['input_time']
                
                if input_log['is_correct']:
                    correct_inputs += 1
                
                # Top-3æ­£è§£ç‡ã®è¨ˆç®—
                if input_log['predicted_top3'] and len(input_log['predicted_top3']) > 0:
                    target_char = input_log['target_char'].lower()
                    if target_char in [pred.lower() for pred in input_log['predicted_top3']]:
                        top3_correct += 1
        
        # æŒ‡æ¨™ã®è¨ˆç®—
        top1_accuracy = (correct_inputs / total_inputs * 100) if total_inputs > 0 else 0.0
        top3_accuracy = (top3_correct / total_inputs * 100) if total_inputs > 0 else 0.0
        avg_input_time = (total_input_time / total_inputs) if total_inputs > 0 else 0.0
        
        # WPMã®è¨ˆç®—ï¼ˆè‹±èªã§ã¯å¹³å‡5æ–‡å­— = 1å˜èªã¨ã—ã¦è¨ˆç®—ï¼‰
        wpm = (60 / avg_input_time / 5) if avg_input_time > 0 else 0.0
        
        error_rate = 100.0 - top1_accuracy
        
        return {
            'top1_accuracy': round(top1_accuracy, 2),
            'top3_accuracy': round(top3_accuracy, 2),
            'avg_input_time': round(avg_input_time, 2),
            'wpm': round(wpm, 2),
            'error_rate': round(error_rate, 2),
            'total_inputs': total_inputs,
            'correct_inputs': correct_inputs
        }
    
    def save_results(self, participant_id: str):
        """
        çµæœã‚’JSONå½¢å¼ã§ä¿å­˜
        
        ä¿å­˜å…ˆ: evaluation_results/{participant_id}/evaluation_YYYYMMDD_HHMMSS.json
        """
        try:
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
            results_dir = f"evaluation_results/{participant_id}"
            os.makedirs(results_dir, exist_ok=True)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"evaluation_{timestamp}.json"
            filepath = os.path.join(results_dir, filename)
            
            # è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—
            metrics = self.calculate_metrics()
            
            # çµæœãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰
            results = {
                'participant_id': participant_id,
                'timestamp': datetime.now().isoformat(),
                'model_path': self.model_path,
                'evaluation_log': self.evaluation_log,
                'metrics': metrics
            }
            
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ’¾ è©•ä¾¡çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
            
        except Exception as e:
            print(f"âŒ çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def show_summary(self):
        """
        è©•ä¾¡çµæœã®ã‚µãƒãƒªãƒ¼ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤º
        """
        metrics = self.calculate_metrics()
        
        print("\n" + "="*60)
        print("ğŸ“Š è©•ä¾¡çµæœã‚µãƒãƒªãƒ¼")
        print("="*60)
        print(f"Top-1ç²¾åº¦:     {metrics['top1_accuracy']:.1f}%")
        print(f"Top-3ç²¾åº¦:     {metrics['top3_accuracy']:.1f}%")
        print(f"å¹³å‡å…¥åŠ›æ™‚é–“:   {metrics['avg_input_time']:.2f}ç§’/æ–‡å­—")
        print(f"WPM:          {metrics['wpm']:.1f}")
        print(f"ã‚¨ãƒ©ãƒ¼ç‡:      {metrics['error_rate']:.1f}%")
        print(f"ç·å…¥åŠ›æ•°:      {metrics['total_inputs']}")
        print(f"æ­£è§£æ•°:        {metrics['correct_inputs']}")
        print("="*60)
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.camera:
            self.camera.release()
        
        if self.keyboard_tracker:
            self.keyboard_tracker.stop()
        
        cv2.destroyAllWindows()
        print("ğŸ§¹ ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")


def run_evaluation_mode(model_path: str, participant_id: str, target_texts: List[str], 
                       keyboard_map_path: str = 'keyboard_map.json'):
    """è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ"""
    # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(model_path):
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_path}")
        print("å­¦ç¿’ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return False
    
    # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã®ä½œæˆã¨å®Ÿè¡Œ
    evaluation_mode = EvaluationMode(model_path, keyboard_map_path)
    
    # è©•ä¾¡ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ
    success = evaluation_mode.run_evaluation_session(participant_id, target_texts)
    
    return success


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description='ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰')
    parser.add_argument('--model', type=str, required=True,
                        help='ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ï¼ˆ.pthãƒ•ã‚¡ã‚¤ãƒ«ï¼‰')
    parser.add_argument('--participant', type=str, required=True,
                        help='è¢«é¨“è€…IDï¼ˆä¾‹: P001ï¼‰')
    parser.add_argument('--texts', type=str, nargs='+', required=True,
                        help='å…¥åŠ›ã—ã¦ã‚‚ã‚‰ã†ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ')
    parser.add_argument('--map', type=str, default='keyboard_map.json',
                        help='ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—JSONã®ãƒ‘ã‚¹ (default: keyboard_map.json)')
    
    args = parser.parse_args()
    
    # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã®å®Ÿè¡Œ
    success = run_evaluation_mode(
        model_path=args.model,
        participant_id=args.participant,
        target_texts=args.texts,
        keyboard_map_path=args.map
    )
    
    if success:
        print("âœ… è©•ä¾¡ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
    else:
        print("âŒ è©•ä¾¡ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")

# src/modes/prediction_mode.py
"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰
å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦å…¥åŠ›æ„å›³ã‚’äºˆæ¸¬
"""

import os
import cv2
import numpy as np
import torch
import time
from collections import deque
from typing import List, Tuple, Optional, Dict
import json

# æ—¢å­˜ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.core.camera import Camera
from src.core.hand_tracker import HandTracker
from src.input.keyboard_map import KeyboardMap
from src.processing.coordinate_transformer import CoordinateTransformer
from src.processing.models.hand_lstm import BasicHandLSTM


class PredictionMode:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model_path: str, keyboard_map_path: str = 'keyboard_map.json'):
        """
        äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã®åˆæœŸåŒ–
        
        Args:
            model_path: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
            keyboard_map_path: ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®ãƒ‘ã‚¹
        """
        self.model_path = model_path
        self.keyboard_map_path = keyboard_map_path
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
        self.camera = None
        self.hand_tracker = None
        self.keyboard_map = None
        self.coordinate_transformer = None
        self.model = None
        
        # äºˆæ¸¬ç”¨ã®ãƒãƒƒãƒ•ã‚¡
        self.frame_buffer = deque(maxlen=60)  # 60ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã®ç‰¹å¾´é‡
        self.trajectory_buffer = deque(maxlen=30)  # 30ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã®è»Œè·¡
        
        # äºˆæ¸¬çµæœ
        self.current_prediction = None
        self.prediction_history = []
        
        # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ç”¨
        self.evaluation_mode = False
        self.test_text = "hello world"
        self.current_char_index = 0
        self.correct_predictions = 0
        self.total_predictions = 0
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        self.show_debug = False
        self.frame_count = 0
        self.fps = 0
        self.last_fps_time = time.time()
        
        # 37ã‚­ãƒ¼ã®å®šç¾©
        self.KEY_CHARS = (
            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',
            'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',
            '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '
        )
        
        print(f"ğŸ¯ äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰åˆæœŸåŒ–å®Œäº†")
        print(f"   ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {model_path}")
        print(f"   ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—: {keyboard_map_path}")
    
    def initialize_components(self) -> bool:
        """ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–"""
        try:
            print("ğŸ”§ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–ä¸­...")
            
            # ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–
            self.camera = Camera()
            if not self.camera.is_opened():
                print("âŒ ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            # ç”»é¢ã‚µã‚¤ã‚ºã‚’è¨­å®š
            frame = self.camera.read_frame()
            if frame is None:
                print("âŒ ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            height, width = frame.shape[:2]
            print(f"âœ… ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–å®Œäº†: {width}x{height}")
            
            # æ‰‹è¿½è·¡ã®åˆæœŸåŒ–
            self.hand_tracker = HandTracker()
            print("âœ… æ‰‹è¿½è·¡åˆæœŸåŒ–å®Œäº†")
            
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®åˆæœŸåŒ–
            self.keyboard_map = KeyboardMap()
            if not self.keyboard_map.key_positions:
                print("âš ï¸ ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                print("   ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...")
                if not self.keyboard_map.start_calibration():
                    print("âŒ ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return False
            
            # åº§æ¨™å¤‰æ›å™¨ã®åˆæœŸåŒ–
            self.coordinate_transformer = CoordinateTransformer(self.keyboard_map_path)
            self.coordinate_transformer.set_screen_size(width, height)
            self.coordinate_transformer.set_keyboard_corners(
                self.keyboard_map.get_keyboard_corners()
            )
            print("âœ… åº§æ¨™å¤‰æ›å™¨åˆæœŸåŒ–å®Œäº†")
            
            # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
            if not self.load_model():
                print("âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            print("âœ… ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def load_model(self) -> bool:
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        try:
            print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            
            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿
            checkpoint = torch.load(self.model_path, map_location='cpu')
            
            # ãƒ¢ãƒ‡ãƒ«è¨­å®šã®å–å¾—
            model_config = checkpoint.get('model_config', {})
            input_size = model_config.get('input_size', 15)
            hidden_size = model_config.get('hidden_size', 128)
            num_classes = model_config.get('num_classes', 37)
            
            # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
            self.model = BasicHandLSTM(
                input_size=input_size,
                hidden_size=hidden_size,
                num_classes=num_classes
            )
            
            # é‡ã¿ã®èª­ã¿è¾¼ã¿
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            
            # ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            self.model = self.model.to(self.device)
            
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
            print(f"   å…¥åŠ›ã‚µã‚¤ã‚º: {input_size}")
            print(f"   éš ã‚Œå±¤ã‚µã‚¤ã‚º: {hidden_size}")
            print(f"   ã‚¯ãƒ©ã‚¹æ•°: {num_classes}")
            print(f"   ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def extract_features(self, hand_landmarks) -> Optional[np.ndarray]:
        """æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º"""
        try:
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ç©ºé–“ã§ã®æŒ‡ã®åº§æ¨™ã‚’å–å¾—
            index_finger = hand_landmarks.landmark[8]  # äººå·®ã—æŒ‡å…ˆç«¯
            
            # ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ã‚’ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ç©ºé–“ã«å¤‰æ›
            kb_coords = self.coordinate_transformer.pixel_to_keyboard_space(
                index_finger.x, index_finger.y
            )
            
            if kb_coords is None:
                return None
            
            kb_x, kb_y = kb_coords
            
            # æœ€è¿‘å‚3ã‚­ãƒ¼ã¸ã®ç›¸å¯¾åº§æ¨™ã‚’å–å¾—
            nearest_keys = self.coordinate_transformer.get_nearest_keys_with_relative_coords(
                kb_x, kb_y, top_k=3
            )
            
            # ç‰¹å¾´é‡ã®æ§‹ç¯‰ï¼ˆ15æ¬¡å…ƒï¼‰
            features = np.zeros(15)
            
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ç©ºé–“ã§ã®æŒ‡ã®åº§æ¨™ï¼ˆ2æ¬¡å…ƒï¼‰
            features[0] = kb_x
            features[1] = kb_y
            
            # æœ€è¿‘å‚3ã‚­ãƒ¼ã¸ã®ç›¸å¯¾åº§æ¨™ï¼ˆ6æ¬¡å…ƒï¼‰
            for i, key_info in enumerate(nearest_keys[:3]):
                if i < 3:
                    features[2 + i*2] = key_info.relative_x
                    features[2 + i*2 + 1] = key_info.relative_y
            
            # æœ€è¿‘å‚3ã‚­ãƒ¼ã¸ã®è·é›¢ï¼ˆ3æ¬¡å…ƒï¼‰
            for i, key_info in enumerate(nearest_keys[:3]):
                if i < 3:
                    features[8 + i] = key_info.distance
            
            # é€Ÿåº¦ãƒ»åŠ é€Ÿåº¦ï¼ˆ4æ¬¡å…ƒï¼‰- å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã®å·®åˆ†ã‹ã‚‰è¨ˆç®—
            if len(self.frame_buffer) > 0:
                prev_features = self.frame_buffer[-1]
                if prev_features is not None:
                    # é€Ÿåº¦ï¼ˆX, Yæ–¹å‘ï¼‰
                    features[11] = (kb_x - prev_features[0]) * 30  # 30fps
                    features[12] = (kb_y - prev_features[1]) * 30
                    
                    # åŠ é€Ÿåº¦ï¼ˆX, Yæ–¹å‘ï¼‰
                    if len(self.frame_buffer) > 1:
                        prev_prev_features = self.frame_buffer[-2]
                        if prev_prev_features is not None:
                            features[13] = (prev_features[0] - 2*kb_x + prev_prev_features[0]) * 30**2
                            features[14] = (prev_features[1] - 2*kb_y + prev_prev_features[1]) * 30**2
            
            # ç‰¹å¾´é‡ã®æ­£è¦åŒ–
            features = self.normalize_features(features)
            
            return features
            
        except Exception as e:
            print(f"âš ï¸ ç‰¹å¾´é‡æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def normalize_features(self, features: np.ndarray) -> np.ndarray:
        """ç‰¹å¾´é‡ã®æ­£è¦åŒ–"""
        # åº§æ¨™ç³»ã®æ­£è¦åŒ–ï¼ˆ0-1ã®ç¯„å›²ã«åã‚ã‚‹ï¼‰
        features[:2] = np.clip(features[:2], 0.0, 1.0)
        
        # ç›¸å¯¾åº§æ¨™ã®æ­£è¦åŒ–ï¼ˆ-5ã‹ã‚‰5ã®ç¯„å›²ã«åã‚ã‚‹ï¼‰
        features[2:8] = np.clip(features[2:8], -5.0, 5.0)
        
        # è·é›¢ã®æ­£è¦åŒ–ï¼ˆ0ã‹ã‚‰10ã®ç¯„å›²ã«åã‚ã‚‹ï¼‰
        features[8:11] = np.clip(features[8:11], 0.0, 10.0)
        
        # é€Ÿåº¦ãƒ»åŠ é€Ÿåº¦ã®æ­£è¦åŒ–ï¼ˆ-2ã‹ã‚‰2ã®ç¯„å›²ã«åã‚ã‚‹ï¼‰
        features[11:] = np.clip(features[11:], -2.0, 2.0)
        
        return features
    
    def predict_intent(self) -> Optional[List[Tuple[str, float]]]:
        """å…¥åŠ›æ„å›³ã‚’äºˆæ¸¬"""
        try:
            if len(self.frame_buffer) < 60:
                return None
            
            # ç‰¹å¾´é‡ã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
            features = np.array(list(self.frame_buffer))
            features_tensor = torch.FloatTensor(features).unsqueeze(0).to(self.device)
            
            # æ¨è«–æ™‚é–“ã®è¨ˆæ¸¬
            start_time = time.time()
            
            with torch.no_grad():
                outputs = self.model(features_tensor)
                probabilities = torch.softmax(outputs, dim=1)
            
            inference_time = time.time() - start_time
            
            # Top-3ã®äºˆæ¸¬çµæœã‚’å–å¾—
            top3_probs, top3_indices = torch.topk(probabilities, 3, dim=1)
            
            predictions = []
            for i in range(3):
                key = self.KEY_CHARS[top3_indices[0][i].item()]
                confidence = top3_probs[0][i].item() * 100
                predictions.append((key, confidence))
            
            # æ¨è«–æ™‚é–“ã‚’è¨˜éŒ²
            self.inference_time = inference_time
            
            return predictions
            
        except Exception as e:
            print(f"âš ï¸ äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def run_prediction_mode(self):
        """äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã®å®Ÿè¡Œ"""
        print("ğŸš€ äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™")
        print("   æ“ä½œèª¬æ˜:")
        print("   - D: ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º/éè¡¨ç¤º")
        print("   - E: è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆ")
        print("   - R: è©•ä¾¡ã®ãƒªã‚»ãƒƒãƒˆ")
        print("   - ESC: çµ‚äº†")
        
        try:
            while True:
                # ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
                frame = self.camera.read_frame()
                if frame is None:
                    print("âŒ ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    break
                
                # æ‰‹ã®æ¤œå‡º
                results = self.hand_tracker.detect_hands(frame)
                self.last_results = results  # çµæœã‚’ä¿å­˜
                
                if results.multi_hand_landmarks:
                    hand_landmarks = results.multi_hand_landmarks[0]
                    
                    # ç‰¹å¾´é‡ã®æŠ½å‡º
                    features = self.extract_features(hand_landmarks)
                    
                    if features is not None:
                        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                        self.frame_buffer.append(features)
                        
                        # è»Œè·¡ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                        index_finger = hand_landmarks.landmark[8]
                        self.trajectory_buffer.append((index_finger.x, index_finger.y))
                        
                        # 60ãƒ•ãƒ¬ãƒ¼ãƒ æºœã¾ã£ãŸã‚‰äºˆæ¸¬å®Ÿè¡Œ
                        if len(self.frame_buffer) == 60:
                            predictions = self.predict_intent()
                            if predictions:
                                self.current_prediction = predictions
                                self.prediction_history.append(predictions)
                
                # ç”»é¢è¡¨ç¤ºã®æ›´æ–°
                frame = self.update_display(frame)
                
                # ç”»é¢ã«è¡¨ç¤º
                cv2.imshow('Intent Prediction Mode', frame)
                
                # ã‚­ãƒ¼å…¥åŠ›ã®å‡¦ç†
                key = cv2.waitKey(1) & 0xFF
                if key == 27:  # ESC
                    break
                elif key == ord('d') or key == ord('D'):  # Dã‚­ãƒ¼ã§ãƒ‡ãƒãƒƒã‚°æƒ…å ±ãƒˆã‚°ãƒ«
                    self.show_debug = not self.show_debug
                    print(f"ãƒ‡ãƒãƒƒã‚°æƒ…å ±: {'è¡¨ç¤º' if self.show_debug else 'éè¡¨ç¤º'}")
                elif key == ord('e') or key == ord('E'):  # Eã‚­ãƒ¼ã§è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ
                    self.evaluation_mode = not self.evaluation_mode
                    print(f"è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if self.evaluation_mode else 'ç„¡åŠ¹'}")
                elif key == ord('r') or key == ord('R'):  # Rã‚­ãƒ¼ã§è©•ä¾¡ãƒªã‚»ãƒƒãƒˆ
                    self.reset_evaluation()
                    print("è©•ä¾¡ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
                
                # FPSã®è¨ˆç®—
                self.frame_count += 1
                if time.time() - self.last_fps_time >= 1.0:
                    self.fps = self.frame_count
                    self.frame_count = 0
                    self.last_fps_time = time.time()
        
        except KeyboardInterrupt:
            print("\nâš ï¸ äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        except Exception as e:
            print(f"\nâŒ äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            self.cleanup()
    
    def update_display(self, frame: np.ndarray) -> np.ndarray:
        """ç”»é¢è¡¨ç¤ºã®æ›´æ–°"""
        h, w = frame.shape[:2]
        
        # æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æç”»
        if hasattr(self, 'hand_tracker') and hasattr(self, 'last_results'):
            frame = self.hand_tracker.draw_landmarks(frame, self.last_results)
        
        # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’å¯è¦–åŒ–
        if self.keyboard_map:
            frame = self.keyboard_map.visualize(frame)
        
        # äºˆæ¸¬çµæœã®è¡¨ç¤º
        if self.current_prediction:
            self.draw_predictions(frame, self.current_prediction)
        
        # æ‰‹ã®è»Œè·¡ã‚’æç”»
        self.draw_trajectory(frame)
        
        # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã®è¡¨ç¤º
        if self.evaluation_mode:
            self.draw_evaluation_info(frame)
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
        if self.show_debug:
            self.draw_debug_info(frame)
        
        # æ“ä½œèª¬æ˜ã®è¡¨ç¤º
        instruction_text = "D: ãƒ‡ãƒãƒƒã‚° | E: è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ | R: ãƒªã‚»ãƒƒãƒˆ | ESC: çµ‚äº†"
        cv2.putText(frame, instruction_text, (20, h - 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        
        return frame
    
    def draw_predictions(self, frame: np.ndarray, predictions: List[Tuple[str, float]]):
        """äºˆæ¸¬çµæœã®æç”»"""
        h, w = frame.shape[:2]
        
        # äºˆæ¸¬çµæœã®èƒŒæ™¯
        cv2.rectangle(frame, (w - 300, 20), (w - 20, 140), (0, 0, 0), -1)
        cv2.rectangle(frame, (w - 300, 20), (w - 20, 140), (255, 255, 255), 2)
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        cv2.putText(frame, "Prediction Results", (w - 280, 45), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # Top-3ã®äºˆæ¸¬çµæœ
        for i, (key, confidence) in enumerate(predictions):
            y_pos = 70 + i * 25
            color = (0, 255, 0) if i == 0 else (255, 255, 0) if i == 1 else (0, 255, 255)
            
            # ã‚­ãƒ¼ã¨ç¢ºä¿¡åº¦
            text = f"{key}: {confidence:.1f}%"
            cv2.putText(frame, text, (w - 280, y_pos), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            
            # ç¢ºä¿¡åº¦ãƒãƒ¼
            bar_width = int((confidence / 100.0) * 200)
            cv2.rectangle(frame, (w - 280, y_pos + 5), (w - 280 + bar_width, y_pos + 15), color, -1)
            cv2.rectangle(frame, (w - 280, y_pos + 5), (w - 80, y_pos + 15), (255, 255, 255), 1)
        
        # æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„ã‚­ãƒ¼ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        if predictions:
            best_key = predictions[0][0]
            if self.keyboard_map and best_key in self.keyboard_map.key_positions:
                key_info = self.keyboard_map.key_positions[best_key]
                center_x = int(key_info['center_x'])
                center_y = int(key_info['center_y'])
                
                # ã‚­ãƒ¼ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
                cv2.circle(frame, (center_x, center_y), 30, (0, 255, 0), 3)
                cv2.putText(frame, best_key, (center_x - 10, center_y + 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
    
    def draw_trajectory(self, frame: np.ndarray):
        """æ‰‹ã®è»Œè·¡ã®æç”»"""
        if len(self.trajectory_buffer) < 2:
            return
        
        # éå»30ãƒ•ãƒ¬ãƒ¼ãƒ ã®è»Œè·¡ã‚’æç”»
        for i in range(len(self.trajectory_buffer) - 1):
            x1, y1 = self.trajectory_buffer[i]
            x2, y2 = self.trajectory_buffer[i + 1]
            
            # åº§æ¨™ã‚’ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ã«å¤‰æ›
            px1 = int(x1 * frame.shape[1])
            py1 = int(y1 * frame.shape[0])
            px2 = int(x2 * frame.shape[1])
            py2 = int(y2 * frame.shape[0])
            
            # è»Œè·¡ã®è‰²ï¼ˆæ™‚é–“ã«å¿œã˜ã¦å¤‰åŒ–ï¼‰
            alpha = i / len(self.trajectory_buffer)
            color = (int(255 * alpha), int(255 * (1 - alpha)), 255)
            
            cv2.line(frame, (px1, py1), (px2, py2), color, 2)
    
    def draw_evaluation_info(self, frame: np.ndarray):
        """è©•ä¾¡æƒ…å ±ã®æç”»"""
        h, w = frame.shape[:2]
        
        # è©•ä¾¡æƒ…å ±ã®èƒŒæ™¯
        cv2.rectangle(frame, (20, 20), (400, 120), (0, 0, 0), -1)
        cv2.rectangle(frame, (20, 20), (400, 120), (255, 255, 255), 2)
        
        # ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
        cv2.putText(frame, f"Test: {self.test_text}", (30, 45), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # ç¾åœ¨ã®æ–‡å­—ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        if self.current_char_index < len(self.test_text):
            current_char = self.test_text[self.current_char_index]
            cv2.putText(frame, f"Current: '{current_char}'", (30, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        # ç²¾åº¦
        if self.total_predictions > 0:
            accuracy = (self.correct_predictions / self.total_predictions) * 100
            cv2.putText(frame, f"Accuracy: {accuracy:.1f}%", (30, 95), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # äºˆæ¸¬ãŒæ­£è§£ã‹ãƒã‚§ãƒƒã‚¯
        if self.current_prediction and self.evaluation_mode:
            predicted_key = self.current_prediction[0][0]
            if self.current_char_index < len(self.test_text):
                target_char = self.test_text[self.current_char_index]
                if predicted_key.lower() == target_char.lower():
                    self.correct_predictions += 1
                self.total_predictions += 1
    
    def draw_debug_info(self, frame: np.ndarray):
        """ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®æç”»"""
        h, w = frame.shape[:2]
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®èƒŒæ™¯
        cv2.rectangle(frame, (20, h - 200), (400, h - 20), (0, 0, 0), -1)
        cv2.rectangle(frame, (20, h - 200), (400, h - 20), (255, 255, 255), 2)
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        cv2.putText(frame, "Debug Info", (30, h - 180), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ
        cv2.putText(frame, f"FPS: {self.fps}", (30, h - 155), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        
        # ãƒãƒƒãƒ•ã‚¡ã®å……å¡«çŠ¶æ…‹
        buffer_fill = (len(self.frame_buffer) / 60) * 100
        cv2.putText(frame, f"Buffer: {buffer_fill:.1f}%", (30, h - 130), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        
        # æ¨è«–æ™‚é–“
        if hasattr(self, 'inference_time'):
            cv2.putText(frame, f"Inference: {self.inference_time*1000:.1f}ms", (30, h - 105), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        
        # ç‰¹å¾´é‡ã®å€¤ï¼ˆæœ€åˆã®5æ¬¡å…ƒã®ã¿è¡¨ç¤ºï¼‰
        if len(self.frame_buffer) > 0:
            latest_features = self.frame_buffer[-1]
            if latest_features is not None:
                cv2.putText(frame, f"Features[0-4]: {latest_features[:5][:3]}", (30, h - 80), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
    
    def reset_evaluation(self):
        """è©•ä¾¡ã®ãƒªã‚»ãƒƒãƒˆ"""
        self.current_char_index = 0
        self.correct_predictions = 0
        self.total_predictions = 0
        self.prediction_history = []
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.camera:
            self.camera.release()
        
        cv2.destroyAllWindows()
        print("ğŸ§¹ ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")


def run_prediction_mode(model_path: str, keyboard_map_path: str = 'keyboard_map.json'):
    """äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ"""
    # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(model_path):
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_path}")
        print("å­¦ç¿’ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return False
    
    # äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã®ä½œæˆã¨å®Ÿè¡Œ
    prediction_mode = PredictionMode(model_path, keyboard_map_path)
    
    if not prediction_mode.initialize_components():
        print("âŒ åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False
    
    # äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã®å®Ÿè¡Œ
    prediction_mode.run_prediction_mode()
    
    return True


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨
    model_path = "models/intent_model_latest/best_model.pth"
    
    if os.path.exists(model_path):
        run_prediction_mode(model_path)
    else:
        print(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_path}")
        print("å­¦ç¿’ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")

# src/modes/prediction_mode.py
"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰
å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦å…¥åŠ›æ„å›³ã‚’äºˆæ¸¬
"""

import os
import cv2
import numpy as np
import torch
import time
from collections import deque
from typing import List, Tuple, Optional, Dict
import json

# æ—¢å­˜ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from src.core.camera import Camera
from src.core.hand_tracker import HandTracker
from src.input.keyboard_map import KeyboardMap
from src.processing.coordinate_transformer import WorkAreaTransformer
from src.processing.models.hand_models import HandLSTM
from src.processing.models.hand_models import create_model
from src.processing.feature_extractor import FeatureExtractor


class PredictionMode:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model_path: str, keyboard_map_path: str = 'keyboard_map.json'):
        """
        äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã®åˆæœŸåŒ–
        
        Args:
            model_path: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
            keyboard_map_path: ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®ãƒ‘ã‚¹
        """
        self.model_path = model_path
        self.keyboard_map_path = keyboard_map_path
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
        self.camera = None
        self.hand_tracker = None
        self.keyboard_map = None
        self.transformer = None
        self.model = None
        
        # äºˆæ¸¬ç”¨ã®ãƒãƒƒãƒ•ã‚¡ï¼ˆå¯å¤‰é•·å¯¾å¿œï¼šæœ€å¤§90ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
        self.trajectory_buffer = deque(maxlen=90)  # 90ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã®è»Œè·¡ãƒ‡ãƒ¼ã‚¿
        
        # äºˆæ¸¬çµæœ
        self.current_prediction = None
        self.prediction_history = []
        
        # å…¥åŠ›è©•ä¾¡è¡¨ç¤ºç”¨ï¼ˆActual vs Predictï¼‰
        self.last_actual_key = None
        self.last_predicted_topk = None  # [(key, prob%), ...] ã‚’ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜
        
        # ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ—ï¼ˆå­¦ç¿’æ™‚ã«ä¿å­˜ã—ãŸã‚‚ã®ã‚’ä½¿ç”¨ï¼‰
        self.KEY_CHARS = None
        self.label_map_loaded = False
        
        # ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆload_modelã§è¨­å®šã•ã‚Œã‚‹ï¼‰
        self.min_frames = 60  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼ˆå›ºå®šé•·ãƒ¢ãƒ‡ãƒ«ç”¨ï¼‰
        self.use_variable_length = False
        
        # ç‰¹å¾´é‡æŠ½å‡ºå™¨ï¼ˆå¯å¤‰é•·å¯¾å¿œï¼šsequence_lengthã¯æœ€å¤§å€¤ï¼‰
        self.feature_extractor = FeatureExtractor(sequence_length=90, fps=30.0)
        
        print(f"ğŸ¯ äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰åˆæœŸåŒ–å®Œäº†")
        print(f"   ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {model_path}")
        print(f"   ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—: {keyboard_map_path}")
    
    def initialize_components(self) -> bool:
        """ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–"""
        try:
            print("ğŸ”§ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–ä¸­...")
            
            # ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–
            self.camera = Camera()
            if not self.camera.is_opened():
                print("âŒ ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            # ç”»é¢ã‚µã‚¤ã‚ºã‚’è¨­å®š
            frame = self.camera.read_frame()
            if frame is None:
                print("âŒ ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            height, width = frame.shape[:2]
            print(f"âœ… ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–å®Œäº†: {width}x{height}")
            
            # æ‰‹è¿½è·¡ã®åˆæœŸåŒ–
            self.hand_tracker = HandTracker()
            print("âœ… æ‰‹è¿½è·¡åˆæœŸåŒ–å®Œäº†")
            
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®åˆæœŸåŒ–
            self.keyboard_map = KeyboardMap(self.keyboard_map_path)
            
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã®ç¢ºèª
            if not self.keyboard_map.key_positions:
                print("âš ï¸ ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ãŒæœªè¨­å®šã§ã™")
                print("   ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...")
                if not self.keyboard_map.start_calibration(existing_camera=self.camera):
                    print("âŒ ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return False
            else:
                print("\nğŸ“ ä¿å­˜æ¸ˆã¿ã®ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« (keyboard_map.json) ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
                print("\n1: ä¿å­˜ã—ãŸè¨­å®šã‚’å†åˆ©ç”¨ã™ã‚‹")
                print("2: æ–°ã—ãã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚„ã‚Šç›´ã™")
                
                while True:
                    try:
                        choice = input("\nã©ã¡ã‚‰ã«ã—ã¾ã™ã‹ï¼Ÿ (1/2): ").strip()
                        
                        if choice == "1":
                            print("âœ… ä¿å­˜ã—ãŸè¨­å®šã‚’å†åˆ©ç”¨ã—ã¾ã™ã€‚")
                            break
                        elif choice == "2":
                            print("ğŸ”„ æ–°ã—ã„ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...")
                            if not self.keyboard_map.start_calibration(existing_camera=self.camera):
                                print("âŒ ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ")
                                return False
                            break
                        else:
                            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™ã€‚1 ã¾ãŸã¯ 2 ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                            
                    except KeyboardInterrupt:
                        print("\nâŒ ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                        return False
                    except EOFError:
                        print("\nâŒ ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                        return False
            
            # åº§æ¨™å¤‰æ›å™¨ã®åˆæœŸåŒ–
            self.transformer = WorkAreaTransformer(self.keyboard_map_path)
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‹ã‚‰ä½œæ¥­é ˜åŸŸã®4éš…ã‚’å–å¾—
            keyboard_corners = self.keyboard_map.get_work_area_corners()
            if keyboard_corners is not None:
                self.transformer.set_work_area_corners(keyboard_corners)
            print("âœ… åº§æ¨™å¤‰æ›å™¨åˆæœŸåŒ–å®Œäº†")
            
            # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
            if not self.load_model():
                print("âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            print("âœ… ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def load_model(self) -> bool:
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        try:
            print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            
            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿
            checkpoint = torch.load(self.model_path, map_location='cpu')
            
            # ãƒ¢ãƒ‡ãƒ«è¨­å®šã®å–å¾—
            model_config = checkpoint.get('model_config', {})
            from config.feature_config import get_feature_dim
            input_size = model_config.get('input_size', get_feature_dim())
            hidden_size = model_config.get('hidden_size', 128)
            num_classes = model_config.get('num_classes', 37)
            
            # ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ—ã®èª­ã¿è¾¼ã¿ï¼ˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ or JSONï¼‰
            self.KEY_CHARS = checkpoint.get('label_map')
            if self.KEY_CHARS is None:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®label_map.json
                label_map_path = os.path.join(os.path.dirname(self.model_path), 'label_map.json')
                if os.path.exists(label_map_path):
                    with open(label_map_path, 'r', encoding='utf-8') as f:
                        self.KEY_CHARS = json.load(f).get('labels')
            if self.KEY_CHARS is None:
                # æœ€å¾Œã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆå¾“æ¥å®šç¾©ï¼‰
                self.KEY_CHARS = (
                    'a','b','c','d','e','f','g','h','i','j','k','l','m',
                    'n','o','p','q','r','s','t','u','v','w','x','y','z',
                    '0','1','2','3','4','5','6','7','8','9',' '
                )
            else:
                self.label_map_loaded = True

            # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯lstmï¼‰
            model_type = model_config.get('model_type', 'lstm')
            self.use_variable_length = model_config.get('use_variable_length', False)
            
            # æœ€ä½ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã®è¨­å®š
            if self.use_variable_length:
                self.min_frames = 5  # å¯å¤‰é•·ãƒ¢ãƒ‡ãƒ«ï¼šæœ€ä½5ãƒ•ãƒ¬ãƒ¼ãƒ 
            else:
                self.min_frames = 60  # å›ºå®šé•·ãƒ¢ãƒ‡ãƒ«ï¼š60ãƒ•ãƒ¬ãƒ¼ãƒ å¿…é ˆ
            
            print(f"   ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {model_type.upper()}")
            print(f"   å¯å¤‰é•·å¯¾å¿œ: {'æœ‰åŠ¹' if self.use_variable_length else 'ç„¡åŠ¹'}")
            print(f"   æœ€ä½ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {self.min_frames}")
            
            # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆmodel_typeã«å¿œã˜ã¦ï¼‰
            if model_type in ['cnn', 'gru', 'lstm', 'tcn']:
                # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«æ§‹é€ 
                model_params = {
                    'model_type': model_type,
                    'input_size': input_size,
                    'num_classes': num_classes
                }
                
                # GRU/LSTMã®ã¿hidden_sizeãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                if model_type in ['gru', 'lstm']:
                    model_params['hidden_size'] = hidden_size
                
                self.model = create_model(**model_params)
            else:
                # å¤ã„ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—åã®å ´åˆã€LSTMã¨ã—ã¦æ‰±ã†
                self.model = HandLSTM(
                    input_size=input_size,
                    hidden_size=hidden_size,
                    num_classes=num_classes
                )
            
            # é‡ã¿ã®èª­ã¿è¾¼ã¿
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            
            # ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            self.model = self.model.to(self.device)
            
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
            print(f"   å…¥åŠ›ã‚µã‚¤ã‚º: {input_size}")
            print(f"   éš ã‚Œå±¤ã‚µã‚¤ã‚º: {hidden_size}")
            print(f"   ã‚¯ãƒ©ã‚¹æ•°: {num_classes}")
            print(f"   ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def process_frame(self, frame: np.ndarray) -> Optional[Dict]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã—ã¦è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        try:
            # æ‰‹è¿½è·¡
            results = self.hand_tracker.detect_hands(frame)
            if not results.multi_hand_landmarks:
                return None
            
            # æœ€åˆã®æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’å–å¾—
            hand_landmarks = results.multi_hand_landmarks[0]
            
            # äººå·®ã—æŒ‡ã®åº§æ¨™ã‚’å–å¾—
            index_finger = hand_landmarks.landmark[8]  # äººå·®ã—æŒ‡å…ˆç«¯
            
            # ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ã‚’ä½œæ¥­é ˜åŸŸç©ºé–“ã«å¤‰æ›
            wa_coords = self.transformer.pixel_to_work_area(
                index_finger.x, index_finger.y
            )
            
            if wa_coords is None:
                return None
            
            wa_x, wa_y = wa_coords
            
            # æœ€è¿‘å‚3ã‚­ãƒ¼ã¸ã®ç›¸å¯¾åº§æ¨™ã‚’å–å¾—
            nearest_keys = self.transformer.get_nearest_keys_with_relative_coords(
                wa_x, wa_y, top_k=3
            )
            
            # è»Œè·¡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ§‹ç¯‰ï¼ˆå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã¨çµ±ä¸€ï¼‰
            frame_data = {
                'work_area_coords': {
                    'index_finger': {'x': wa_x, 'y': wa_y}
                },
                'nearest_keys_relative': [
                    {
                        'key': k.key,
                        'relative_x': k.relative_x,
                        'relative_y': k.relative_y,
                        'distance': np.sqrt(k.relative_x**2 + k.relative_y**2)
                    } for k in nearest_keys[:3]
                ]
            }
            
            return frame_data
            
        except Exception as e:
            print(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def predict_intent(self) -> Optional[List[Tuple[str, float]]]:
        """å…¥åŠ›æ„å›³ã‚’äºˆæ¸¬"""
        try:
            # æœ€ä½ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ¢ãƒ‡ãƒ«ã®ç¨®é¡ã«å¿œã˜ã¦å‹•çš„ã«å¤‰æ›´ï¼‰
            if len(self.trajectory_buffer) < self.min_frames:
                return None
            
            # è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’ç‰¹å¾´é‡ã«å¤‰æ›ï¼ˆå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã¨çµ±ä¸€ï¼‰
            trajectory_data = list(self.trajectory_buffer)
            
            # å¯å¤‰é•·ãƒ¢ãƒ¼ãƒ‰ã‹å›ºå®šé•·ãƒ¢ãƒ¼ãƒ‰ã‹ã§ç‰¹å¾´é‡æŠ½å‡ºæ–¹æ³•ã‚’åˆ†å²
            if self.use_variable_length:
                # å¯å¤‰é•·ãƒ¢ãƒ¼ãƒ‰: å®Ÿéš›ã®é•·ã•ã§ç‰¹å¾´é‡ã‚’æŠ½å‡º
                features_np = self.feature_extractor.extract_from_trajectory_variable_length(trajectory_data)
                actual_length = len(trajectory_data)
            else:
                # å›ºå®šé•·ãƒ¢ãƒ¼ãƒ‰: å›ºå®šé•·ã§ç‰¹å¾´é‡ã‚’æŠ½å‡º
                features_np = self.feature_extractor.extract_from_trajectory(trajectory_data)
                actual_length = features_np.shape[0]  # å›ºå®šé•·ï¼ˆsequence_lengthï¼‰
            
            # ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
            features_tensor = torch.FloatTensor(features_np).unsqueeze(0).to(self.device)
            
            # å®Ÿéš›ã®ç³»åˆ—é•·ã‚’å–å¾—ï¼ˆå¯å¤‰é•·å¯¾å¿œï¼šãƒãƒƒãƒ•ã‚¡ã‹ã‚‰ï¼‰
            lengths = torch.tensor([actual_length]).to(self.device) if self.use_variable_length else None
            
            # æ¨è«–æ™‚é–“ã®è¨ˆæ¸¬
            start_time = time.time()
            
            with torch.no_grad():
                # å¯å¤‰é•·ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯lengthsã‚’æ¸¡ã™ã€å›ºå®šé•·ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯None
                outputs = self.model(features_tensor, lengths)
                probabilities = torch.softmax(outputs, dim=1)
            
            inference_time = time.time() - start_time
            
            # Top-3ã®äºˆæ¸¬çµæœã‚’å–å¾—
            top3_probs, top3_indices = torch.topk(probabilities, 3, dim=1)
            
            predictions = []
            for i in range(3):
                key = self.KEY_CHARS[top3_indices[0][i].item()]
                confidence = top3_probs[0][i].item() * 100
                predictions.append((key, confidence))
            
            # æ¨è«–æ™‚é–“ã‚’è¨˜éŒ²
            self.inference_time = inference_time
            
            return predictions
            
        except Exception as e:
            print(f"âš ï¸ äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def run_prediction_mode(self):
        """äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã®å®Ÿè¡Œ"""
        print("ğŸš€ äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™")
        print("   æ“ä½œæ–¹æ³•:")
        print("   - æ‰‹ã‚’ã‚«ãƒ¡ãƒ©ã«æ˜ ã—ã¦ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã®æ„å›³ã‚’äºˆæ¸¬")
        print("   - ESC: çµ‚äº†")
        print("   - ä»»æ„ã®ã‚­ãƒ¼å…¥åŠ›: Actualã¨ã—ã¦è¨˜éŒ²ï¼ˆã‚¹ãƒšãƒ¼ã‚¹å¯ï¼‰")
        
        try:
            while True:
                # ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
                frame = self.camera.read_frame()
                if frame is None:
                    continue
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
                frame_data = self.process_frame(frame)
                if frame_data is not None:
                    self.trajectory_buffer.append(frame_data)
                
                # äºˆæ¸¬å®Ÿè¡Œ
                if len(self.trajectory_buffer) >= 60:
                    predictions = self.predict_intent()
                    if predictions:
                        self.current_prediction = predictions
                        self.prediction_history.append(predictions)
                
                # ç”»é¢æç”»
                self.draw_frame(frame)
                
                # ã‚­ãƒ¼å…¥åŠ›å‡¦ç†
                key = cv2.waitKey(1) & 0xFF
                if key == 27:  # ESC
                    break
                else:
                    # å®Ÿã‚­ãƒ¼å…¥åŠ›ã®ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼ˆå°å­—å¯èƒ½æ–‡å­—å…¨èˆ¬ã‚’å—ã‘ä»˜ã‘ï¼‰
                    if 32 <= key <= 126:  # ASCIIå°å­—å¯èƒ½æ–‡å­—ï¼ˆspace ~ ~ï¼‰
                        # ã‚¹ãƒšãƒ¼ã‚¹ã¯ ' ' ã«ã€ãã‚Œä»¥å¤–ã¯ãã®ã¾ã¾æ–‡å­—ã¨ã—ã¦è¨˜éŒ²
                        actual_char = ' ' if key == 32 else chr(key).lower()
                        self.last_actual_key = actual_char
                        # ãã®ç¬é–“ã®äºˆæ¸¬Top-3ã‚’ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
                        if self.current_prediction and len(self.current_prediction) > 0:
                            self.last_predicted_topk = list(self.current_prediction[:3])
                        else:
                            self.last_predicted_topk = None
                        
                        # ã‚­ãƒ¼ç¢ºå®šå¾Œã®å‡¦ç†ï¼ˆãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ï¼‰
                        if self.use_variable_length:
                            # å¯å¤‰é•·ãƒ¢ãƒ‡ãƒ«: ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢ï¼ˆå„ã‚­ãƒ¼ç‹¬ç«‹ï¼‰
                            self.trajectory_buffer.clear()
                            self.current_prediction = None
                        # else:
                        #     å›ºå®šé•·ãƒ¢ãƒ‡ãƒ«: ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°æ–¹å¼ï¼ˆã‚¯ãƒªã‚¢ã—ãªã„ï¼‰
                
                # FPSè¨ˆç®—ã¯ç„¡åŠ¹åŒ–ï¼ˆãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½å‰Šé™¤ã«ä¼´ã„ï¼‰
        
        except KeyboardInterrupt:
            print("\nâš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        
        finally:
            self.cleanup()
    
    def draw_frame(self, frame: np.ndarray):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã®æç”»"""
        # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®æç”»
        if self.keyboard_map:
            self.keyboard_map.visualize(frame)
        
        # æ‰‹è¿½è·¡ã®æç”»
        if self.hand_tracker:
            # æ‰‹ã®æ¤œå‡ºçµæœã‚’å–å¾—ã—ã¦æç”»
            results = self.hand_tracker.detect_hands(frame)
            if results.multi_hand_landmarks:
                self.hand_tracker.draw_landmarks(frame, results)
        
        # äºˆæ¸¬çµæœã®æç”»ï¼ˆæœªæº–å‚™æ™‚ã¯ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¡¨ç¤ºï¼‰
        if self.current_prediction:
            self.draw_prediction(frame)
        else:
            self.draw_loading_indicator(frame)

        # Actual vs Predict ã®æç”»
        self.draw_actual_vs_predict(frame)
        
        # ç”»é¢è¡¨ç¤º
        cv2.imshow('Keyboard Intent Prediction', frame)

    def draw_actual_vs_predict(self, frame: np.ndarray):
        """ç”»é¢ä¸‹éƒ¨ã« Actual / Predict ã‚’äºŒæ®µè¡¨ç¤º"""
        h, w = frame.shape[:2]
        margin = 10
        box_height = 70
        x1, y1 = margin, h - (box_height + margin)
        x2, y2 = w - margin, h - margin
        
        # èƒŒæ™¯
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), -1)
        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 1)
        
        # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹
        actual_text = f"Actual: {self.last_actual_key if self.last_actual_key is not None else '-'}"
        # Predictã¯ã‚­ãƒ¼æŠ¼ä¸‹æ™‚ã®Top-3ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã®ã¿è¡¨ç¤º
        if self.last_predicted_topk and len(self.last_predicted_topk) > 0:
            predict_items = [f"{k}({p:.0f}%)" for k, p in self.last_predicted_topk]
            predict_text = "Predict: " + " | ".join(predict_items)
        else:
            predict_text = "Predict: -"
        
        # æç”»
        cv2.putText(frame, actual_text, (x1 + 12, y1 + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        cv2.putText(frame, predict_text, (x1 + 12, y1 + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    def draw_loading_indicator(self, frame: np.ndarray):
        """äºˆæ¸¬æº–å‚™ä¸­ã®ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¡¨ç¤ºï¼ˆå·¦ä¸Šï¼‰"""
        cv2.rectangle(frame, (10, 10), (260, 60), (0, 0, 0), -1)
        cv2.rectangle(frame, (10, 10), (260, 60), (255, 255, 255), 1)
        cv2.putText(frame, "Loading predictions...", (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)
    
    def draw_prediction(self, frame: np.ndarray):
        """äºˆæ¸¬çµæœã®æç”»"""
        if not self.current_prediction:
            return
        
        # äºˆæ¸¬çµæœã®èƒŒæ™¯
        cv2.rectangle(frame, (10, 10), (300, 120), (0, 0, 0), -1)
        cv2.rectangle(frame, (10, 10), (300, 120), (255, 255, 255), 2)
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        cv2.putText(frame, "Prediction Results", (20, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # Top-3äºˆæ¸¬çµæœ
        for i, (key, confidence) in enumerate(self.current_prediction[:3]):
            color = (0, 255, 0) if i == 0 else (255, 255, 0) if i == 1 else (0, 255, 255)
            cv2.putText(frame, f"{i+1}. {key}: {confidence:.1f}%", (20, 55 + i*20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
    
    # è©•ä¾¡ãƒ»ãƒ‡ãƒãƒƒã‚°é–¢é€£ã®æç”»ã¯å‰Šé™¤ã—ã¾ã—ãŸ
    
    # è©•ä¾¡ãƒªã‚»ãƒƒãƒˆæ©Ÿèƒ½ã¯å‰Šé™¤ã—ã¾ã—ãŸ
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.camera:
            self.camera.release()
        
        cv2.destroyAllWindows()
        print("ğŸ§¹ ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")


def run_prediction_mode(model_path: str, keyboard_map_path: str = 'keyboard_map.json'):
    """äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ"""
    # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(model_path):
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_path}")
        print("å­¦ç¿’ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return False
    
    # äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã®ä½œæˆã¨å®Ÿè¡Œ
    prediction_mode = PredictionMode(model_path, keyboard_map_path)
    
    if not prediction_mode.initialize_components():
        print("âŒ åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False
    
    # äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã®å®Ÿè¡Œ
    prediction_mode.run_prediction_mode()
    
    return True


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description='ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰')
    parser.add_argument('--model', type=str, default=None,
                        help='ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã€‚modelsé…ä¸‹ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåï¼ˆintent_model_YYYYMMDD_HHMMSSï¼‰ã¾ãŸã¯.pthã®ãƒ•ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--map', type=str, default='keyboard_map.json',
                        help='ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒãƒƒãƒ—JSONã®ãƒ‘ã‚¹ (default: keyboard_map.json)')
    args = parser.parse_args()

    models_dir = "models"

    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã®æ±ºå®š
    chosen_model_path = None
    if args.model:
        if args.model.endswith('.pth') and os.path.exists(args.model):
            chosen_model_path = args.model
        else:
            candidate = os.path.join(models_dir, args.model, 'best_model.pth')
            if os.path.exists(candidate):
                chosen_model_path = candidate
            else:
                print(f"âŒ æŒ‡å®šãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.model}")
                exit(1)
    else:
        # æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•é¸æŠ
        if not os.path.exists(models_dir):
            print("âŒ modelsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            print("å­¦ç¿’ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")
            exit(1)
        model_dirs = [d for d in os.listdir(models_dir)
                      if d.startswith('intent_model_') and os.path.isdir(os.path.join(models_dir, d))]
        if not model_dirs:
            print("âŒ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("å­¦ç¿’ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")
            exit(1)
        latest_model_dir = sorted(model_dirs)[-1]
        chosen_model_path = os.path.join(models_dir, latest_model_dir, 'best_model.pth')

    print(f"ğŸ” ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«: {chosen_model_path}")
    if os.path.exists(chosen_model_path):
        run_prediction_mode(chosen_model_path, keyboard_map_path=args.map)
    else:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {chosen_model_path}")
        print("å­¦ç¿’ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")

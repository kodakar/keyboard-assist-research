# src/processing/models/hand_lstm.py
"""
æ‰‹ã®å‹•ãã‚’å­¦ç¿’ã™ã‚‹åŸºæœ¬çš„ãªLSTMãƒ¢ãƒ‡ãƒ«
PyTorchã‚’ä½¿ç”¨ã—ãŸå®Ÿè£…
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import json
import os
from typing import List, Dict, Tuple, Optional
from datetime import datetime
import pickle

class BasicHandLSTM(nn.Module):
    def __init__(self, 
                 input_size: int = 18,      # 18æ¬¡å…ƒï¼ˆä½œæ¥­é ˜åŸŸç‰¹å¾´é‡ï¼‰
                 hidden_size: int = 64,     # LSTMéš ã‚Œå±¤ã‚µã‚¤ã‚º
                 num_layers: int = 2,       # LSTMå±¤æ•°
                 num_classes: int = 37,     # 37ã‚­ãƒ¼ï¼ˆa-z, 0-9, spaceï¼‰
                 dropout: float = 0.2):     # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡
        """
        åŸºæœ¬çš„ãªæ‰‹ã®å‹•ãå­¦ç¿’ç”¨LSTMãƒ¢ãƒ‡ãƒ«
        
        Args:
            input_size: å…¥åŠ›ç‰¹å¾´é‡ã®æ¬¡å…ƒæ•°ï¼ˆä½œæ¥­é ˜åŸŸç‰¹å¾´é‡ã€18æ¬¡å…ƒï¼‰
            hidden_size: LSTMéš ã‚Œå±¤ã®ã‚µã‚¤ã‚º
            num_layers: LSTMã®å±¤æ•°
            num_classes: åˆ†é¡ã‚¯ãƒ©ã‚¹æ•°ï¼ˆã‚­ãƒ¼ã®æ•°ï¼‰
            dropout: ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡
        """
        super(BasicHandLSTM, self).__init__()
        
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.num_classes = num_classes
        
        # LSTMå±¤
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )
        
        # å…¨çµåˆå±¤
        self.fc = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 2, num_classes)
        )
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
        self.model_info = {
            'model_type': 'BasicHandLSTM',
            'input_size': input_size,
            'hidden_size': hidden_size,
            'num_layers': num_layers,
            'num_classes': num_classes,
            'dropout': dropout,
            'created_at': datetime.now().isoformat()
        }
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        é †ä¼æ’­
        
        Args:
            x: å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ« (batch_size, sequence_length, input_size)
        
        Returns:
            å‡ºåŠ›ãƒ†ãƒ³ã‚½ãƒ« (batch_size, num_classes)
        """
        # LSTMã®å‡ºåŠ›ã‚’å–å¾—
        lstm_out, (hidden, cell) = self.lstm(x)
        
        # æœ€å¾Œã®æ™‚åˆ»ã®å‡ºåŠ›ã‚’ä½¿ç”¨
        last_output = lstm_out[:, -1, :]
        
        # å…¨çµåˆå±¤ã§åˆ†é¡
        output = self.fc(last_output)
        
        return output
    
    @torch.no_grad()
    def predict_key(self, hand_sequence: np.ndarray) -> Tuple[str, float]:
        """
        æ‰‹ã®å‹•ãã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‹ã‚‰ã‚­ãƒ¼ã‚’äºˆæ¸¬
        
        Args:
            hand_sequence: æ‰‹ã®å‹•ãã‚·ãƒ¼ã‚±ãƒ³ã‚¹ (sequence_length, input_size)
        
        Returns:
            (äºˆæ¸¬ã‚­ãƒ¼, ç¢ºä¿¡åº¦)
        """
        self.eval()
        
        # ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        x = torch.FloatTensor(hand_sequence).unsqueeze(0)  # (1, seq_len, input_size)
        
        # äºˆæ¸¬
        output = self.forward(x)
        probabilities = torch.softmax(output, dim=1)
        
        # æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ã‚¯ãƒ©ã‚¹ã‚’å–å¾—
        predicted_class = torch.argmax(probabilities, dim=1).item()
        confidence = probabilities[0, predicted_class].item()
        
        # ã‚¯ãƒ©ã‚¹IDã‚’ã‚­ãƒ¼ã«å¤‰æ›
        predicted_key = self._class_id_to_key(predicted_class)
        
        return predicted_key, confidence
    
    def _class_id_to_key(self, class_id: int) -> str:
        """ã‚¯ãƒ©ã‚¹IDã‚’ã‚­ãƒ¼æ–‡å­—ã«å¤‰æ›"""
        if class_id < 26:
            return chr(ord('a') + class_id)  # a-z
        elif class_id < 36:
            return chr(ord('0') + class_id - 26)  # 0-9
        else:
            return 'space'  # ã‚¹ãƒšãƒ¼ã‚¹
    
    def _key_to_class_id(self, key: str) -> int:
        """ã‚­ãƒ¼æ–‡å­—ã‚’ã‚¯ãƒ©ã‚¹IDã«å¤‰æ›"""
        if key.isalpha() and key.islower():
            return ord(key) - ord('a')
        elif key.isdigit():
            return 26 + int(key)
        elif key == 'space':
            return 36
        else:
            return 0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    def save_model(self, filepath: str):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        try:
            # ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹è¾æ›¸ã‚’ä½œæˆ
            model_state = {
                'model_state_dict': self.state_dict(),
                'model_info': self.model_info,
                'input_size': self.input_size,
                'hidden_size': self.hidden_size,
                'num_layers': self.num_layers,
                'num_classes': self.num_classes
            }
            
            # PyTorchå½¢å¼ã§ä¿å­˜
            torch.save(model_state, filepath)
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
            
        except Exception as e:
            print(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    @classmethod
    def load_model(cls, filepath: str) -> 'BasicHandLSTM':
        """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹è¾æ›¸ã‚’èª­ã¿è¾¼ã¿
            model_state = torch.load(filepath, map_location='cpu')
            
            # ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
            model = cls(
                input_size=model_state['input_size'],
                hidden_size=model_state['hidden_size'],
                num_layers=model_state['num_layers'],
                num_classes=model_state['num_classes']
            )
            
            # é‡ã¿ã‚’èª­ã¿è¾¼ã¿
            model.load_state_dict(model_state['model_state_dict'])
            model.model_info = model_state['model_info']
            
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {filepath}")
            return model
            
        except Exception as e:
            print(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise


class HandLSTMTrainer:
    def __init__(self, model: BasicHandLSTM, learning_rate: float = 0.001):
        """
        LSTMãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’å™¨
        
        Args:
            model: å­¦ç¿’å¯¾è±¡ã®LSTMãƒ¢ãƒ‡ãƒ«
            learning_rate: å­¦ç¿’ç‡
        """
        self.model = model
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        
        # å­¦ç¿’å±¥æ­´
        self.training_history = {
            'epochs': [],
            'train_loss': [],
            'val_loss': [],
            'train_accuracy': [],
            'val_accuracy': []
        }
    
    def prepare_training_data(self, dataset: List[Dict]) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        
        Args:
            dataset: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
        
        Returns:
            (å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ«, ãƒ©ãƒ™ãƒ«ãƒ†ãƒ³ã‚½ãƒ«)
        """
        X, y = [], []
        
        for sample in dataset:
            if 'trajectory_data' in sample and sample['trajectory_data']:
                # è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                trajectory = sample['trajectory_data']
                
                # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                landmarks_sequence = []
                for point in trajectory:
                    if 'landmarks' in point:
                        landmarks_sequence.append(point['landmarks'])
                
                if len(landmarks_sequence) >= 10:  # æœ€å°ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·
                    # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã‚’çµ±ä¸€ï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã¾ãŸã¯åˆ‡ã‚Šè©°ã‚ï¼‰
                    if len(landmarks_sequence) > 30:
                        landmarks_sequence = landmarks_sequence[:30]
                    elif len(landmarks_sequence) < 30:
                        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆæœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç¹°ã‚Šè¿”ã—ï¼‰
                        last_frame = landmarks_sequence[-1]
                        while len(landmarks_sequence) < 30:
                            landmarks_sequence.append(last_frame)
                    
                    X.append(landmarks_sequence)
                    
                    # ãƒ©ãƒ™ãƒ«ã‚’æº–å‚™
                    intended_key = sample['intended_key']
                    class_id = self.model._key_to_class_id(intended_key)
                    y.append(class_id)
        
        if not X:
            raise ValueError("æœ‰åŠ¹ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        X_tensor = torch.FloatTensor(X)
        y_tensor = torch.LongTensor(y)
        
        print(f"ğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†")
        print(f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X)}")
        print(f"   å…¥åŠ›å½¢çŠ¶: {X_tensor.shape}")
        print(f"   ãƒ©ãƒ™ãƒ«å½¢çŠ¶: {y_tensor.shape}")
        
        return X_tensor, y_tensor
    
    def train(self, 
              train_data: Tuple[torch.Tensor, torch.Tensor],
              val_data: Optional[Tuple[torch.Tensor, torch.Tensor]] = None,
              epochs: int = 100,
              batch_size: int = 32,
              early_stopping_patience: int = 10):
        """
        ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’å®Ÿè¡Œ
        
        Args:
            train_data: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ (X, y)
            val_data: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ (X, y)
            epochs: ã‚¨ãƒãƒƒã‚¯æ•°
            batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
            early_stopping_patience: æ—©æœŸåœæ­¢ã®ãƒ‘ãƒ†ãƒ³ã‚¹
        """
        X_train, y_train = train_data
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆ
        train_dataset = torch.utils.data.TensorDataset(X_train, y_train)
        train_loader = torch.utils.data.DataLoader(
            train_dataset, batch_size=batch_size, shuffle=True
        )
        
        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        val_loader = None
        if val_data:
            X_val, y_val = val_data
            val_dataset = torch.utils.data.TensorDataset(X_val, y_val)
            val_loader = torch.utils.data.DataLoader(
                val_dataset, batch_size=batch_size, shuffle=False
            )
        
        print(f"ğŸš€ å­¦ç¿’é–‹å§‹")
        print(f"   ã‚¨ãƒãƒƒã‚¯æ•°: {epochs}")
        print(f"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
        print(f"   å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X_train)}")
        if val_data:
            print(f"   æ¤œè¨¼ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X_val)}")
        
        best_val_loss = float('inf')
        patience_counter = 0
        
        for epoch in range(epochs):
            # å­¦ç¿’
            self.model.train()
            train_loss = 0.0
            train_correct = 0
            train_total = 0
            
            for batch_X, batch_y in train_loader:
                self.optimizer.zero_grad()
                
                # é †ä¼æ’­
                outputs = self.model(batch_X)
                loss = self.criterion(outputs, batch_y)
                
                # é€†ä¼æ’­
                loss.backward()
                self.optimizer.step()
                
                # çµ±è¨ˆ
                train_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                train_total += batch_y.size(0)
                train_correct += (predicted == batch_y).sum().item()
            
            # å­¦ç¿’çµæœ
            avg_train_loss = train_loss / len(train_loader)
            train_accuracy = 100 * train_correct / train_total
            
            # æ¤œè¨¼
            val_loss = 0.0
            val_accuracy = 0.0
            
            if val_loader:
                self.model.eval()
                val_correct = 0
                val_total = 0
                
                with torch.no_grad():
                    for batch_X, batch_y in val_loader:
                        outputs = self.model(batch_X)
                        loss = self.criterion(outputs, batch_y)
                        
                        val_loss += loss.item()
                        _, predicted = torch.max(outputs.data, 1)
                        val_total += batch_y.size(0)
                        val_correct += (predicted == batch_y).sum().item()
                
                avg_val_loss = val_loss / len(val_loader)
                val_accuracy = 100 * val_correct / val_total
                
                # æ—©æœŸåœæ­¢ãƒã‚§ãƒƒã‚¯
                if avg_val_loss < best_val_loss:
                    best_val_loss = avg_val_loss
                    patience_counter = 0
                else:
                    patience_counter += 1
                
                if patience_counter >= early_stopping_patience:
                    print(f"â¹ï¸ æ—©æœŸåœæ­¢: {epoch + 1}ã‚¨ãƒãƒƒã‚¯ç›®")
                    break
            
            # å±¥æ­´ã‚’è¨˜éŒ²
            self.training_history['epochs'].append(epoch + 1)
            self.training_history['train_loss'].append(avg_train_loss)
            self.training_history['train_accuracy'].append(train_accuracy)
            
            if val_loader:
                self.training_history['val_loss'].append(avg_val_loss)
                self.training_history['val_accuracy'].append(val_accuracy)
            
            # é€²æ—è¡¨ç¤º
            if (epoch + 1) % 10 == 0 or epoch == 0:
                print(f"Epoch {epoch + 1:3d}/{epochs} | "
                      f"Train Loss: {avg_train_loss:.4f} | "
                      f"Train Acc: {train_accuracy:.2f}%", end="")
                
                if val_loader:
                    print(f" | Val Loss: {avg_val_loss:.4f} | "
                          f"Val Acc: {val_accuracy:.2f}%")
                else:
                    print()
        
        print(f"âœ… å­¦ç¿’å®Œäº†")
        return self.training_history
    
    def save_training_history(self, filepath: str):
        """å­¦ç¿’å±¥æ­´ã‚’ä¿å­˜"""
        try:
            with open(filepath, 'wb') as f:
                pickle.dump(self.training_history, f)
            print(f"âœ… å­¦ç¿’å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
        except Exception as e:
            print(f"âš ï¸ å­¦ç¿’å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def load_training_history(self, filepath: str):
        """å­¦ç¿’å±¥æ­´ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(filepath, 'rb') as f:
                self.training_history = pickle.load(f)
            print(f"âœ… å­¦ç¿’å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {filepath}")
        except Exception as e:
            print(f"âš ï¸ å­¦ç¿’å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")


def create_sample_model() -> BasicHandLSTM:
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
    model = BasicHandLSTM(
        input_size=15,      # 15æ¬¡å…ƒï¼ˆä½œæ¥­é ˜åŸŸç‰¹å¾´é‡ï¼‰
        hidden_size=64,     # LSTMéš ã‚Œå±¤ã‚µã‚¤ã‚º
        num_layers=2,       # LSTMå±¤æ•°
        num_classes=37,     # 37ã‚­ãƒ¼
        dropout=0.2         # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡
    )
    
    print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ")
    print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
    
    return model

# src/processing/enhanced_data_collector.py
"""
æ‹¡å¼µãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ 
æ‰‹ã®è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã®æ™‚ç³»åˆ—ä¿å­˜ã¨å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰
"""

import json
import os
import numpy as np
from datetime import datetime
from collections import deque
import cv2
from typing import List, Dict, Optional, Tuple

class EnhancedDataCollector:
    def __init__(self, 
                 trajectory_buffer_size: int = 30,
                 data_dir: str = "data",
                 user_id: str = "user_001"):
        """
        æ‹¡å¼µãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        
        Args:
            trajectory_buffer_size: è»Œè·¡ãƒãƒƒãƒ•ã‚¡ã®ã‚µã‚¤ã‚ºï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰
            data_dir: ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        """
        self.trajectory_buffer_size = trajectory_buffer_size
        self.data_dir = os.path.abspath(data_dir)
        self.user_id = user_id
        
        # æ‰‹ã®è»Œè·¡ã‚’ãƒãƒƒãƒ•ã‚¡ï¼ˆæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ï¼‰
        self.trajectory_buffer = deque(maxlen=trajectory_buffer_size)
        
        # ç¾åœ¨ã®å…¥åŠ›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        self.current_context = ""
        self.target_text = ""
        
        # ãƒ‡ãƒ¼ã‚¿åé›†ã®çŠ¶æ…‹
        self.is_collecting = False
        self.collection_start_time = None
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        os.makedirs(data_dir, exist_ok=True)
        os.makedirs(os.path.join(data_dir, "trajectories"), exist_ok=True)
        os.makedirs(os.path.join(data_dir, "samples"), exist_ok=True)
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        models_dir = os.path.join(data_dir, "models")
        os.makedirs(models_dir, exist_ok=True)
        os.makedirs(os.path.join(models_dir, "user_001"), exist_ok=True)
        os.makedirs(os.path.join(models_dir, "shared"), exist_ok=True)
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            "total_samples": 0,
            "total_trajectories": 0,
            "session_start": datetime.now().isoformat()
        }
    
    def start_collection_session(self, target_text: str = ""):
        """
        ãƒ‡ãƒ¼ã‚¿åé›†ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹
        
        Args:
            target_text: ç›®æ¨™ã¨ã™ã‚‹å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        """
        self.target_text = target_text
        self.current_context = ""
        self.is_collecting = True
        self.collection_start_time = datetime.now()
        self.trajectory_buffer.clear()
        
        print(f"ğŸš€ ãƒ‡ãƒ¼ã‚¿åé›†ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹")
        print(f"   ç›®æ¨™ãƒ†ã‚­ã‚¹ãƒˆ: {target_text}")
        print(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {self.user_id}")
    
    def stop_collection_session(self):
        """ãƒ‡ãƒ¼ã‚¿åé›†ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åœæ­¢"""
        self.is_collecting = False
        session_duration = datetime.now() - self.collection_start_time
        
        print(f"â¹ï¸ ãƒ‡ãƒ¼ã‚¿åé›†ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†")
        print(f"   ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“: {session_duration}")
        print(f"   åé›†ã‚µãƒ³ãƒ—ãƒ«æ•°: {self.stats['total_samples']}")
        print(f"   åé›†è»Œè·¡æ•°: {self.stats['total_trajectories']}")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆã‚’ä¿å­˜
        self._save_session_stats()
    
    def add_hand_position(self, hand_landmarks, frame_timestamp: Optional[float] = None):
        """
        æ‰‹ã®ä½ç½®ã‚’è»Œè·¡ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        
        Args:
            hand_landmarks: MediaPipeã®æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            frame_timestamp: ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
        """
        if not self.is_collecting:
            return
        
        # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’é…åˆ—ã«å¤‰æ›ï¼ˆ21ç‚¹ Ã— 3åº§æ¨™ = 63æ¬¡å…ƒï¼‰
        landmarks_array = []
        for landmark in hand_landmarks.landmark:
            landmarks_array.extend([landmark.x, landmark.y, landmark.z])
        
        # è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        trajectory_point = {
            'timestamp': frame_timestamp or datetime.now().timestamp(),
            'landmarks': landmarks_array,
            'frame_index': len(self.trajectory_buffer)
        }
        
        self.trajectory_buffer.append(trajectory_point)
    
    def add_key_sample(self, intended_key: str, actual_key: str, 
                      hand_landmarks, target_text: str = ""):
        """
        ã‚­ãƒ¼å…¥åŠ›ã‚µãƒ³ãƒ—ãƒ«ã‚’è¨˜éŒ²
        
        Args:
            intended_key: æ„å›³ã—ãŸã‚­ãƒ¼
            actual_key: å®Ÿéš›ã«æŠ¼ã•ã‚ŒãŸã‚­ãƒ¼
            hand_landmarks: ã‚­ãƒ¼æŠ¼ä¸‹æ™‚ã®æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            target_text: ç›®æ¨™ãƒ†ã‚­ã‚¹ãƒˆ
        """
        if not self.is_collecting:
            return
        
        # ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°
        if intended_key == actual_key:
            self.current_context += intended_key
        else:
            # èª¤å…¥åŠ›ã®å ´åˆã¯ã€æ„å›³ã—ãŸã‚­ãƒ¼ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°
            self.current_context += intended_key
        
        # è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆãƒãƒƒãƒ•ã‚¡ãŒæº€ãŸã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
        trajectory_data = None
        if len(self.trajectory_buffer) >= self.trajectory_buffer_size:
            trajectory_data = list(self.trajectory_buffer)
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        sample = {
            'timestamp': datetime.now().isoformat(),
            'user_id': self.user_id,
            'target_text': target_text or self.target_text,
            'intended_key': intended_key,
            'actual_key': actual_key,
            'current_context': self.current_context,
            'hand_landmarks': self._landmarks_to_array(hand_landmarks),
            'landmarks_format': 'array_63d',  # 21ç‚¹ Ã— 3åº§æ¨™
            'trajectory_data': trajectory_data,
            'trajectory_length': len(self.trajectory_buffer),
            'session_duration': (datetime.now() - self.collection_start_time).total_seconds()
        }
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚’ä¿å­˜
        self._save_sample(sample)
        
        # è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆåˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        if trajectory_data:
            self._save_trajectory(trajectory_data, intended_key)
        
        # çµ±è¨ˆã‚’æ›´æ–°
        self.stats['total_samples'] += 1
        if trajectory_data:
            self.stats['total_trajectories'] += 1
        
        print(f"ğŸ“ ã‚µãƒ³ãƒ—ãƒ«è¨˜éŒ²: {intended_key} -> {actual_key} "
              f"(è»Œè·¡: {len(self.trajectory_buffer)}ãƒ•ãƒ¬ãƒ¼ãƒ )")
    
    def _landmarks_to_array(self, hand_landmarks) -> List[float]:
        """æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’é…åˆ—ã«å¤‰æ›"""
        landmarks_array = []
        for landmark in hand_landmarks.landmark:
            landmarks_array.extend([landmark.x, landmark.y, landmark.z])
        return landmarks_array
    
    def _save_sample(self, sample: Dict):
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"sample_{timestamp}_{sample['intended_key']}_{self.stats['total_samples']:04d}.json"
        filepath = os.path.join(self.data_dir, "samples", filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(sample, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸ ã‚µãƒ³ãƒ—ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_trajectory(self, trajectory_data: List[Dict], key: str):
        """è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"trajectory_{timestamp}_{key}_{self.stats['total_trajectories']:04d}.json"
        filepath = os.path.join(self.data_dir, "trajectories", filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(trajectory_data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸ è»Œè·¡ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_session_stats(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆã‚’ä¿å­˜"""
        stats_file = os.path.join(self.data_dir, f"session_stats_{self.user_id}.json")
        
        session_stats = {
            'user_id': self.user_id,
            'session_start': self.collection_start_time.isoformat(),
            'session_end': datetime.now().isoformat(),
            'total_samples': self.stats['total_samples'],
            'total_trajectories': self.stats['total_trajectories'],
            'target_text': self.target_text,
            'final_context': self.current_context
        }
        
        try:
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(session_stats, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸ çµ±è¨ˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_training_dataset_info(self) -> Dict:
        """å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æƒ…å ±ã‚’å–å¾—"""
        samples_dir = os.path.join(self.data_dir, "samples")
        trajectories_dir = os.path.join(self.data_dir, "trajectories")
        
        sample_files = [f for f in os.listdir(samples_dir) if f.endswith('.json')]
        trajectory_files = [f for f in os.listdir(trajectories_dir) if f.endswith('.json')]
        
        return {
            'total_samples': len(sample_files),
            'total_trajectories': len(trajectory_files),
            'samples_directory': samples_dir,
            'trajectories_directory': trajectories_dir,
            'user_id': self.user_id,
            'last_updated': datetime.now().isoformat()
        }
    
    def export_training_dataset(self, output_file: str = None) -> str:
        """å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’çµ±åˆã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = os.path.join(self.data_dir, f"training_dataset_{self.user_id}_{timestamp}.json")
        
        samples_dir = os.path.join(self.data_dir, "samples")
        sample_files = [f for f in os.listdir(samples_dir) if f.endswith('.json')]
        
        dataset = []
        for sample_file in sample_files:
            try:
                with open(os.path.join(samples_dir, sample_file), 'r', encoding='utf-8') as f:
                    sample = json.load(f)
                    dataset.append(sample)
            except Exception as e:
                print(f"âš ï¸ ã‚µãƒ³ãƒ—ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {sample_file}: {e}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¿å­˜
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(dataset, f, indent=2, ensure_ascii=False)
            print(f"âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {output_file}")
            print(f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(dataset)}")
            return output_file
        except Exception as e:
            print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def visualize_trajectory(self, frame, trajectory_data: List[Dict] = None):
        """
        è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’ç”»åƒä¸Šã«å¯è¦–åŒ–
        
        Args:
            frame: è¡¨ç¤ºç”¨ãƒ•ãƒ¬ãƒ¼ãƒ 
            trajectory_data: è»Œè·¡ãƒ‡ãƒ¼ã‚¿ï¼ˆNoneã®å ´åˆã¯ç¾åœ¨ã®ãƒãƒƒãƒ•ã‚¡ã‚’ä½¿ç”¨ï¼‰
        """
        if trajectory_data is None:
            trajectory_data = list(self.trajectory_buffer)
        
        if not trajectory_data:
            return frame
        
        h, w = frame.shape[:2]
        
        # è»Œè·¡ã‚’ç·šã§æç”»
        points = []
        for i, point in enumerate(trajectory_data):
            if 'landmarks' in point and len(point['landmarks']) >= 63:
                try:
                    # æ‰‹ã®ä¸­å¿ƒä½ç½®ï¼ˆãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯9ç•ªã€ä¸­æŒ‡ã®ä»˜ã‘æ ¹ï¼‰ã‚’ä½¿ç”¨
                    # MediaPipe Hands: 21å€‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ Ã— 3åº§æ¨™(x,y,z) = 63æ¬¡å…ƒ
                    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯9ç•ª: ä¸­æŒ‡ã®ä»˜ã‘æ ¹ â†’ landmarks[27:30] (x, y, z)
                    # æ­£ã—ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: 9ç•ªç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ = landmarks[27:30]
                    x = int(point['landmarks'][27] * w)  # xåº§æ¨™ (27 = 9*3)
                    y = int(point['landmarks'][28] * h)  # yåº§æ¨™ (28 = 9*3+1)
                    points.append((x, y))
                except (IndexError, ValueError) as e:
                    print(f"âš ï¸ è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã®åº§æ¨™å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
        
        # è»Œè·¡ã‚’æç”»
        if len(points) > 1:
            for i in range(1, len(points)):
                # è‰²ã‚’ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§å¤‰åŒ–ï¼ˆå¤ã„ç‚¹ã¯é’ã€æ–°ã—ã„ç‚¹ã¯èµ¤ï¼‰
                color_ratio = i / len(points)
                color = (
                    int(255 * color_ratio),  # B
                    int(255 * (1 - color_ratio)),  # G
                    int(255)  # R
                )
                cv2.line(frame, points[i-1], points[i], color, 2)
            
            # æœ€æ–°ã®ç‚¹ã‚’å¼·èª¿è¡¨ç¤º
            if points:
                cv2.circle(frame, points[-1], 8, (0, 255, 255), -1)
        
        return frame
    
    def cleanup_memory(self):
        """ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ"""
        # è»Œè·¡ãƒãƒƒãƒ•ã‚¡ãŒå¤§ãããªã‚Šã™ããŸå ´åˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if len(self.trajectory_buffer) > self.trajectory_buffer_size * 2:
            print(f"ğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ: ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º {len(self.trajectory_buffer)} -> {self.trajectory_buffer_size}")
            self.trajectory_buffer.clear()
        
        # çµ±è¨ˆæƒ…å ±ã®ãƒªã‚»ãƒƒãƒˆï¼ˆé•·æ™‚é–“ã‚»ãƒƒã‚·ãƒ§ãƒ³å¯¾ç­–ï¼‰
        if self.collection_start_time:
            session_duration = (datetime.now() - self.collection_start_time).total_seconds()
            if session_duration > 3600:  # 1æ™‚é–“ä»¥ä¸Š
                print(f"â° é•·æ™‚é–“ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¤œå‡º: {session_duration:.1f}ç§’")
                print(f"   çµ±è¨ˆæƒ…å ±ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã™")
                self.stats['total_samples'] = 0
                self.stats['total_trajectories'] = 0
                self.collection_start_time = datetime.now()
    
    def get_memory_usage(self) -> Dict:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ã‚’å–å¾—"""
        return {
            'trajectory_buffer_size': len(self.trajectory_buffer),
            'max_buffer_size': self.trajectory_buffer_size,
            'memory_usage_percent': (len(self.trajectory_buffer) / self.trajectory_buffer_size) * 100,
            'session_duration': (datetime.now() - self.collection_start_time).total_seconds() if self.collection_start_time else 0
        }

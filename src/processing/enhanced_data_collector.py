# src/processing/enhanced_data_collector.py
"""
æ‹¡å¼µãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ 
æ‰‹ã®è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã®æ™‚ç³»åˆ—ä¿å­˜ã¨å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰
"""

import json
import os
import numpy as np
from datetime import datetime
from collections import deque
import cv2
from typing import List, Dict, Optional, Tuple
from src.processing.coordinate_transformer import WorkAreaTransformer

class EnhancedDataCollector:
    def __init__(self, 
                 trajectory_buffer_size: int = 30,
                 data_dir: str = "data",
                 user_id: str = "user_001"):
        """
        æ‹¡å¼µãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        
        Args:
            trajectory_buffer_size: è»Œè·¡ãƒãƒƒãƒ•ã‚¡ã®ã‚µã‚¤ã‚ºï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰
            data_dir: ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        """
        self.trajectory_buffer_size = trajectory_buffer_size
        self.data_dir = os.path.abspath(data_dir)
        self.user_id = user_id
        
        # åº§æ¨™å¤‰æ›ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–
        self.transformer = WorkAreaTransformer()
        
        # æ‰‹ã®è»Œè·¡ã‚’ãƒãƒƒãƒ•ã‚¡ï¼ˆæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ï¼‰
        self.trajectory_buffer = deque(maxlen=trajectory_buffer_size)
    
        # å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã®åº§æ¨™ï¼ˆé€Ÿåº¦è¨ˆç®—ç”¨ï¼‰
        self.previous_coords = None
        
        # ç¾åœ¨ã®å…¥åŠ›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        self.current_context = ""
        self.target_text = ""
        
        # ãƒ‡ãƒ¼ã‚¿åé›†ã®çŠ¶æ…‹
        self.is_collecting = False
        self.collection_start_time = None
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(os.path.join(self.data_dir, "trajectories"), exist_ok=True)
        os.makedirs(os.path.join(self.data_dir, "samples"), exist_ok=True)
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        models_dir = os.path.join(self.data_dir, "models")
        os.makedirs(models_dir, exist_ok=True)
        os.makedirs(os.path.join(models_dir, "user_001"), exist_ok=True)
        os.makedirs(os.path.join(models_dir, "shared"), exist_ok=True)
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            "total_samples": 0,
            "total_trajectories": 0,
            "session_start": datetime.now().isoformat()
        }
    
    def set_work_area_corners(self, corners: np.ndarray):
        """
        ä½œæ¥­é ˜åŸŸã®4éš…ã®åº§æ¨™ã‚’è¨­å®š
        
        Args:
            corners: 4éš…ã®åº§æ¨™ (å·¦ä¸Š, å³ä¸Š, å³ä¸‹, å·¦ä¸‹) ã®é…åˆ—
        """
        self.transformer.set_work_area_corners(corners)
    
    def start_collection_session(self, target_text: str = ""):
        """
        ãƒ‡ãƒ¼ã‚¿åé›†ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹
        
        Args:
            target_text: ç›®æ¨™ã¨ã™ã‚‹å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        """
        self.target_text = target_text
        self.current_context = ""
        self.is_collecting = True
        self.collection_start_time = datetime.now()
        self.trajectory_buffer.clear()
        
        print(f"ğŸš€ ãƒ‡ãƒ¼ã‚¿åé›†ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹")
        print(f"   ç›®æ¨™ãƒ†ã‚­ã‚¹ãƒˆ: {target_text}")
        print(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {self.user_id}")
    
    def stop_collection_session(self):
        """ãƒ‡ãƒ¼ã‚¿åé›†ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åœæ­¢"""
        self.is_collecting = False
        session_duration = datetime.now() - self.collection_start_time
        
        print(f"â¹ï¸ ãƒ‡ãƒ¼ã‚¿åé›†ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†")
        print(f"   ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“: {session_duration}")
        print(f"   åé›†ã‚µãƒ³ãƒ—ãƒ«æ•°: {self.stats['total_samples']}")
        print(f"   åé›†è»Œè·¡æ•°: {self.stats['total_trajectories']}")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆã‚’ä¿å­˜
        self._save_session_stats()
    
    def add_hand_position(self, hand_landmarks, frame_timestamp: Optional[float] = None):
        """
        æ‰‹ã®ä½ç½®ã‚’è»Œè·¡ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ ï¼ˆç›¸å¯¾åº§æ¨™ç³»ï¼‰
        
        Args:
            hand_landmarks: MediaPipeã®æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            frame_timestamp: ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
        """
        if not self.is_collecting:
            return
        
        try:
            # é‡è¦ãªãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®åº§æ¨™ã‚’å–å¾—ï¼ˆ0-1æ­£è¦åŒ–ï¼‰
            index_finger = hand_landmarks.landmark[8]  # äººå·®ã—æŒ‡ã®å…ˆç«¯
            middle_finger = hand_landmarks.landmark[12]  # ä¸­æŒ‡ã®å…ˆç«¯
            wrist = hand_landmarks.landmark[0]  # æ‰‹é¦–
            
            # ä½œæ¥­é ˜åŸŸåº§æ¨™ã«å¤‰æ›
            wa_coords = {}
            for name, landmark in [("index_finger", index_finger), 
                                  ("middle_finger", middle_finger), 
                                  ("wrist", wrist)]:
                # ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ã‚’ä½œæ¥­é ˜åŸŸåº§æ¨™ã«å¤‰æ›
                wa_coord = self.transformer.pixel_to_work_area(
                    landmark.x, landmark.y
                )
                if wa_coord:
                    wa_coords[name] = {"x": float(wa_coord[0]), "y": float(wa_coord[1])}
                else:
                    # å¤‰æ›å¤±æ•—æ™‚ã¯å…ƒã®åº§æ¨™ã‚’ä½¿ç”¨
                    wa_coords[name] = {"x": float(landmark.x), "y": float(landmark.y)}
            
            # äººå·®ã—æŒ‡ã®ä½ç½®ã‹ã‚‰æœ€è¿‘å‚ã‚­ãƒ¼ã¨ç›¸å¯¾åº§æ¨™ã‚’å–å¾—
            nearest_keys_info = []
            if "index_finger" in wa_coords:
                index_x = wa_coords["index_finger"]["x"]
                index_y = wa_coords["index_finger"]["y"]
                
                nearest_keys = self.transformer.get_nearest_keys_with_relative_coords(
                    index_x, index_y, top_k=3
                )
                
                for key_info in nearest_keys:
                    # é€Ÿåº¦è¨ˆç®—
                    approach_velocity = self._calculate_approach_velocity(
                        index_x, index_y, key_info.key, frame_timestamp
                    )
                    
                    nearest_keys_info.append({
                        "key": key_info.key,
                        "relative_x": float(key_info.relative_x),
                        "relative_y": float(key_info.relative_y),
                        "distance": float(np.sqrt(key_info.relative_x**2 + key_info.relative_y**2)),
                        "approach_velocity": float(approach_velocity) if approach_velocity is not None else 0.0
                    })
            
            # è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            trajectory_point = {
                "timestamp": float(frame_timestamp or datetime.now().timestamp()),
                "frame_index": len(self.trajectory_buffer),
                "work_area_coords": wa_coords,  # åå‰å¤‰æ›´
                "nearest_keys_relative": nearest_keys_info,
                "data_version": "2.0"  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³è¿½åŠ 
            }
            
            # å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã®åº§æ¨™ã‚’æ›´æ–°ï¼ˆé€Ÿåº¦è¨ˆç®—ç”¨ï¼‰
            self.previous_coords = {
                "index_finger": (float(index_finger.x), float(index_finger.y)),
                "timestamp": float(frame_timestamp or datetime.now().timestamp())
            }
            
            # è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
            self.trajectory_buffer.append(trajectory_point)
            
        except Exception as e:
            print(f"âš ï¸ æ‰‹ã®ä½ç½®è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®å½¢å¼ã§ä¿å­˜
            landmarks_array = []
            for landmark in hand_landmarks.landmark:
                landmarks_array.extend([landmark.x, landmark.y, landmark.z])
            
            trajectory_point = {
                'timestamp': frame_timestamp or datetime.now().timestamp(),
                'landmarks': landmarks_array,
                'frame_index': len(self.trajectory_buffer)
            }
            self.trajectory_buffer.append(trajectory_point)
    
    def _calculate_approach_velocity(self, current_x: float, current_y: float, 
                                   target_key: str, current_timestamp: float) -> float:
        """
        æŒ‡å®šã‚­ãƒ¼ã¸ã®æ¥è¿‘é€Ÿåº¦ã‚’è¨ˆç®—ï¼ˆã‚­ãƒ¼ã‚µã‚¤ã‚º/ç§’ï¼‰
        
        Args:
            current_x: ç¾åœ¨ã®Xåº§æ¨™ï¼ˆã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ç©ºé–“ï¼‰
            current_y: ç¾åœ¨ã®Yåº§æ¨™ï¼ˆã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ç©ºé–“ï¼‰
            target_key: ç›®æ¨™ã‚­ãƒ¼
            current_timestamp: ç¾åœ¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            
        Returns:
            æ¥è¿‘é€Ÿåº¦ï¼ˆã‚­ãƒ¼ã‚µã‚¤ã‚º/ç§’ï¼‰
        """
        if self.previous_coords is None:
            return 0.0
        
        try:
            # å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã®åº§æ¨™ã‚’å–å¾—
            prev_x, prev_y = self.previous_coords["index_finger"]
            prev_timestamp = self.previous_coords["timestamp"]
            
            # æ™‚é–“å·®ã‚’è¨ˆç®—
            time_diff = current_timestamp - prev_timestamp
            if time_diff <= 0:
                return 0.0
            
            # å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã®åº§æ¨™ã‚’ä½œæ¥­é ˜åŸŸã«å¤‰æ›
            prev_kb_coord = self.transformer.pixel_to_work_area(prev_x, prev_y)
            if prev_kb_coord is None:
                return 0.0
            
            prev_kb_x, prev_kb_y = prev_kb_coord
            
            # è·é›¢ã®å¤‰åŒ–ã‚’è¨ˆç®—
            distance_diff = np.sqrt((current_x - prev_kb_x)**2 + (current_y - prev_kb_y)**2)
            
            # é€Ÿåº¦ã‚’è¨ˆç®—ï¼ˆã‚­ãƒ¼ã‚µã‚¤ã‚º/ç§’ï¼‰
            velocity = distance_diff / time_diff
            
            return velocity
            
        except Exception as e:
            print(f"âš ï¸ é€Ÿåº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def add_key_sample(self, intended_key: str, actual_key: str,
                      hand_landmarks, target_text: str = ""):
        """
        ã‚­ãƒ¼å…¥åŠ›ã‚µãƒ³ãƒ—ãƒ«ã‚’è¨˜éŒ²
        
        Args:
            intended_key: æ„å›³ã—ãŸã‚­ãƒ¼
            actual_key: å®Ÿéš›ã«æŠ¼ã•ã‚ŒãŸã‚­ãƒ¼
            hand_landmarks: ã‚­ãƒ¼æŠ¼ä¸‹æ™‚ã®æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            target_text: ç›®æ¨™ãƒ†ã‚­ã‚¹ãƒˆ
        """
        if not self.is_collecting:
            return
        
        # ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°
        if intended_key == actual_key:
            self.current_context += intended_key
        else:
            # èª¤å…¥åŠ›ã®å ´åˆã¯ã€æ„å›³ã—ãŸã‚­ãƒ¼ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°
            self.current_context += intended_key
        
        # è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆãƒãƒƒãƒ•ã‚¡ãŒæº€ãŸã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
        trajectory_data = None
        if len(self.trajectory_buffer) >= self.trajectory_buffer_size:
            trajectory_data = list(self.trajectory_buffer)
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆç›¸å¯¾åº§æ¨™ç³»ï¼‰
        sample = {
            'timestamp': datetime.now().isoformat(),
            'user_id': self.user_id,
            'target_text': target_text or self.target_text,
            'intended_key': intended_key,
            'actual_key': actual_key,
            'current_context': self.current_context,
            'hand_landmarks': self._landmarks_to_array(hand_landmarks),
            'landmarks_format': 'array_63d',  # 21ç‚¹ Ã— 3åº§æ¨™ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
            'trajectory_data': trajectory_data,
            'trajectory_length': len(self.trajectory_buffer),
            'session_duration': (datetime.now() - self.collection_start_time).total_seconds(),
            'coordinate_system': 'work_area_v2'  # åº§æ¨™ç³»ã®æŒ‡å®š
        }
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚’ä¿å­˜
        self._save_sample(sample)
        
        # è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆåˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        if trajectory_data:
            self._save_trajectory(trajectory_data, intended_key)
        
        # çµ±è¨ˆã‚’æ›´æ–°
        self.stats['total_samples'] += 1
        if trajectory_data:
            self.stats['total_trajectories'] += 1
        
        print(f"ğŸ“ ã‚µãƒ³ãƒ—ãƒ«è¨˜éŒ²: {intended_key} -> {actual_key} "
              f"(è»Œè·¡: {len(self.trajectory_buffer)}ãƒ•ãƒ¬ãƒ¼ãƒ )")
    
    def set_screen_size(self, width: int, height: int):
        """
        ç”»é¢ã‚µã‚¤ã‚ºã‚’è¨­å®šï¼ˆåº§æ¨™å¤‰æ›ã«ä½¿ç”¨ï¼‰
        
        Args:
            width: ç”»é¢å¹…ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
            height: ç”»é¢é«˜ã•ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
        """
        self.transformer.set_screen_size(width, height)
        print(f"âœ… ç”»é¢ã‚µã‚¤ã‚ºã‚’è¨­å®šã—ã¾ã—ãŸ: {width}x{height}")
    
    def set_work_area_corners(self, corners: np.ndarray):
        """
        ä½œæ¥­é ˜åŸŸã®4éš…ã®åº§æ¨™ã‚’è¨­å®š
        
        Args:
            corners: 4éš…ã®åº§æ¨™ (å·¦ä¸Š, å³ä¸Š, å³ä¸‹, å·¦ä¸‹) ã®é…åˆ—
                    å„åº§æ¨™ã¯ (x, y) ã®å½¢å¼ã§ã€0-1ã®æ­£è¦åŒ–åº§æ¨™
        """
        self.transformer.set_work_area_corners(corners)
        print(f"âœ… ä½œæ¥­é ˜åŸŸã®4éš…ã‚’è¨­å®šã—ã¾ã—ãŸ")
    
    def _landmarks_to_array(self, hand_landmarks) -> List[float]:
        """æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’é…åˆ—ã«å¤‰æ›"""
        landmarks_array = []
        for landmark in hand_landmarks.landmark:
            landmarks_array.extend([landmark.x, landmark.y, landmark.z])
        return landmarks_array
    
    def _save_sample(self, sample: Dict):
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"sample_{timestamp}_{sample['intended_key']}_{self.stats['total_samples']:04d}.json"
        filepath = os.path.join(self.data_dir, "samples", filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(sample, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸ ã‚µãƒ³ãƒ—ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_trajectory(self, trajectory_data: List[Dict], key: str):
        """è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"trajectory_{timestamp}_{key}_{self.stats['total_trajectories']:04d}.json"
        filepath = os.path.join(self.data_dir, "trajectories", filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(trajectory_data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸ è»Œè·¡ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_session_stats(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆã‚’ä¿å­˜"""
        stats_file = os.path.join(self.data_dir, f"session_stats_{self.user_id}.json")
        
        session_stats = {
            'user_id': self.user_id,
            'session_start': self.collection_start_time.isoformat(),
            'session_end': datetime.now().isoformat(),
            'total_samples': self.stats['total_samples'],
            'total_trajectories': self.stats['total_trajectories'],
            'target_text': self.target_text,
            'final_context': self.current_context
        }
        
        try:
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(session_stats, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸ çµ±è¨ˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_training_dataset_info(self) -> Dict:
        """å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æƒ…å ±ã‚’å–å¾—"""
        samples_dir = os.path.join(self.data_dir, "samples")
        trajectories_dir = os.path.join(self.data_dir, "trajectories")
        
        sample_files = [f for f in os.listdir(samples_dir) if f.endswith('.json')]
        trajectory_files = [f for f in os.listdir(trajectories_dir) if f.endswith('.json')]
        
        return {
            'total_samples': len(sample_files),
            'total_trajectories': len(trajectory_files),
            'samples_directory': samples_dir,
            'trajectories_directory': trajectories_dir,
            'user_id': self.user_id,
            'last_updated': datetime.now().isoformat()
        }
    
    def export_training_dataset(self, output_file: str = None) -> str:
        """å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’çµ±åˆã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = os.path.join(self.data_dir, f"training_dataset_{self.user_id}_{timestamp}.json")
        
        samples_dir = os.path.join(self.data_dir, "samples")
        sample_files = [f for f in os.listdir(samples_dir) if f.endswith('.json')]
        
        dataset = []
        for sample_file in sample_files:
            try:
                with open(os.path.join(samples_dir, sample_file), 'r', encoding='utf-8') as f:
                    sample = json.load(f)
                    dataset.append(sample)
            except Exception as e:
                print(f"âš ï¸ ã‚µãƒ³ãƒ—ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {sample_file}: {e}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¿å­˜
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(dataset, f, indent=2, ensure_ascii=False)
            print(f"âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {output_file}")
            print(f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(dataset)}")
            return output_file
        except Exception as e:
            print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def visualize_trajectory(self, frame, trajectory_data: List[Dict] = None):
        """
        è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’ç”»åƒä¸Šã«å¯è¦–åŒ–
        
        Args:
            frame: è¡¨ç¤ºç”¨ãƒ•ãƒ¬ãƒ¼ãƒ 
            trajectory_data: è»Œè·¡ãƒ‡ãƒ¼ã‚¿ï¼ˆNoneã®å ´åˆã¯ç¾åœ¨ã®ãƒãƒƒãƒ•ã‚¡ã‚’ä½¿ç”¨ï¼‰
        """
        if trajectory_data is None:
            trajectory_data = list(self.trajectory_buffer)
        
        if not trajectory_data:
            return frame
        
        h, w = frame.shape[:2]
        
        # è»Œè·¡ã‚’ç·šã§æç”»
        points = []
        for i, point in enumerate(trajectory_data):
            if 'landmarks' in point and len(point['landmarks']) >= 63:
                try:
                    # æ‰‹ã®ä¸­å¿ƒä½ç½®ï¼ˆãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯9ç•ªã€ä¸­æŒ‡ã®ä»˜ã‘æ ¹ï¼‰ã‚’ä½¿ç”¨
                    # MediaPipe Hands: 21å€‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ Ã— 3åº§æ¨™(x,y,z) = 63æ¬¡å…ƒ
                    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯9ç•ª: ä¸­æŒ‡ã®ä»˜ã‘æ ¹ â†’ landmarks[27:30] (x, y, z)
                    # æ­£ã—ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: 9ç•ªç›®ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ = landmarks[27:30]
                    x = int(point['landmarks'][27] * w)  # xåº§æ¨™ (27 = 9*3)
                    y = int(point['landmarks'][28] * h)  # yåº§æ¨™ (28 = 9*3+1)
                    points.append((x, y))
                except (IndexError, ValueError) as e:
                    print(f"âš ï¸ è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã®åº§æ¨™å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
        
        # è»Œè·¡ã‚’æç”»
        if len(points) > 1:
            for i in range(1, len(points)):
                # è‰²ã‚’ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§å¤‰åŒ–ï¼ˆå¤ã„ç‚¹ã¯é’ã€æ–°ã—ã„ç‚¹ã¯èµ¤ï¼‰
                color_ratio = i / len(points)
                color = (
                    int(255 * color_ratio),  # B
                    int(255 * (1 - color_ratio)),  # G
                    int(255)  # R
                )
                cv2.line(frame, points[i-1], points[i], color, 2)
            
            # æœ€æ–°ã®ç‚¹ã‚’å¼·èª¿è¡¨ç¤º
            if points:
                cv2.circle(frame, points[-1], 8, (0, 255, 255), -1)
        
        return frame
    
    def cleanup_memory(self):
        """ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ"""
        # è»Œè·¡ãƒãƒƒãƒ•ã‚¡ãŒå¤§ãããªã‚Šã™ããŸå ´åˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if len(self.trajectory_buffer) > self.trajectory_buffer_size * 2:
            print(f"ğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ: ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º {len(self.trajectory_buffer)} -> {self.trajectory_buffer_size}")
            self.trajectory_buffer.clear()
        
        # çµ±è¨ˆæƒ…å ±ã®ãƒªã‚»ãƒƒãƒˆï¼ˆé•·æ™‚é–“ã‚»ãƒƒã‚·ãƒ§ãƒ³å¯¾ç­–ï¼‰
        if self.collection_start_time:
            session_duration = (datetime.now() - self.collection_start_time).total_seconds()
            if session_duration > 3600:  # 1æ™‚é–“ä»¥ä¸Š
                print(f"â° é•·æ™‚é–“ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¤œå‡º: {session_duration:.1f}ç§’")
                print(f"   çµ±è¨ˆæƒ…å ±ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã™")
                self.stats['total_samples'] = 0
                self.stats['total_trajectories'] = 0
                self.collection_start_time = datetime.now()
    
    def get_memory_usage(self) -> Dict:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ã‚’å–å¾—"""
        return {
            'trajectory_buffer_size': len(self.trajectory_buffer),
            'max_buffer_size': self.trajectory_buffer_size,
            'memory_usage_percent': (len(self.trajectory_buffer) / self.trajectory_buffer_size) * 100,
            'session_duration': (datetime.now() - self.collection_start_time).total_seconds() if self.collection_start_time else 0
        }

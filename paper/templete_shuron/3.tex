\newpage
\setcounter{chapter}{3}
\setcounter{section}{0}

\begin{center}
	\vspace{0.5cm}
	\huge{\bf 第3章}
	\par
	\vspace{1cm}
	\hrulefill
	\par
	\vspace{1cm}
	\huge{\bf 提案システム}
	\par
	\vspace{0.5cm}
	\hrulefill
	\vspace{1cm}
	\par
	
	\begin{flushleft}
		\large{{\bf　本章では，運動機能障害者のキーボード入力を支援するために提案するシステムの設計について述べる．}}
	\end{flushleft}
\end{center}

\addcontentsline{toc}{chapter}{\protect\numberline{第3章}{提案システム}}

\newpage

\section{システム概要}

運動機能障害者のキーボード入力を支援するため，卓上カメラを用いた入力意図推定システムを提案する．
本システムは，手の不随意運動等がある場合でも，手指の軌跡からリアルタイムで入力意図を推定し，正確なキーボード入力を可能にすることを目的としている．
また，一般的なWebカメラのみで動作するため，追加ハードウェアなしに低コストで導入できる．
図\ref{fig:system_flow}に示すように，提案システムは5つの処理ステップで構成される．

\begin{figure}[htb]
\centering
\includegraphics[width=0.7\columnwidth]{../figures/system.png}
\caption{提案システムの処理フロー}
\label{fig:system_flow}
\end{figure}

まず，4点キャリブレーションにより作業領域を設定する．
次に，MediaPipe\cite{lugaresi2019mediapipe}を用いて手部ランドマークを検出し，人差し指先端の軌跡データを可変長（5〜90フレーム）で取得する．
取得した軌跡から18次元の動的特徴量を抽出し，学習済みGRU（Gated Recurrent Unit）\cite{cho2014learning}モデルに入力して37クラス（a-z，0-9，スペース）の入力意図を推定する．
結果はTop-3候補とその確率をリアルタイムで画面に表示する．
図\ref{fig:realtime_prediction}にリアルタイム予測画面の例を示す．
システムは各キー入力に対してTop-3候補を確率とともに提示し，ユーザーは第1候補が誤っている場合でも候補から選択できる仕組みとなっている．
以下，各処理ステップについて詳述する．

\begin{figure}[htb]
\centering
\includegraphics[width=\columnwidth]{../figures/realtime_prediction.png}
\caption{リアルタイム予測画面の例}
\label{fig:realtime_prediction}
\end{figure}


\section{座標系の統一と正規化}

カメラの位置や角度，キーボードの種類はユーザーごとに異なる．
そのため，同じキーを指した場合でも画像上の座標は環境によって変化する．
本システムでは，この問題に対処するため，画像座標系とキーボード座標系を統一するキャリブレーションを行う．

\subsection{4点キャリブレーション}

システム起動時，ユーザーはカメラ映像上でキーボードの4隅を順にクリックする．
具体的には，1キーの左上，ハイフンキーの右上，スペースキーの右上，スペースキーの左上の4点を指定する（図\ref{fig:keyboard_mapping}）．
クリックされた画像座標$(x, y)$は，画像の幅$w$と高さ$h$で除算して0-1正規化座標$(x/w, y/h)$に変換される．
これらの4点からキーボード領域の境界（上辺，下辺，左辺，右辺）を求め，その領域を4行（数字行，QWERTY行，ASDF行，ZXCV行）に分割する．
その後，JIS配列テンプレートに基づいて各行のキーオフセットを考慮し，37個のキー（a-z，0-9，スペース）の中心座標とサイズを算出する．

\begin{figure}[htb]
\centering
\includegraphics[width=0.9\columnwidth]{../figures/keyboard_mapping.png}
\caption{4点キャリブレーションによる座標系変換の例}
\label{fig:keyboard_mapping}
\end{figure}

\subsection{作業領域座標系への変換}

算出された37個のキー位置から，全キーの外接矩形を求め，上下左右に1キー分の余白を加えた領域を作業領域として定義する．
このとき作業領域全体を$(0,0)$〜$(1,1)$の範囲に正規化した座標系として扱う．
MediaPipeが出力する手指の正規化座標$(x_{mp}, y_{mp})$は，この作業領域座標系に変換され，$(x_{wa}, y_{wa})$として表現される．
この変換により，異なるカメラ位置や角度においても同じキーが同じ座標として表現され，ユーザーや環境が変わっても同一の学習済みモデルを適用することが可能となる．


\section{MediaPipeによる手指軌跡の取得}

手のランドマーク検出には，Googleが開発したオープンソースのフレームワークであるMediaPipeを使用する．
MediaPipeは軽量で処理速度が速く，一般的なWebカメラでも30fpsでの動作が可能であるため，リアルタイム入力支援に適している．

\subsection{手のランドマーク検出}

本システムでは，MediaPipe Handsモジュールを利用して手のランドマーク検出を行う．
図\ref{fig:hand_landmarks}に示すように，このモジュールはカメラ映像から手の21個のランドマークをリアルタイムに検出する．

\begin{figure}[htb]
\centering
\includegraphics[width=0.9\columnwidth]{../figures/hand_landmarks.png}
\caption{MediaPipe Handsによる手のランドマーク検出（21点）}
\label{fig:hand_landmarks}
\end{figure}

21個のランドマークは，手首（WRIST），親指（THUMB），人差し指（INDEX\_FINGER），中指（MIDDLE\_FINGER），薬指（RING\_FINGER），小指（PINKY）のそれぞれについて，付け根（CMC/MCP），関節（IP/PIP/DIP），先端（TIP）の位置を表す．

\subsection{追跡対象の選定}

これらのランドマークのうち，入力操作に最も関与すると考えられる人差し指の先端（ランドマークポイント8：INDEX\_FINGER\_TIP）を追跡対象とする．
人差し指の先端を選定した理由は，キーボード入力において人差し指は最も頻繁に使用される指の一つであること，指先は手の中で最も移動範囲が大きく入力意図を反映しやすいこと，そしてMediaPipeにおいて指先のランドマークは比較的安定して検出されることによる．
検出された人差し指先端の座標は，前節で定義した正規化座標系に変換される．
変換された座標は毎フレーム記録され，キー押下時に直前5フレーム（約0.17秒，30fps想定）から90フレーム（約3秒）の指先軌跡を時系列データとして取得する．

\subsection{可変長入力への対応}

キー入力の速度はユーザーや入力状況によって大きく異なる．
高速なタイピングでは短い軌跡，慎重な入力では長い軌跡となる．
また，震えを伴う入力では，目標キーに到達するまでに時間がかかる場合がある．
このような多様な入力パターンに対応するため，本システムでは5〜90フレームの可変長入力を許容する設計とした．
固定長に切り詰めたり，パディングで埋めたりするのではなく，実際の軌跡長をそのまま使用することで，入力パターンの多様性を保持する．


\section{震え特性を捉える18次元動的特徴量}

前節で取得した軌跡データから，深層学習モデルによる入力意図推定を高精度で行うために，18次元の動的特徴量を設計した．
本特徴量設計では，従来の静的な座標情報に加えて，手の動きの時間的変化と震え特性を包括的に捉えることで，運動機能障害者特有の複雑な動作パターンからの意図抽出を可能とする．

\subsection{特徴量の構成}

表\ref{tab:feature_structure}に示すように，18次元の特徴量は5つのカテゴリで構成される．

\begin{table}[htb]
\caption{18次元動的特徴量の構成}
\begin{center}
\begin{tabular}{|l|c|} \hline
特徴量カテゴリ & 次元数 \\ \hline \hline
指先の正規化座標 & 2 \\ \hline
最近傍3キーへの相対座標 & 6 \\ \hline
最近傍3キーへの距離 & 3 \\ \hline
速度・加速度 & 4 \\ \hline
振幅・方向転換頻度 & 3 \\ \hline
合計 & 18 \\ \hline
\end{tabular}
\end{center}
\label{tab:feature_structure}
\end{table}

以下，各カテゴリについて詳述する．

\subsection{指先の正規化座標（2次元）}

作業領域内での指先の位置を表す基本的な特徴量である．
4点キャリブレーションにより定義された正規化座標系における$(x, y)$座標を使用する．
この特徴量により，指先がキーボード上のどの位置にあるかを把握できる．

\subsection{最近傍3キーへの相対座標（6次元）}

現在の指先位置から最も近い3つのキーの中心座標への相対位置ベクトル$(dx_i, dy_i)$（$i = 1, 2, 3$）を特徴量とする．
これにより，指先がどのキーに向かっているかの情報を取得できる．
最近傍キーを3つ使用する理由は，震えにより指先位置が揺れ動いた場合でも，候補となる複数のキーへの相対位置を考慮できるためである．
1つのキーのみを考慮した場合，僅かな位置のずれで最近傍キーが入れ替わり，特徴量が不連続に変化する問題が生じる．

\subsection{最近傍3キーへの距離（3次元）}

現在の指先位置から最も近い3つのキーの中心座標までのユークリッド距離$d_i$（$i = 1, 2, 3$）を特徴量とする．
これにより，指先がキーにどの程度近づいているかを定量的に把握できる．
距離特徴量は，キー押下のタイミング判定にも有用である．
距離が閾値以下になった時点でキー押下と判定することで，物理的なキー接触とは独立した入力判定が可能となる．

\subsection{速度・加速度（4次元）}

指先の移動速度$(v_x, v_y)$と加速度$(a_x, a_y)$を特徴量とする．
速度は連続する2フレーム間の座標差分にフレームレート$f$を乗じて計算する．

\begin{equation}
v_x(t) = (x(t) - x(t-1)) \cdot f, \quad v_y(t) = (y(t) - y(t-1)) \cdot f
\end{equation}

加速度は2次差分にフレームレートの2乗を乗じて計算する．

\begin{equation}
a_x(t) = (x(t) - 2x(t-1) + x(t-2)) \cdot f^2, \quad a_y(t) = (y(t) - 2y(t-1) + y(t-2)) \cdot f^2
\end{equation}

これにより，指先の動きの時間的変化を捉えることができる．
健常者の場合は目標キーに向かって滑らかに減速する傾向があるが，震えを伴う場合は速度・加速度の変動が大きくなる．
この違いを学習することで，震えを伴う入力からでも意図を推定できる可能性がある．

\subsection{振幅・方向転換頻度（3次元）}

震えの特性を定量化するため，過去10フレームの座標変動から算出する特徴量を設計した．
振幅は，過去10フレームの座標変動の標準偏差として定義する．
\begin{equation}
\text{amplitude}_x = \sqrt{\frac{1}{N}\sum_{i=1}^{N}(x_i - \bar{x})^2}
\end{equation}
\begin{equation}
\text{amplitude}_y = \sqrt{\frac{1}{N}\sum_{i=1}^{N}(y_i - \bar{y})^2}
\end{equation}

ここで，$N$は過去フレーム数（本システムでは10），$\bar{x}, \bar{y}$はそれぞれ$x, y$座標の平均値である．

方向転換頻度は，x方向速度の符号変化の頻度として定義する．
過去10フレームのx方向速度について，隣接する2フレーム間で符号が変化した回数をカウントし，最大可能変化回数（フレーム数-1）で正規化する．
ただし，速度が0の場合を除外する．

\begin{equation}
\text{direction\_change} = \frac{1}{N-1}\sum_{i=1}^{N-1}\mathbb{1}[\text{sign}(v_x(i)) \neq \text{sign}(v_x(i-1)) \land \text{sign}(v_x(i-1)) \neq 0]
\end{equation}

ここで，$\mathbb{1}[\cdot]$は指示関数であり，条件が真のとき1，偽のとき0を返す．
符号変化とは，前フレームが正（負）で現在フレームが負（正）になることを意味する．
速度が0の場合を除外するのは，停止状態から動き出す瞬間を方向転換としてカウントしないためである．
これらの震え特性特徴量により，個々のユーザーの震えパターンを定量化する．
震え除去を行わずに生の軌跡から直接学習することで，重要な意図情報の損失を防ぎつつ，ロバストな入力意図推定を実現する．


\section{GRUモデルによる入力意図推定}

前節で設計した18次元の動的特徴量シーケンスから入力意図を推定するため，本研究ではGRUを採用した．

\subsection{GRUの選定理由}

指先の軌跡は時間的に連続した動きであり，震えを含む複雑な動作パターンから入力意図を推定するには時間的な文脈を学習できるモデルが必要である．
再帰型ニューラルネットワーク（RNN）の一種であるGRUは，このような時系列データの処理に適している．
GRUを選定した理由は，GRUがLong Short-Term Memory（LSTM）\cite{hochreiter1997long}と同等の長期依存関係学習能力を持ちながらパラメータ数が少なく学習・推論ともに高速であること，リアルタイム処理が求められる入力支援システムにおいて推論速度は重要な要素であること，そして先行研究においても手の動作認識タスクにおいてGRUが良好な性能を示していることによる．
なお，LSTM，1次元畳み込みニューラルネットワーク（CNN），Temporal Convolutional Network（TCN）\cite{bai2018empirical}との比較検証については第4章で述べる．

\subsection{GRUの構造}

GRUは，更新ゲート$z_t$とリセットゲート$r_t$の2つのゲート機構を持つ．
時刻$t$における隠れ状態$h_t$は，以下の式で計算される．

\begin{equation}
z_t = \sigma(W_z x_t + U_z h_{t-1} + b_z)
\end{equation}
\begin{equation}
r_t = \sigma(W_r x_t + U_r h_{t-1} + b_r)
\end{equation}
\begin{equation}
\tilde{h}_t = \tanh(W_h x_t + U_h (r_t \odot h_{t-1}) + b_h)
\end{equation}
\begin{equation}
h_t = (1 - z_t) \odot h_{t-1} + z_t \odot \tilde{h}_t
\end{equation}

ここで，$\sigma$はシグモイド関数，$\odot$は要素ごとの積，$W, U, b$はそれぞれ重み行列とバイアスである．
更新ゲート$z_t$は，過去の情報をどの程度保持するかを制御し，リセットゲート$r_t$は，過去の情報をどの程度無視するかを制御する．
これらのゲート機構により，長期的な依存関係と短期的な変化の両方を適切に学習できる．

\subsection{モデルアーキテクチャ}

採用したGRUモデルは以下の層で構成される．
入力層は18次元の特徴量ベクトル（可変長シーケンス）を受け取る．
GRU層は2層構成で，隠れ層は128次元，ドロップアウト率は0.2とした．
全結合層は128次元から64次元を経て37次元へと変換する．
出力層は37クラス（a-z，0-9，スペース）に対するソフトマックス出力である．
可変長入力への対応として，PyTorchのPackedSequence機能を使用し，バッチ内の異なる長さのシーケンスを効率的に処理できる．

\subsection{学習設定}

モデルの学習には以下の設定を使用した．
損失関数はクロスエントロピー損失，最適化手法はAdam（学習率0.001），バッチサイズは32，エポック数は100（早期終了あり）とした．
訓練データ，検証データ，テストデータの分割比は6:2:2である．
過学習を防ぐため，ドロップアウト（率0.2）と早期終了（patience=5）を適用した．
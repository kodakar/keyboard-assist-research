\newpage
\setcounter{chapter}{4}
\setcounter{section}{0}

\begin{center}
	\vspace{0.5cm}
	\huge{\bf 第4章}
	\par
	\vspace{1cm}
	\hrulefill
	\par
	\vspace{1cm}
	\huge{\bf 評価実験}
	\par
	\vspace{0.5cm}
	\hrulefill
	\vspace{1cm}
	\par
	
	\begin{flushleft}
		\large{{\bf　本章では，モデル比較実験による最適モデルの選定と，選定したモデルを用いた実用性評価実験の設計および結果について述べる．}}
	\end{flushleft}
\end{center}

\addcontentsline{toc}{chapter}{\protect\numberline{第4章}{評価実験}}

\newpage

\section{評価の目的と概要}

提案システムの性能を検証するため，モデル比較実験と実用性評価実験の2段階で評価を実施した．
モデル比較実験では，入力意図推定に適したモデルの選定を目的として，事前に収集したデータセットを用いてGRU，LSTM，CNN，TCNの4種類のモデルについて比較評価を行った．オフライン評価と研究者本人による予備的なリアルタイム評価の結果に基づき，GRUを最適モデルとして選定した．
選定したGRUモデルを用いた実用性評価実験では，健常者10名を対象に入力実験を実施し，システムの実用性を検証した．


\section{実験環境}

評価実験に使用した環境を表\ref{tab:exp_env}に示す．
モデルの学習にはGPUを使用し，CUDA対応版のPyTorchで実施した．
図\ref{fig:data_collection_setup}にデータ収集時の実験環境を示す．

\begin{table}[htb]
\caption{実験環境}
\begin{center}
\begin{tabular}{|l|l|} \hline
項目 & 内容 \\ \hline \hline
OS & Windows 11 \\ \hline
CPU & Intel Core i7-14700 (2.10 GHz) \\ \hline
メモリ & 32GB \\ \hline
GPU & NVIDIA GeForce RTX 4070 Ti Super \\ \hline
プログラミング言語 & Python 3.10 \\ \hline
深層学習フレームワーク & PyTorch 2.0 (CUDA対応) \\ \hline
手認識ライブラリ & MediaPipe 0.10 \\ \hline
画像処理ライブラリ & OpenCV 4.11 \\ \hline
カメラ & Webカメラ（640×480, 30fps） \\ \hline
\end{tabular}
\end{center}
\label{tab:exp_env}
\end{table}

\begin{figure}[htb]
\centering
\includegraphics[width=0.8\columnwidth]{../figures/data_collection_setup.png}
\caption{データ収集の実験環境}
\label{fig:data_collection_setup}
\end{figure}


\section{モデル比較実験}

\subsection{データセット}

モデル比較実験には，研究者本人が収集したデータセットを使用した．
入力テキストには，37種類の文字が均等に含まれるランダム文字列を使用した．
ランダム文字列を採用した理由は，言語モデルによる文脈予測の影響を排除し，システム単体の純粋なキーストローク認識能力を評価するためである．
10種類のランダム文字列（シード0-9）を各5回ずつ入力し，合計4,750サンプルのデータセットを構築した．
データセットは訓練用（60\%），検証用（20\%），テスト用（20\%）に分割した．

\subsection{比較モデル}

GRU（2層構成，隠れ層128次元），LSTM（2層構成，隠れ層128次元），CNN（3層畳み込み，カーネルサイズ3），TCN（3層構成，dilation factor 1, 2, 4）の4種類を比較した．
すべてのモデルは同一のデータセット，同一のハイパーパラメータ（学習率0.001，バッチサイズ32，エポック数100，早期終了patience 5）で学習した．

\subsection{オフライン評価結果}

表\ref{tab:offline_results}にテストセットを用いたオフライン評価の結果を示す．
GRUがTop-1精度98.00\%と最も高い性能を達成した．
また，GRUはパラメータ数が約167Kと4モデル中最小であり，計算コストも低い．

\begin{table}[htb]
\caption{モデル別オフライン評価結果}
\begin{center}
\begin{tabular}{|l|c|c|c|} \hline
モデル & パラメータ数 & Top-1精度 & Top-3精度 \\ \hline \hline
GRU & 約167K & \textbf{98.00\%} & \textbf{99.89\%} \\ \hline
LSTM & 約219K & 97.47\% & 99.89\% \\ \hline
CNN & 約169K & 93.58\% & 99.47\% \\ \hline
TCN & 約209K & 94.21\% & 99.47\% \\ \hline
\end{tabular}
\end{center}
\label{tab:offline_results}
\end{table}

図\ref{fig:learning_curves}にGRUモデルの学習曲線を示す．
訓練損失と検証損失が安定して収束しており，過学習を起こさず適切に学習できていることが確認できる．

\begin{figure}[htb]
\centering
\includegraphics[width=\columnwidth]{../figures/learning_curves.png}
\caption{GRUモデルの学習曲線}
\label{fig:learning_curves}
\end{figure}

図\ref{fig:confusion_matrix}にGRUモデルの混同行列を示す．
対角成分が高く，ほとんどのクラスで高い認識精度を達成している．
一部の隣接キー（d-f，o-0など）間で誤認識が見られるものの，全体として優れた識別性能を示した．

\begin{figure}[htb]
\centering
\includegraphics[width=\columnwidth]{../figures/confusion_matrix.png}
\caption{GRUモデルの混同行列（テストセット）}
\label{fig:confusion_matrix}
\end{figure}


\subsection{予備的リアルタイム評価結果}

研究者本人による予備的なリアルタイム評価を行った結果を表\ref{tab:realtime_preliminary}に示す．
GRUがTop-1精度100.0\%と完璧な認識精度を実現した．
一方，CNNとTCNはリアルタイム環境で性能が大幅に低下した．
これは，畳み込み層による局所的な特徴抽出が，可変長の時系列パターン全体を捉える上で不十分であったためと考えられる．
図\ref{fig:model_comparison}にオフライン評価とリアルタイム評価の比較を示す．

\begin{table}[htb]
\caption{モデル別予備的リアルタイム評価結果}
\begin{center}
\begin{tabular}{|l|c|c|} \hline
モデル & Top-1精度 & Top-3精度 \\ \hline \hline
GRU & \textbf{100.0\%} & \textbf{100.0\%} \\ \hline
LSTM & 81.8\% & 100.0\% \\ \hline
CNN & 36.4\% & 90.9\% \\ \hline
TCN & 63.6\% & 72.7\% \\ \hline
\end{tabular}
\end{center}
\label{tab:realtime_preliminary}
\end{table}


\begin{figure}[htb]
\centering
\includegraphics[width=\columnwidth]{../figures/model_comparison.png}
\caption{モデル別性能比較（オフライン vs リアルタイム）}
\label{fig:model_comparison}
\end{figure}

\subsection{モデル選定}

モデル比較実験の結果に基づき，入力意図推定モデルとしてGRUを採用した．
GRUを選択した理由は，オフライン評価・リアルタイム評価ともに最高精度を達成したこと，パラメータ数が最小で計算効率が高いこと，時系列データの長期依存関係を適切に学習できることである．


\section{実用性評価実験}

\subsection{実験参加者}

実験参加者は20代の健常男性10名である．
全員がキーボード入力に習熟しており，タッチタイピングが可能である．
本研究では，運動機能障害者を直接の実験参加者とすることが倫理的・実務的に困難であったため，健常者による評価を行った．
ただし，震えを伴う入力の評価として，実験参加者に振戦を模擬した入力を行わせる条件を設けた．

\subsection{入力条件}

評価には通常入力と振戦模擬入力の2種類の入力条件を設定した．
通常入力条件では，実験参加者に「丁寧かつ正確に入力してください」と指示し，標準的な使用状況下でのシステム性能を評価した．
振戦模擬入力条件では，実験参加者に「目標キーに向かって指を動かした後，押下直前にわざと手を動かして別のキーを押してください」と指示した．
これにより，振戦による誤入力を模擬した条件下でのシステムの頑健性を検証した．
振戦模擬入力は実際の運動機能障害者の入力パターンを完全に再現するものではないが，震えにより意図しないキーが押下される状況を近似的に評価できる．

\subsection{入力タスク}

入力タスクには，37種類の全文字が均等に含まれるランダム文字列を使用した．
各実験参加者は，通常入力条件と振戦模擬入力条件のそれぞれで，この文字列を1回入力した．

\subsection{評価指標}

実用性評価実験では，Top-1精度とTop-3精度を主要な評価指標として使用した．
振戦模擬入力条件では，追加の評価指標として誤入力発生率（実際に押下されたキーが意図したキーと異なる割合）と救済率（誤入力が発生した試行においてシステムが正しい意図を推定できた割合）を測定した．
救済率は，振戦により誤ったキーを押してしまった場合に，システムがどの程度正しい意図を推定できるかを示す指標であり，本システムの実用性を評価する上で重要な指標である．

\subsection{入力条件別性能}

表\ref{tab:realtime_results}に実験参加者10名の平均性能を示す．
通常入力ではTop-1精度83.8\%，Top-3精度97.6\%を達成した．
振戦模擬入力ではTop-1精度64.9\%，Top-3精度90.0\%であった．
図\ref{fig:condition_comparison}に入力条件別の精度比較を示す．

\begin{table}[htb]
\caption{入力条件別性能評価（実験参加者10名の平均）}
\begin{center}
\begin{tabular}{|l|c|c|} \hline
入力条件 & Top-1精度 & Top-3精度 \\ \hline \hline
通常入力 & 83.8\% & 97.6\% \\ \hline
振戦模擬入力 & 64.9\% & 90.0\% \\ \hline
\end{tabular}
\end{center}
\label{tab:realtime_results}
\end{table}

\begin{figure}[htb]
\centering
\includegraphics[width=\columnwidth]{../figures/condition_comparison.png}
\caption{入力条件別精度比較}
\label{fig:condition_comparison}
\end{figure}

\subsection{振戦模擬入力における救済率}

振戦模擬入力条件では，実験参加者の操作により全試行の96.5\%で物理的な誤入力（隣接キー等の押下）が発生した．
このような状況下でも，システムはTop-1精度64.9\%を達成した．
これは実質的に，誤入力が発生した際にシステムが自動的に正しい意図を推定できた割合（救済率65.0\%）を示している．
図\ref{fig:rescue_rate_distribution}に救済率の分布を示す．
また，Top-3精度は90.0\%を維持しており，自動補正が外れた場合でも9割の確率で候補から正解を選択可能である．

\begin{figure}[htb]
\centering
\includegraphics[width=\columnwidth]{../figures/rescue_rate_distribution.png}
\caption{救済率の分布}
\label{fig:rescue_rate_distribution}
\end{figure}


\subsection{実験参加者別結果}

図\ref{fig:participant_comparison}に実験参加者別のTop-1精度を示す．
通常入力のTop-1精度は実験参加者間で64.9\%〜97.3\%の範囲であり，比較的安定した性能を示した．
振戦模擬入力では40.5\%〜81.1\%の範囲となり，実験参加者間のばらつきが大きくなった．
これは，振戦の模擬方法が実験参加者によって異なることに起因すると考えられる．

\begin{figure}[htb]
\centering
\includegraphics[width=\columnwidth]{../figures/participant_comparison.png}
\caption{実験参加者別Top-1精度}
\label{fig:participant_comparison}
\end{figure}


\subsection{軌跡の可視化}

図\ref{fig:trajectory_isomura}および図\ref{fig:trajectory_furuta}に，振戦模擬入力時の実際の指先軌跡の可視化例を示す．
図\ref{fig:trajectory_isomura}では，目標キーである「h」キーに向かって移動した後，押下直前に「g」キーを押している．
しかし軌跡の大部分は「h」キーに向かっているため，システムは正しく「h」キーと推定できている．
図\ref{fig:trajectory_furuta}も同様に，軌跡の全体的な動きから正しい入力意図を読み取れていることが確認できる．
このように，システムは軌跡全体のパターンから，押下直前の急激な動きが誤入力であることを判断できる．

\begin{figure}[htb]
\centering
\includegraphics[width=\columnwidth]{../figures/trajectory_isomura.png}
\caption{実験参加者Aの軌跡可視化例}
\label{fig:trajectory_isomura}
\end{figure}

\begin{figure}[htb]
\centering
\includegraphics[width=\columnwidth]{../figures/trajectory_furuta.png}
\caption{実験参加者Bの軌跡可視化例}
\label{fig:trajectory_furuta}
\end{figure}

\clearpage
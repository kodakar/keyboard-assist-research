\newpage
\setcounter{chapter}{2}
\setcounter{section}{0}

\begin{center}
	\vspace{0.5cm}
	\huge{\bf 第2章}
	\par
	\vspace{1cm}
	\hrulefill
	\par
	\vspace{1cm}
	\huge{\bf 関連研究}
	\par
	\vspace{0.5cm}
	\hrulefill
	\vspace{1cm}
	\par
	
	\begin{flushleft}
		\large{{\bf　本章では，本研究に関連する既存研究について述べ，本研究の位置づけを明確にする．}}
	\end{flushleft}
\end{center}

\addcontentsline{toc}{chapter}{\protect\numberline{第2章}{関連研究}}

\newpage

\section{運動機能障害者向けの入力支援技術}

運動機能障害を持つ人々向けの入力支援技術としては，音声入力，視線入力，特殊ハードウェア，カメラベースの手認識など，様々なアプローチが開発されている．本節では，これらの技術の特徴と課題について概観する．

\subsection{音声入力}

音声入力はDragon NaturallySpeaking等に代表され，広く普及している入力支援技術である\cite{webaim2023motor}．
音声認識技術の発展により，健常者にとっては高い認識精度が実現されており，ハンズフリーでの入力が可能である点が大きな利点である．

しかし，脳性麻痺など構音障害を伴う場合には，発話の明瞭度が低下するため正確な認識が困難となる．
また，音声入力は周囲の騒音の影響を受けやすく，オフィスや公共の場での使用には制約がある．
さらに，プログラミングのような記号や特殊文字を多用する作業においては，音声での入力が煩雑になるという課題もある．

\subsection{視線入力}

視線入力は，目の動きを追跡してカーソル操作や文字入力を行う技術である．
Tobii社がALSや脳性麻痺患者向けの視線追跡デバイスを開発しており\cite{cerebralpalsy2023tobii}，重度の運動障害者に有効な手段となっている．
四肢の運動機能が著しく制限されている場合でも，目の動きが保たれていれば入力が可能であるため，重度障害者にとって貴重な選択肢である．

Gizatdinovaら\cite{gizatdinova2023vision}は視線入力とヘッド入力（頭部の動きによる入力）を比較評価し，ヘッド入力は高精度だが入力速度が遅く，視線入力は高速だが精度が劣るという特有の課題を報告している．
また，視線追跡デバイスは数十万円と高価であり，個人ごとのキャリブレーションにも専門的な調整を要するため，導入のハードルが高いという問題がある．

\subsection{特殊ハードウェア}

特殊ハードウェアによる入力支援としては，適応キーボード，マウススティック，ヘッドポインタなどがある\cite{reciteme2025assistive}．
適応キーボードは，キーの大きさや配置を変更したり，キーガードを設置したりすることで，誤入力を減らすことを目的としている．
マウススティックやヘッドポインタは，口や頭部でポインティングデバイスを操作することで，上肢の機能が制限されている場合でも入力を可能にする．

これらの特殊ハードウェアは物理的なアクセシビリティを向上させるが，特定の姿勢や設置環境を前提とするため汎用性に欠ける．
また，外出先や異なる環境での使用が困難であり，社会参加の障壁となる場合がある．

Cossovichら\cite{cossovich2023co}は運動機能障害者へのインタビュー調査を通じて，多くのユーザーが大衆向けに設計された既存デバイスで我慢している現状を報告している．
この調査では，ユーザーが自身の障害特性に合った入力デバイスを見つけることの困難さや，適切な支援技術へのアクセスの問題が指摘されており，より適切な入力支援技術の開発が求められている．


\section{カメラベースの手認識技術}

カメラベースの手認識技術は，追加ハードウェアなしに手の動きを認識できる可能性があり，低コストでの導入が期待できるアプローチである．
近年の深層学習技術の発展により，高精度な手認識が実現されつつある．

\subsection{手認識フレームワーク}

Googleが開発したMediaPipe\cite{lugaresi2019mediapipe}は，リアルタイムの知覚パイプラインを構築するためのオープンソースフレームワークである．
特にMediaPipe Hands\cite{zhang2020mediapipe}モジュールは，単一のRGBカメラから手の21個のランドマークをリアルタイムに検出することができる．
このフレームワークは軽量で処理速度が速く，一般的なWebカメラでも30fps以上での動作が可能であるため，リアルタイムアプリケーションに適している．

MediaPipeの手認識は，手のひら検出と手のランドマーク検出の2段階で構成される．
まず，手のひら検出モデルが画像中の手の位置を特定し，次にランドマーク検出モデルが検出された手領域から21個のランドマーク座標を推定する．
この2段階アプローチにより，高速かつ高精度な手認識が実現されている．

\subsection{手認識の応用研究}

カメラベースの手認識技術は，様々な応用分野で研究が進められている．

運動機能障害者向けの応用として，Pradeepら\cite{pradeep2025real}はWebカメラによる顔追跡とニューラルネットワークを組み合わせたハンズフリーマウス制御システムを開発し，運動機能障害者が頭部の動きでマウスカーソルを操作できることを実証した．
このシステムは追加ハードウェアなしに実現可能であり，低コストでの導入が可能である点が評価されている．

手話認識の分野では，Abdallahら\cite{abdallah2022light}がMediaPipeとGRU/CNNを組み合わせたシステムを開発し，99.84\%の認識精度を達成した．
この研究では，MediaPipeで抽出した手のランドマーク座標を時系列データとして深層学習モデルに入力することで，高精度な手話認識を実現している．

また，Leら\cite{le2023real}はYOLOv7による一人称視点からの手動作検出システムを開発し，95\%以上の検出精度を報告している．
一人称視点からの手動作検出は，ウェアラブルデバイスやスマートグラスなどへの応用が期待されている．

\subsection{仮想キーボードへの応用}

カメラベースの手認識技術をキーボード入力に応用する研究も進められている．

代表的な研究として，Mallikら\cite{mallik2024virtual}はMediaPipe HolisticとLong Short-Term Memory（LSTM）\cite{hochreiter1997long}を組み合わせた仮想キーボードシステムを実装し，97\%の認識精度を達成した．
このシステムでは，カメラで撮影した手の動きから指先の位置を検出し，仮想的に表示されたキーボード上でのタイピングを認識する．

多言語対応の観点からは，Rahimら\cite{rahimadvanced}が1D CNNとBi-GRUを組み合わせたCronoNetアーキテクチャにより，多言語対応の仮想キーボードを開発した．
このシステムは，英語だけでなく複数の言語に対応しており，グローバルな利用を想定している．

しかし，これらの研究は健常者の安定した動作を前提としており，震えや不随意運動を伴う入力への対応は考慮されていない．
運動機能障害者がこれらのシステムを利用するためには，不規則な動作パターンからでも入力意図を推定できる手法が必要となる．


\section{震え補正と運動意図推定}

運動機能障害に伴う震えの補正技術と，時系列データからの運動意図推定に関する研究について概観する．

\subsection{震え補正技術}

運動機能障害に伴う震えの補正技術については，信号処理や機械学習を用いた研究が進められている．

適応フィルタを用いたアプローチとして，Araújoら\cite{araujo2023analysis}は生理的振戦とパーキンソン病による病的振戦の両方に対してFx-LMS（Filtered-x Least Mean Square）アルゴリズムを評価し，特に病的振戦に対して優れた補正性能を示した．
この研究では，適応フィルタを用いて振戦成分を推定・除去することで，より滑らかな運動軌跡を得ることを目指している．

深層学習との組み合わせでは，Wuら\cite{wu2022visual}がLeap Motionセンサーを用いたジェスチャー予測において，Kalmanフィルタによる震え補正とLSTM-RNN（Recurrent Neural Network）の組み合わせにより99.31\%の精度を達成している．
Kalmanフィルタは，観測値に含まれるノイズを除去しつつ，状態の推定を行う手法であり，震え補正に広く用いられている．

一方，振戦の評価に焦点を当てた研究もある．
Wolkeら\cite{wolke2025validity}はMediaPipeを用いた振戦の定量的評価手法を提案し，スマートフォンカメラでも臨床的に有効な精度が得られることを示した．
この研究は，特殊な機器を用いずに振戦の評価が可能であることを示しており，医療現場での応用が期待されている．

リハビリテーションへの応用として，Neogら\cite{neog2024hand}は3D手部ランドマーク検出を用いた手機能評価システムにより，仮想環境でのリハビリテーション効果を示した．
このシステムでは，手の動きを定量的に評価することで，リハビリテーションの進捗を客観的に把握することができる．

これらの研究では，震えを信号処理により除去または補正するアプローチが主流である．
しかし，フィルタリングにより震えを除去すると，震えに含まれる本来の入力意図に関する情報まで失われる可能性がある．
また，震えを補正すべきノイズとして扱う研究が多く，震えを個人の特性として学習するアプローチは十分に検討されていない．

\subsection{運動意図推定}

時系列データからの運動意図推定では，LSTMやGRUなどの再帰型ニューラルネットワーク（RNN）が広く用いられている．

LSTMは，長期的な依存関係を学習できるRNNの一種であり，時系列データの処理に広く用いられている．
LSTMは入力ゲート，忘却ゲート，出力ゲートの3つのゲート機構を持ち，長期記憶と短期記憶を適切に制御することで，長い時系列データからの学習を可能にしている．

GRU（Gated Recurrent Unit）\cite{cho2014learning}は，LSTMを簡略化したモデルであり，更新ゲートとリセットゲートの2つのゲート機構を持つ．
GRUはLSTMと同等の長期依存関係学習能力を持ちながら，パラメータ数が約24\%少なく，学習・推論ともに高速である．
このため，リアルタイム処理が求められるアプリケーションに適している．

これらのモデルを用いた意図推定の応用例として，Leiら\cite{lei2022intention}はロボット車椅子のナビゲーションにおいて意図予測ベースの共有制御システムを提案し，脳性麻痺患者において従来手法より約30\%タスク完了時間を短縮した．
この研究では，ユーザーの操作意図を予測することで，より自然で効率的な車椅子操作を実現している．

同様に，Yangら\cite{yang2023learning}はRNNを用いて上肢の運動開始を予測し，支援ロボットの制御に応用した．
運動開始の予測は，支援ロボットがユーザーの動作に先行して準備を行うことを可能にし，より自然な支援を実現する．

しかし，これらの意図推定研究は特殊センサーやロボットアームを前提としており，汎用カメラを用いたキーボード入力支援への適用例は見られない．


\section{本研究の位置づけ}

前節までに述べたように，既存の入力支援技術にはそれぞれ課題がある．
音声入力は構音障害を伴う場合に利用できず，騒音環境での使用にも制約がある．
視線入力は高コストであり，専門的なキャリブレーションを要する．
特殊ハードウェアは特定の環境を前提とし，汎用性に欠ける．
カメラベースの手認識技術は低コストで実現可能だが，健常者の安定した動作を前提としている．
震え補正技術は震えをノイズとして除去するアプローチが主流であり，入力意図に関する情報が失われる可能性がある．

これらの課題を踏まえ，本研究では，汎用カメラのみを用いて，運動機能障害者の震えを含む手指の軌跡から入力意図を推定するシステムを提案する．
本研究の特徴は以下の3点である．

第一に，震えを除去せず生の軌跡から深層学習モデルで直接学習することで，震えに含まれる動作特性も活用して入力意図を推定する点である．
これにより，フィルタリングによる情報損失を回避し，より正確な意図推定が期待できる．

第二に，一般的なWebカメラのみで動作するため，追加ハードウェアなしに低コストで導入できる点である．
高価な視線追跡デバイスや特殊なセンサーを必要とせず，既存のPC環境にそのまま導入可能である．

第三に，MediaPipeによる手部ランドマーク検出と，震えの特性を含む18次元の動的特徴量設計，およびGRUによる時系列解析を組み合わせることで，運動機能障害者の不規則な動作パターンに対応できる点である．
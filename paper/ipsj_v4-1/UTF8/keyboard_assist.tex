%%
%% 研究報告用スイッチ
%% [techrep]
%%
%% 欧文表記無しのスイッチ(etitle,eabstractは任意)
%% [noauthor]
%%

%\documentclass[submit,techrep]{ipsj}
\documentclass[submit,techrep,noauthor]{ipsj}



\usepackage[dvipdfmx]{graphicx}
\usepackage{latexsym}
\usepackage{url}

\def\Underline{\setbox0\hbox\bgroup\let\\\endUnderline}
\def\endUnderline{\vphantom{y}\egroup\smash{\underline{\box0}}\\}
\def\|{\verb|}
%

%\setcounter{巻数}{59}%vol59=2018
%\setcounter{号数}{10}
%\setcounter{page}{1}


\begin{document}


\title{卓上カメラによる指先動作認識を用いた\\運動機能障害者のためのAIキーボード入力支援システム}

\etitle{AI Keyboard Input Assistance System for Individuals\\with Motor Disabilities Using Finger Motion Recognition via a Tabletop Camera}

\affiliate{IWAI}{東京電機大学 未来科学部 情報メディア学科\\
Department of Information and Media Sciences, School of Future Sciences, Tokyo Denki University}


\author{小高 大和}{Yamato Kodaka}{IWAI}[kodaka@example.com]
\author{岩井 将行}{Masayuki Iwai}{IWAI}

\begin{abstract}
運動機能障害者における手指の震えや不随意運動は，従来のキーボード入力を困難にし，デジタルアクセスの格差を生む要因となっている．
本研究では，汎用的な卓上USBカメラのみを用いて手指動作から入力意図を推定するシステムを提案する．
提案システムでは，MediaPipeによる手部ランドマーク検出を基盤とし，位置座標，速度，加速度，震えの振幅や方向転換頻度など18次元の動的特徴量を抽出することで運動特性を定量化した．
これらの特徴量を可変長に対応したGRUモデルに入力し，37クラスのキー入力意図を推定するアーキテクチャを構築した．
評価実験において，オフラインでTop-1精度98.0\%，リアルタイム環境で丁寧な入力時に91.9\%を達成した．
特に，震えを伴う入力では79.1\%で誤入力が発生したが，そのうち73.5\%で手指軌跡から正しい意図を推定でき，不随意運動下における入力補正の有効性が確認された．
本システムは追加ハードウェアを必要とせず，低コストで運動機能障害者のデジタルアクセシビリティ向上に貢献する．
\end{abstract}


%
%\begin{jkeyword}
%情報処理学会論文誌ジャーナル，\LaTeX，スタイルファイル，べからず集
%\end{jkeyword}
%
%\begin{eabstract}
%This document is a guide to prepare a draft for submitting to IPSJ
%Journal, and the final camera-ready manuscript of a paper to appear in
%IPSJ Journal, using {\LaTeX} and special style files.  Since this
%document itself is produced with the style files, it will help you to
%refer its source file which is distributed with the style files.
%\end{eabstract}
%
%\begin{ekeyword}
%IPSJ Journal, \LaTeX, style files, ``Dos and Dont's'' list
%\end{ekeyword}

\maketitle

%1
\section{はじめに}

パソコンやスマートフォンなどの情報機器は，現代社会において不可欠なコミュニケーション手段である．
しかし，脳性麻痺，本態性振戦，パーキンソン病などの神経疾患や加齢に伴う運動機能の低下により，手の震えや不随意運動を持つ人々にとって，キーボードによる正確な文字入力は困難であり，デジタル社会への参加を阻む障壁となる．

運動機能障害者向けの入力支援技術として，音声入力\cite{webaim2023motor}，視線入力\cite{cerebralpalsy2023tobii}，特殊キーボード\cite{reciteme2025assistive}などが開発されてきた．
しかし，音声入力は構音障害を伴う場合に利用できず，視線入力や特殊デバイスは高価で導入のハードルが高い．
また，これらの技術は個人の障害特性に合わせた調整が必要であり，手軽に利用を開始できないという課題がある．

そこで本研究では，汎用的な卓上カメラのみを用いて，手指の動きから入力意図を推定するシステムを提案する．
提案システムは，MediaPipe\cite{lugaresi2019mediapipe,zhang2020mediapipe}による手部ランドマーク検出を基盤とし，震えの特性を含む18次元の動的特徴量を抽出する．
これをGated Recurrent Unit（GRU）\cite{cho2014learning}モデルに入力し，震えを伴う軌跡からでも正しい入力意図を推定することで，追加ハードウェアなしに運動機能障害者のキーボード入力を支援する．


%2
\section{関連研究}

%2.1
\subsection{運動機能障害者向けの入力支援技術}

運動機能障害者を対象とした入力支援の研究は多岐にわたる．
音声認識による入力支援\cite{webaim2023motor}は広く普及しているが，脳性麻痺など構音障害を伴う場合には適用が困難である．
Tobii社の視線追跡デバイス\cite{cerebralpalsy2023tobii}はALSや重度の運動障害者に有効だが，高価格と専門的な調整が必要となる．
適応キーボードやマウススティック\cite{reciteme2025assistive}は物理的なアクセシビリティを向上させるが，導入コストと環境依存性が課題である．
Cossovichら\cite{cossovich2023co}は運動機能障害者との共同設計を通じて，既存デバイスが個々の障害特性に適合しにくい実態を報告している．

一方，カメラベースの手認識技術は追加ハードウェアなしに実現できる可能性がある．
Abdallahら\cite{abdallah2022light}はMediaPipeと深層学習を組み合わせ，手話認識で99.84\%の精度を達成した．
Mallikら\cite{mallik2024virtual}はMediaPipe HolisticとLSTMにより仮想キーボードを実装し，97\%の認識精度を報告している．
Rahimら\cite{rahimadvanced}は1D CNNとBi-GRUを組み合わせたCronoNetで多言語対応の仮想キーボードを開発した．
しかし，これらの研究は健常者を対象としており，震えや不随意運動への対応は考慮されていない．

%2.2
\subsection{震え補正と運動意図推定}

運動機能障害に伴う震えの補正技術については，信号処理や機械学習を用いた研究が進められている．
Araújoら\cite{araujo2023analysis}はFx-LMSアルゴリズムにより病的振戦の補正を実現した．
Wuら\cite{wu2022visual}はLeap MotionセンサーとLSTM-RNNを組み合わせ，Kalmanフィルタによる震え補正を施したジェスチャー予測で99.31\%の精度を達成している．
Wolkeら\cite{wolke2025validity}はMediaPipeを用いた振戦の定量的評価手法を提案し，医療分野での有効性を示した．

時系列データからの運動意図推定では，Long Short-Term Memory（LSTM）\cite{hochreiter1997long}やGated Recurrent Unit（GRU）\cite{cho2014learning}などの再帰型ニューラルネットワークが広く用いられている．
Yangら\cite{yang2023learning}はRNNを用いて上肢の運動意図を予測し，支援ロボットの制御に応用した．
しかし，これらの研究は特殊センサーやロボットアームを前提としており，汎用カメラによるキーボード入力支援への適用例は少ない．

%2.3
\subsection{本研究の位置づけ}

既存の入力支援技術は，高コスト，専用機器の必要性，健常者を対象とした設計という課題を抱えている．
本研究は，汎用的な卓上カメラのみを用いて手指の動きから入力意図を推定するシステムを提案する．
MediaPipeによる手部ランドマーク検出を基盤とし，震えの特性を含む動的特徴量を抽出してGRUモデルに入力することで，震えを伴う軌跡からでも正しい入力意図を推定する．
追加ハードウェアを必要とせず，低コストで導入可能な点が既存技術との差異である．


%3
\section{提案システム}

運動機能障害者のキーボード入力を支援するため，カメラを用いた入力意図推定システムを提案する．
本システムは，手の震えや不随意運動の影響を受けやすいユーザーに対し，
リアルタイムでの入力予測と補正を行い，日常的なPC操作における入力精度を向上させることを目的とする．
最終的には，一般的なWebカメラのみを使用し，追加のハードウェアなしに動作する実用的なシステムの実現を目指す．

%3.1
\subsection{システム概要}

図\ref{fig:system}に示すように，提案システムは
（1）4点キャリブレーションによる作業領域設定，
（2）手の軌跡データ取得，
（3）動的特徴量抽出，
（4）深層学習モデルによる入力意図推定，
（5）リアルタイム予測表示
の5つのコンポーネントで構成される．

処理フローは，まずカメラから手の映像を取得し，4点キャリブレーションにより設定した作業領域座標系に変換する．
次に，MediaPipeを用いて手のランドマークを検出し，可変長（5-90フレーム）の軌跡データを収集する．
収集した軌跡から18次元の動的特徴量を抽出し，学習済み深層学習モデルによって37クラス（a-z，0-9，スペース）の入力意図推定を行う．

\begin{figure}[tb]
\centering
%\includegraphics[width=\columnwidth]{system.png}
\fbox{システム構成図（作成予定）}
\caption{システム構成図}
\label{fig:system}
\end{figure}

%3.2
\subsection{4点キャリブレーションによる作業領域設定}

本システムでは，カメラの位置や角度，使用するキーボードの種類が異なっても安定して入力意図を推定するため，
カメラ映像内のピクセル座標と物理的なキーボード上のキー座標を統一する必要がある．
そのために，図\ref{fig:keyboard_mapping}に示す4点クリックによるキャリブレーション機能を実装した．

システム起動時，ユーザーはキーボードの四隅（1キー左上，-キー右上，スペースキー右下，スペースキー左下）を順にクリックする．
これらの4点からホモグラフィ変換行列を算出し，定義された四辺形を「作業領域」として，
この領域内を基準とした正規化座標系（左上を(0,0)，右下を(1,1)）を構築する．
以降，MediaPipeで検出した指先のピクセル座標は，すべてこの作業領域座標系に変換してから処理される．
このキャリブレーション機構により，多様な利用環境への柔軟な対応を可能としている．

\begin{figure}[tb]
\centering
%\includegraphics[width=\columnwidth]{keyboard_mapping.png}
\fbox{キーボードマッピングの例（作成予定）}
\caption{キーボードマッピングの例}
\label{fig:keyboard_mapping}
\end{figure}

%3.3
\subsection{手の軌跡データの取得}

前節で設定した作業領域座標系に基づき，ユーザーの手指の動きを時系列データとして取得する．
手のランドマーク検出には，Googleが開発したオープンソースのフレームワークであるMediaPipe Handsを利用し，
カメラ映像からリアルタイムに手の21個のランドマークポイントを検出する．
MediaPipeは軽量で処理速度が速く，一般的なWebカメラでも30fpsでの動作が可能であるため，リアルタイム入力支援に適している\cite{mediapipe}．

現在の実装では，入力操作に最も関与すると考えられる人差し指の先端（ランドマークポイント8）の座標を追跡対象とする．
検出した指先座標は作業領域座標系に変換し，さらに最近傍3キーへの相対位置と距離を計算する．
キーが押下された瞬間をトリガーとして，その直前の軌跡データをバッファに保持し，学習用サンプルとして保存する．

本システムでは可変長軌跡に対応しており，ユーザーの入力速度に応じて5フレーム（約0.17秒）から90フレーム（約3秒）までの範囲で
自動的に軌跡長が調整される．この可変長対応により，速い入力から遅い入力まで幅広く対応可能となっている．

%3.4
\subsection{動的特徴量の設計}

軌跡データから，深層学習モデルによる入力意図推定を高精度で行うために，18次元の動的特徴量を設計した．
本特徴量設計では，従来の静的な座標情報に加えて，手の動きの時間的変化と震え特性を包括的に捉えることで，
運動機能障害者特有の複雑な動作パターンからの意図抽出を可能とする．

18次元の特徴量は，
（1）作業領域内での指先の正規化座標（2次元），
（2）最近傍3キーへの相対座標（6次元），
（3）最近傍3キーへの距離（3次元），
（4）指先の速度および加速度（4次元），
（5）震えの特性を表す振幅と方向転換頻度（3次元）
から構成される．

特に震え特性の特徴量では，過去10フレームの座標変動から算出する「振幅」と，
速度ベクトルの符号変化頻度から算出する「方向転換頻度」により，個々のユーザーの震えパターンを定量化する．
これらの動的特徴量により，震え除去を行わずに生の軌跡データから直接学習することで，
重要な意図情報の損失を防ぎつつ，ロバストな入力意図推定を実現する．

%3.5
\subsection{深層学習モデルによる入力意図推定}

前節で設計した18次元の動的特徴量シーケンスから入力意図を推定するため，
時系列データのパターン学習に適した複数の深層学習モデルを実装した．
本研究では，LSTM，CNN，GRU，TCNの4種類のモデルを実装し，それぞれの特性を評価する．

\subsubsection{LSTMモデル}

従来型のアプローチとして，時系列データの長期依存関係を学習できるLSTMを採用した．
モデル構成は，入力層（18次元），LSTM層（2層，隠れ層128次元，ドロップアウト率0.2），
全結合層（128→64→37次元），出力層（37クラスのソフトマックス）である．

\subsubsection{CNNモデル}

可変長軌跡への対応が容易で，並列計算が可能なCNNモデルを実装した．
1次元畳み込み層を用いて時系列パターンを抽出し，Global Average Poolingにより可変長入力に対応する．
パラメータ数が最小（約167,653）で，学習速度が最も速いという利点がある．

\subsubsection{GRU・TCNモデル}

LSTMの代替として，より高速で省メモリなGRU，および最新の時系列モデルであるTCN（Temporal Convolutional Network）も実装した．
これらのモデルにより，精度と計算コストのトレードオフを評価する．


%4
\section{実装}

\subsection{開発環境}

本システムは以下の環境で開発した．

\begin{itemize}
\item OS: macOS / Windows
\item Python: 3.10
\item 主要ライブラリ: OpenCV, MediaPipe, PyTorch, scikit-learn
\item GPU: NVIDIA GeForce GTX 1660 Ti（学習時）
\end{itemize}

\subsection{データ収集}

学習データの収集には，データ収集専用のプログラム（\texttt{collect\_training\_data.py}）を実装した．
被験者は画面に表示される目標テキストに従ってキーボード入力を行い，
各キー押下時の指の軌跡データ（可変長，5-90フレーム）が自動的に記録される．

データ収集では，以下の多様なテキストパターンを使用した：

\begin{enumerate}
\item アルファベット全26文字を含むパングラム
\item 英語頻出単語群
\item 数字を含むランダムな文字列
\item 連続文字を含む単語
\end{enumerate}

最終的に約1,000サンプルのデータセットを構築し，訓練用60\%，検証用20\%，テスト用20\%に分割した．

\subsection{モデルの学習}

各モデルの学習には以下のパラメータを使用した：

\begin{itemize}
\item エポック数: 50-150
\item バッチサイズ: 32
\item 学習率: 0.001
\item 最適化手法: Adam
\item Early Stopping: 検証損失が5エポック改善しない場合に停止
\end{itemize}

データ拡張として，ガウシアンノイズの付加，時間軸の伸縮，人工的な震え（4-12Hz正弦波）の付加を実装した．


%5
\section{評価実験}

\subsection{実験概要}

提案システムの性能を評価するため，被験者（研究者本人）によるデータ収集と，
それを用いた深層学習モデルの学習・評価実験を実施した．
評価指標として，Top-1精度（第1候補の正解率），Top-3精度（第3候補までに正解が含まれる割合）を用いた．

\subsection{学習結果}

各モデルの学習結果を表\ref{tab:model_comparison}に示す．

\begin{table}[tb]
\caption{各モデルの性能比較}
\label{tab:model_comparison}
\centering
\begin{tabular}{lccc}\hline\hline
モデル & Top-1精度 & Top-3精度 & パラメータ数 \\\hline
LSTM & 86.9\% & 98.0\% & 218,533 \\
CNN & 85.2\% & 97.5\% & 167,653 \\
GRU & 86.1\% & 97.8\% & 166,565 \\
TCN & 85.8\% & 97.6\% & 207,909 \\\hline
\end{tabular}
\end{table}

LSTMモデルが最も高い精度を達成したが，CNNモデルも高速性とのトレードオフで優れた性能を示した．
図\ref{fig:learning_curves}に学習曲線を示す．

\begin{figure}[tb]
\centering
%\includegraphics[width=\columnwidth]{learning_curves.png}
\fbox{学習曲線（作成予定）}
\caption{モデルの学習曲線}
\label{fig:learning_curves}
\end{figure}

\subsection{データ多様化による性能改善}

初期モデルでは，学習データ上で高精度を達成した一方で，リアルタイム予測では性能が著しく低下するという課題が観測された．
この原因を学習データの偏りと分析し，意図的に多様なパターンを含むデータを追加収集した．

約1,000サンプルに拡充したデータセットでモデルを再学習させた結果，
検証データにおいて正解率86.9\%，Top-3正解率98.0\%という高水準を達成した．
さらに重要な成果として，この新モデルを用いた実環境でのリアルタイム予測では，
「通常速度の入力ではほぼ100\%」「意図的に手を揺らしながらの入力でも高い確率で正解が予測される」など，
体感性能が劇的に向上した．
これにより，データセットの多様化が，本システムの性能を実用レベルに引き上げる上で極めて有効であることが実験的に示された．

\subsection{リアルタイム予測システム}

学習済みモデルを用いたリアルタイム予測システムを実装した．
図\ref{fig:realtime_prediction}に示すように，ユーザーの手の動きをリアルタイムで追跡し，
Top-3の予測候補を確信度とともに画面に表示する．

\begin{figure}[tb]
\centering
%\includegraphics[width=\columnwidth]{realtime_prediction.png}
\fbox{リアルタイム予測画面（作成予定）}
\caption{リアルタイム予測システムの動作画面}
\label{fig:realtime_prediction}
\end{figure}


%6
\section{考察}

\subsection{モデルの比較}

4種類のモデルを比較した結果，LSTMが最も高い精度を達成した一方で，
CNNはパラメータ数が最小で学習速度が最も速いという利点があった．
実用化を考えると，リアルタイム性を重視する場合はCNN，精度を重視する場合はLSTMが適していると考えられる．

\subsection{可変長軌跡への対応}

固定長（60フレーム）から可変長（5-90フレーム）に対応したことで，
ユーザーの入力速度に柔軟に対応できるようになった．
特に，速い入力（15-30フレーム）でも高い精度で予測できることが確認された．

\subsection{データ多様化の効果}

学習データの多様化が，リアルタイム予測性能を劇的に改善させることが示された．
これは，特定のパターンへの過適合を防ぎ，汎化性能を向上させる上で極めて重要であることを示している．

\subsection{実用化に向けた課題}

本研究は健常者によるデータ収集に基づいており，実際の運動機能障害者による評価が今後の課題である．
また，個々のユーザーの障害特性に適応する個人化機能の実装も必要である．


%7
\section{おわりに}

本研究では，運動機能障害者のキーボード入力を支援するため，
カメラを用いた機械学習による入力意図推定システムを提案した．
4点キャリブレーション，MediaPipeによる手の軌跡データ収集，18次元動的特徴量の設計，
深層学習モデル（LSTM, CNN, GRU, TCN）による時系列学習という一連の処理により，
震えを含む軌跡から直接的な意図推定を実現した．

評価実験では，当初観測された学習結果と実使用環境の性能乖離という課題に対し，
学習データの多様化というアプローチで解決を図った．
その結果，検証データで86.9\%という高精度を達成し，リアルタイム予測においても実用レベルの性能向上を確認した．
これにより，追加のハードウェアを必要としない低コストな入力支援システムの実現可能性を実証した．

今後は，実際の運動機能障害者による評価実験，個人適応システムの開発を通じて，実用化に向けた研究を進める．



\begin{acknowledgment}
本研究を進めるにあたり，有益な助言をいただいた岩井研究室の皆様に深く感謝いたします．
\end{acknowledgment}



% 全引用を事前登録（BibTeX用）
\nocite{webaim2023motor,cerebralpalsy2023tobii,reciteme2025assistive,
cossovich2023co,abdallah2022light,le2023real,mallik2024virtual,
rahimadvanced,araujo2023analysis,wu2022visual,wolke2025validity,
yang2023learning,lei2022intention,pradeep2025real,gizatdinova2023vision,
neog2024hand,ottoboni2022multifunctional,lugaresi2019mediapipe,
zhang2020mediapipe,hochreiter1997long,cho2014learning,mackenzie2002text}

\bibliographystyle{ipsjunsrt}
\bibliography{references}




\end{document}


%%
%% 研究報告用スイッチ
%% [techrep]
%%
%% 欧文表記無しのスイッチ(etitle,eabstractは任意)
%% [noauthor]
%%

%\documentclass[submit,techrep]{ipsj}
\documentclass[submit,techrep,noauthor]{ipsj}



\usepackage[dvipdfmx]{graphicx}
\usepackage{latexsym}
\usepackage{url}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows.meta, positioning, calc}

\def\Underline{\setbox0\hbox\bgroup\let\\\endUnderline}
\def\endUnderline{\vphantom{y}\egroup\smash{\underline{\box0}}\\}
\def\|{\verb|}
%

%\setcounter{巻数}{59}%vol59=2018
%\setcounter{号数}{10}
%\setcounter{page}{1}


\begin{document}


\title{卓上カメラによる指先動作認識を用いた\\運動機能障害者のためのAIキーボード入力支援システム}

\etitle{AI Keyboard Input Assistance System for Individuals\\with Motor Disabilities Using Finger Motion Recognition via a Tabletop Camera}

\affiliate{TDU}{東京電機大学大学院 未来科学研究科 情報メディア学専攻\\
Information Systems and Multimedia Design, Graduate School of Science and Technology for Future Life, Tokyo Denki University}


\author{小高 大和}{Kodaka Yamato}{TDU}[kodak@cps.im.dendai.ac.jp]
\author{岩井 将行}{Iwai Masayuki}{TDU}

\begin{abstract}
運動機能障害者における手指の震えや不随意運動は，従来のキーボード入力を困難にし，デジタルアクセスの格差を生む要因となっている．
本研究では，汎用的な卓上USBカメラのみを用いて手指動作から入力意図を推定するシステムを提案する．
提案システムでは，MediaPipeによる手部ランドマーク検出を基盤とし，位置座標，速度，加速度，震えの振幅や方向転換頻度など18次元の動的特徴量を抽出することで運動特性を定量化した．
これらの特徴量を可変長に対応したGRUモデルに入力し，37クラスのキー入力意図を推定するアーキテクチャを構築した．
評価実験において，オフラインでTop-1精度98.0\%，リアルタイム環境で丁寧な入力時に91.9\%を達成した．
特に，震えを伴う入力では79.1\%で誤入力が発生したが，そのうち73.5\%で手指軌跡から正しい意図を推定でき，不随意運動下における入力補正の有効性が確認された．
本システムは追加ハードウェアを必要とせず，低コストで運動機能障害者のデジタルアクセシビリティ向上に貢献する．
\end{abstract}


%
%\begin{jkeyword}
%情報処理学会論文誌ジャーナル，\LaTeX，スタイルファイル，べからず集
%\end{jkeyword}
%
%\begin{eabstract}
%This document is a guide to prepare a draft for submitting to IPSJ
%Journal, and the final camera-ready manuscript of a paper to appear in
%IPSJ Journal, using {\LaTeX} and special style files.  Since this
%document itself is produced with the style files, it will help you to
%refer its source file which is distributed with the style files.
%\end{eabstract}
%
%\begin{ekeyword}
%IPSJ Journal, \LaTeX, style files, ``Dos and Dont's'' list
%\end{ekeyword}

\maketitle

%1
\section{はじめに}

パソコンやスマートフォンなどのデジタルデバイスは，
現代社会において情報アクセスやコミュニケーションに不可欠なツールとなっている．
しかし，脳性麻痺，本態性振戦，パーキンソン病などの神経疾患や加齢に伴う運動機能の低下により，手の震えや不随意運動を持つ人々にとって，キーボードによる正確な文字入力は困難であり，デジタル社会への参加を阻む障壁となる．

運動機能障害者向けの入力支援技術として，音声入力\cite{webaim2023motor}，視線入力\cite{cerebralpalsy2023tobii}，特殊キーボード\cite{reciteme2025assistive}などが開発されてきた．
しかし，音声入力は構音障害を伴う場合に利用できず，視線入力や特殊デバイスは高価で導入のハードルが高い．
また，これらの技術は個人の障害特性に合わせた調整が必要であり，手軽に利用を開始できないという課題がある．

そこで本研究では，汎用的な卓上カメラのみを用いて，手指の動きから入力意図を推定するシステムを提案する．
提案システムは，MediaPipe\cite{lugaresi2019mediapipe,zhang2020mediapipe}による手部ランドマーク検出を基盤とし，震えの特性を含む18次元の動的特徴量を抽出する．
これをGated Recurrent Unit（GRU）\cite{cho2014learning}モデルに入力し，震えを伴う軌跡からでも正しい入力意図を推定することで，追加ハードウェアなしに運動機能障害者のキーボード入力を支援する．


%2
\section{関連研究}

%2.1
\subsection{運動機能障害者向けの入力支援技術}

運動機能障害を持つ人々向けの入力支援技術としては，音声入力，視線入力，特殊ハードウェア，カメラベースの手認識などが開発されている．

音声入力はDragon NaturallySpeaking等に代表され広く普及しているが\cite{webaim2023motor}，脳性麻痺など構音障害を伴う場合には発話の明瞭度が低下するため正確な認識が困難となる．
視線入力ではTobii社がALSや脳性麻痺患者向けの視線追跡デバイスを開発しており\cite{cerebralpalsy2023tobii}，重度の運動障害者に有効な手段となっているが，デバイスが数十万円と高価であり，個人ごとのキャリブレーションにも専門的な調整を要する．
Gizatdinovaら\cite{gizatdinova2023vision}は視線入力とヘッド入力を比較評価し，ヘッド入力は高精度だが入力速度が遅く，視線入力は高速だが精度が劣るという特有の課題を報告している．
特殊ハードウェアとしては適応キーボードやマウススティック等があり\cite{reciteme2025assistive}，物理的なアクセシビリティを向上させるが，特定の姿勢や設置環境を前提とするため汎用性に欠ける．
Cossovichら\cite{cossovich2023co}は運動機能障害者へのインタビュー調査を通じて，多くのユーザーが大衆向けに設計された既存デバイスで我慢している現状を報告しており，より適切な入力支援技術の開発が求められている．

一方，カメラベースの手認識技術は追加ハードウェアなしに実現できる可能性がある．
Pradeepら\cite{pradeep2025real}はWebカメラによる顔追跡とニューラルネットワークを組み合わせたハンズフリーマウス制御システムを開発し，運動機能障害者が頭部の動きでマウスカーソルを操作できることを実証した．
また，Abdallahら\cite{abdallah2022light}はMediaPipe\cite{lugaresi2019mediapipe}とGRU/CNNを組み合わせた手話認識で99.84\%の精度を達成し，Leら\cite{le2023real}はYOLOv7による一人称視点からの手動作検出で95\%以上の精度を報告している．
キーボード入力への応用としては，Mallikら\cite{mallik2024virtual}がMediaPipe HolisticとLSTMにより仮想キーボードを実装し97\%の認識精度を達成，Rahimら\cite{rahimadvanced}は1D CNNとBi-GRUを組み合わせたCronoNetで多言語対応の仮想キーボードを開発した．
しかし，これらの研究は健常者の安定した動作を前提としており，震えや不随意運動を伴う入力への対応は考慮されていない．
運動機能障害者がこれらのシステムを利用するには，不規則な動作パターンからでも入力意図を推定できる手法が必要となる．

%2.2
\subsection{震え補正と運動意図推定}

運動機能障害に伴う震えの補正技術については，信号処理や機械学習を用いた研究が進められている．
Araújoら\cite{araujo2023analysis}は生理的振戦とパーキンソン病による病的振戦の両方に対してFx-LMSアルゴリズムを評価し，特に病的振戦に対して優れた補正性能を示した．
Wuら\cite{wu2022visual}はLeap Motionセンサーを用いたジェスチャー予測において，Kalmanフィルタによる震え補正とLSTM-RNNの組み合わせにより99.31\%の精度を達成している．
Wolkeら\cite{wolke2025validity}はMediaPipeを用いた振戦の定量的評価手法を提案し，スマートフォンカメラでも臨床的に有効な精度が得られることを示した．
Neogら\cite{neog2024hand}は3D手部ランドマーク検出を用いた手機能評価システムにより，仮想環境でのリハビリテーション効果を示した．
これらの研究では，震えを信号処理により除去または補正するアプローチが主流である．
また，震えを補正すべきノイズとして扱う研究が多く，震えを個人の特性として学習するアプローチは十分に検討されていない．

一方，時系列データからの運動意図推定では，Long Short-Term Memory（LSTM）\cite{hochreiter1997long}やGated Recurrent Unit（GRU）\cite{cho2014learning}などの再帰型ニューラルネットワークが広く用いられている．
Leiら\cite{lei2022intention}はロボット車椅子のナビゲーションにおいて意図予測ベースの共有制御システムを提案し，脳性麻痺患者において従来手法より約30\%タスク完了時間を短縮した．
Yangら\cite{yang2023learning}はRNNを用いて上肢の運動開始を予測し，支援ロボットの制御に応用した．
しかし，これらの意図推定研究は特殊センサーやロボットアームを前提としており，汎用カメラを用いたキーボード入力支援への適用例は見られない．

%2.3
\subsection{本研究の位置づけ}

前節までに述べたように，既存の入力支援技術には高コスト・専用機器の必要性・健常者を対象とした設計という課題がある．
カメラベースの手認識技術は低コストで実現可能だが，健常者の安定した動作を前提としている．
震え補正技術についても，震えをノイズとして除去するアプローチが主流だが，フィルタリングにより本来の入力意図に関する情報まで失われる可能性がある．

そこで本研究では，汎用カメラのみを用いて，運動機能障害者の震えを含む手指の軌跡から入力意図を推定するシステムを提案する．
震えを除去せず生の軌跡から深層学習モデルで直接学習することで，震えに含まれる動作特性も活用して入力意図を推定する．
これにより，追加ハードウェアなしに低コストで運動機能障害者のキーボード入力を支援する．


%3
\section{提案システム}

運動機能障害者のキーボード入力を支援するため，卓上カメラを用いた入力意図推定システムを提案する．
本システムは，手の不随意運動等がある場合でも，手指の軌跡からリアルタイムで入力意図を推定し，正確なキーボード入力を可能にする．
また，一般的なWebカメラのみで動作するため，追加ハードウェアなしに低コストで導入できる．

%3.1
\subsection{システム概要}

図\ref{fig:system}に示すように，提案システムは5つの処理ステップで構成される．
まず，4点キャリブレーションにより作業領域を設定する．
次に，MediaPipeを用いて手部ランドマークを検出し，人差し指先端の軌跡データを可変長（5-90フレーム）で取得する．
取得した軌跡から18次元の動的特徴量を抽出し，学習済みGRUモデルに入力して37クラス（a-z，0-9，スペース）の入力意図を推定する．
推定結果はTop-3候補とその確率をリアルタイムで画面に表示する．

\begin{figure}[tb]
\centering
    \begin{tikzpicture}[
        node distance=0.4cm,
        block/.style={
            rectangle,
            draw=black,
            line width=1pt,
            fill=gray!25,
            text width=4.2cm,
            text centered,
            minimum height=0.75cm,
            font=\sffamily\bfseries\small,
            rounded corners=1pt
        },
        process/.style={
            rectangle,
            draw=black,
            line width=1pt,
            fill=white,
            text width=4.2cm,
            text centered,
            minimum height=0.75cm,
            font=\sffamily\bfseries\small,
            rounded corners=1pt
        },
        arrow/.style={
            -Stealth,
            line width=1pt,
            black
        }
    ]
    
    % ノード配置
    \node[block] (camera) {カメラ入力};
    \node[process, below=of camera] (calib) {4点キャリブレーション};
    \node[process, below=of calib] (mediapipe) {手の軌跡データ収集};
    \node[process, below=of mediapipe] (feature) {18次元特徴量抽出};
    \node[block, below=of feature] (lstm) {GRU入力意図推定};
    \node[block, below=of lstm] (output) {リアルタイム予測表示};
    
    % 矢印
    \draw[arrow] (camera) -- (calib);
    \draw[arrow] (calib) -- (mediapipe);
    \draw[arrow] (mediapipe) -- (feature);
    \draw[arrow] (feature) -- (lstm);
    \draw[arrow] (lstm) -- (output);
    
    \end{tikzpicture}
    \caption{提案システムの処理フロー}
\label{fig:system}
\end{figure}

%3.2
\subsection{座標系の統一と正規化}

カメラの位置や角度，キーボードの種類はユーザーごとに異なる．
そのため，同じキーを指した場合でも画像上の座標は環境によって変化する．
本システムでは，この問題に対処するため，画像座標系とキーボード座標系を統一するキャリブレーションを行う．

システム起動時，ユーザーはキーボードの4隅（1キーの左上，ハイフンキーの右上，スペースキーの右上と左上）を順にクリックする（図\ref{fig:keyboard_mapping}）．
この4点から矩形領域を定義し，JIS配列テンプレートに基づいて各キーの位置を算出する．
キーボード領域は(0,0)から(1,1)の正規化座標系として定義され，以降，カメラ映像から検出される手指座標は，すべてこの正規化座標系に変換される．

\begin{figure}[tb]
\centering
\includegraphics[width=\columnwidth]{keyboard_mapping.png}
\caption{4点キャリブレーションによる座標系変換の例}
\label{fig:keyboard_mapping}
\end{figure}

%3.3
\subsection{MediaPipeによる手指軌跡の取得}

手のランドマーク検出には，Googleが開発したオープンソースのフレームワークであるMediaPipe\cite{lugaresi2019mediapipe}を使用する．
MediaPipeは軽量で処理速度が速く，一般的なWebカメラでも30fpsでの動作が可能であるため，リアルタイム入力支援に適している．

本システムでは，MediaPipe Hands\cite{zhang2020mediapipe}モジュールを利用して手のランドマーク検出を行う．
図\ref{fig:hand_landmarks}に示すように，このモジュールはカメラ映像から手の21個のランドマークをリアルタイムに検出する．
これらのランドマークのうち，入力操作に最も関与すると考えられる人差し指の先端（ランドマークポイント8）を追跡対象とし，その座標を前節で定義した正規化座標系に変換する．
変換された座標は毎フレーム記録され，キー押下時に直前5フレーム（約0.17秒）から90フレーム（約3秒）の指先軌跡を時系列データとして取得する．

\begin{figure}[tb]
\centering
\includegraphics[width=\columnwidth]{hand_landmarks.png}
\caption{MediaPipe Handsによる手のランドマーク検出（21点）}
\label{fig:hand_landmarks}
\end{figure}

%3.4
\subsection{震え特性を捉える18次元動的特徴量}

前節で取得した軌跡データから，深層学習モデルによる入力意図推定を高精度で行うために，18次元の動的特徴量を設計した．
本特徴量設計では，従来の静的な座標情報に加えて，手の動きの時間的変化と震え特性を包括的に捉えることで，
運動機能障害者特有の複雑な動作パターンからの意図抽出を可能とする．

表\ref{tab:feature_structure}に示すように，18次元の特徴量は，
（1）作業領域内での指先の正規化座標（2次元），
（2）最近傍3キーへの相対座標（6次元），
（3）最近傍3キーへの距離（3次元），
（4）指先の速度および加速度（4次元），
（5）震えの特性を表す振幅と方向転換頻度（3次元）
から構成される．

特に震え特性の特徴量では，過去10フレームの座標変動から算出する「振幅」と，
速度ベクトルの符号変化頻度から算出する「方向転換頻度」により，個々のユーザーの震えパターンを定量化する．
これらの動的特徴量により，震え除去を行わずに生の軌跡データから直接学習することで，
重要な意図情報の損失を防ぎつつ，ロバストな入力意図推定を実現する．

\begin{table}[tb]
    \caption{18次元動的特徴量の構成}
    \label{tab:feature_structure}
    \centering
    \begin{tabular}{lc}\hline\hline
    特徴量カテゴリ & 次元数 \\\hline
    指先の正規化座標 & 2 \\
    最近傍3キーへの相対座標 & 6 \\
    最近傍3キーへの距離 & 3 \\
    速度・加速度 & 4 \\
    振幅・方向転換頻度 & 3 \\
    \hline
    合計 & 18 \\\hline
\end{tabular}
\end{table}

%3.5
\subsection{GRUモデルによる入力意図推定}

前節で設計した18次元の動的特徴量シーケンスから入力意図を推定するため，
本研究ではGRU\cite{cho2014learning}を採用した．
指先の軌跡は時間的に連続した動きであり，
震えを含む複雑な動作パターンから入力意図を推定するには時間的文脈を学習できるモデルが必要である．
そこで，代表的な時系列モデルである
Long Short-Term Memory（LSTM）\cite{hochreiter1997long}，
1次元畳み込みニューラルネットワーク（CNN），
Gated Recurrent Unit（GRU），
Temporal Convolutional Network（TCN）\cite{bai2018empirical}の
4種類を比較した結果，GRUが最も優れた性能を示した（4.2節）．

GRUはLSTMと同等の長期依存関係学習能力を持ちながら
パラメータ数が約24\%少なく学習・推論ともに高速であるため，
実用的なリアルタイム処理が可能である．

採用したGRUの構成は，
入力層（18次元），
GRU層（2層，隠れ層128次元，ドロップアウト率0.2），
全結合層（128→64→37次元），
出力層（37クラスのソフトマックス）である．



%4
\section{評価実験}

\subsection{実験設定}

\subsubsection{学習用データの収集}

提案モデルの学習用データとして，
多様な文字パターンを含むキーボード軌跡データを収集した．
図\ref{fig:data_collection_setup}に示す実験環境において，
a-z，0-9，スペースの37種類の文字を均等に含み
ランダムな順序で構成した文字列（10種類，各95文字）を目標テキストとし，
研究者本人が各文字列を5回ずつ入力することで，
合計4,750サンプル（10種類×5回×95文字）のデータセットを構築した．

各キー入力時の指先軌跡は可変長（5フレーム〜90フレーム）で記録した．
これは，キー押下直前の軌跡長が入力速度によって異なるためであり，
速い入力から遅い入力まで柔軟に対応できる．
図\ref{fig:trajectory_distribution}に軌跡長の分布を示す．
データセット全体で多様な入力速度が含まれていることが確認できる．

収集したデータセットは，
訓練用（60\%，2,850サンプル），
検証用（20\%，950サンプル），
テスト用（20\%，950サンプル）に分割した．

\begin{figure}[tb]
\centering
\includegraphics[width=\columnwidth]{data_collection_setup.png}
\caption{データ収集の実験環境}
\label{fig:data_collection_setup}
\end{figure}

\begin{figure}[tb]
\centering
\fbox{trajectory length distribution.png}
\caption{可変長軌跡データの分布}
\label{fig:trajectory_distribution}
\end{figure}

\subsubsection{学習条件}

各モデルの学習には以下のパラメータを使用した：

\begin{itemize}
\item エポック数: 100
\item バッチサイズ: 32
\item 学習率: 0.001
\item 最適化手法: Adam
\item 損失関数: Cross Entropy Loss（クラス重み付き）
\item 学習率スケジューラ: ReduceLROnPlateau（factor=0.5, patience=3）
\item Early Stopping（patience=5）
\end{itemize}

\subsubsection{評価指標}

本研究では，システムの性能を多角的に評価するため，
以下の評価指標を用いた．

\textbf{オフライン評価:}
学習済みモデルをテストセット（950サンプル）で評価し，
以下の指標を測定した．

\begin{itemize}
\item Top-1精度: 第1候補が正解である割合
\item Top-3精度: 第3候補までに正解が含まれる割合
\end{itemize}

\textbf{リアルタイム評価:}
実際のキーボード入力時のシステム性能を評価するため，
被験者が実際に文字列を入力し，
以下の指標を測定した\cite{mackenzie2002text}．

\begin{itemize}
\item Top-1精度: 第1候補が正解である割合
\item Top-3精度: 第3候補までに正解が含まれる割合
\item WPM (Words Per Minute): 1分あたりの入力単語数
\item 平均入力時間: 1文字あたりの平均入力時間
\item エラー率: 第1候補が不正解である割合
\item 救済率: ユーザーが誤ったキーを押下した場合に，
  システムが正しい文字を推定できた割合
\end{itemize}

\subsection{モデル比較実験}

入力意図推定に適した時系列モデルを選定するため，
4種類の深層学習モデル（LSTM，CNN，GRU，TCN）を比較評価した．
各モデルを4.1.1で構築した訓練データで学習させ，
テストセット（950サンプル）によるオフライン評価と
実際のキーボード入力によるリアルタイム評価を実施し，
実環境での性能を検証した．

まず，テストセットを用いたオフライン評価を行い，
各モデルの基本的な認識性能を測定した．
図\ref{fig:learning_curves}にGRUモデルの学習曲線を示す．
訓練損失と検証損失が安定して収束しており，
過学習を起こさず適切に学習できていることが確認できる．
表\ref{tab:offline_performance}に示すように，
GRUがTop-1精度98.0\%と最も高い性能を達成した．
また，GRUはパラメータ数が約167Kと4モデル中最小であり，
モデルの計算コストが低いため学習時間が短く，
リアルタイム推論においても高速に動作する．
詳細な認識パターンを確認するため，
図\ref{fig:confusion_matrix}にGRUモデルの混同行列を示す．
対角成分が高く，ほとんどのクラスで高い認識精度を達成している．
一部の隣接キー（d-f、o-0など）間で誤認識が見られるものの，
全体として優れた識別性能を示した．

\begin{table}[tb]
\caption{モデル別オフライン性能評価}
\label{tab:offline_performance}
\centering
\begin{tabular}{lccc}\hline\hline
モデル & パラメータ数 & Top-1精度 & Top-3精度 \\\hline
LSTM & 約219K & 97.47\% & 99.89\% \\
CNN & 約169K & 93.58\% & 99.47\% \\
GRU & 約167K & \textbf{98.00\%} & \textbf{99.89\%} \\
TCN & 約209K & 94.21\% & 99.47\% \\\hline
\end{tabular}
\end{table}

\begin{figure}[tb]
\centering
\includegraphics[width=\columnwidth]{confusion_matrix.png}
\caption{GRUモデルの混同行列（テストセット）}
\label{fig:confusion_matrix}
\end{figure}

\begin{figure}[tb]
\centering
\includegraphics[width=\linewidth]{learning_curves.png}
\caption{GRUモデルの学習曲線}
\label{fig:learning_curves}
\end{figure}

次に，実環境での性能を検証するため，
被験者が「hello world」を実際に入力するリアルタイム評価を行った．
図\ref{fig:realtime_prediction}に実際のリアルタイム予測画面を示す．
システムは各キー入力に対してTop-3候補を確率とともに提示し，
ユーザーは第1候補が誤っている場合でも候補から選択できる仕組みとなっている．
表\ref{tab:realtime_performance}に示すように，
GRUがTop-1精度81.8\%，Top-3精度100.0\%と最も優れた性能を示した．
オフライン評価と比較してTop-1精度は約16ポイント低下したが，
Top-3精度が100\%であることから，
正解が常に上位3候補に含まれており，
候補提示による入力支援が有効に機能することが確認された．
この結果に基づき，入力意図推定モデルとしてGRUを採用した（3.5節）．

\begin{table}[tb]
\caption{モデル別リアルタイム性能評価}
\label{tab:realtime_performance}
\centering
\begin{tabular}{lccc}\hline\hline
モデル & Top-1精度 & Top-3精度 & WPM \\\hline
LSTM & 72.7\% & 81.8\% & 71.0 \\
CNN & 45.5\% & 54.5\% & 61.6 \\
GRU & \textbf{81.8\%} & \textbf{100.0\%} & \textbf{69.9} \\
TCN & 36.4\% & 45.5\% & 48.5 \\\hline
\end{tabular}
\end{table}

\begin{figure}[tb]
\centering
\fbox{realtime prediction screen.png}
\caption{リアルタイム予測画面の例（GRUモデル）}
\label{fig:realtime_prediction}
\end{figure}

\subsection{実用性評価}

選定したGRUモデルの実環境での実用性を検証するため，
健常者○名を対象に実用性評価実験を実施した．
評価には，言語モデルによる予測効果を排除するため，
37種類の全文字が均等に含まれるランダム文字列を入力テキストとして用いることで，
純粋なシステムの性能を測定した．
また，異なる入力状況下での性能を検証するため，
丁寧入力，通常入力，摂動負荷入力の3種類の入力スタイルを設定した．
丁寧入力では，被験者にゆっくり正確な入力を求めることで，
システムが達成可能な性能上限を確認した．
通常入力では，日常的な入力速度を想定した標準的な入力を行わせることで，
実用的な環境下での性能を評価した．
摂動負荷入力では，
図\ref{fig:perturbation_setup}に示すように，
被験者の手首に紐を取り付けキー押下直前に引っ張ることで物理的な摂動を加え，
不随意運動による入力の揺らぎを模擬した条件下でのシステムの頑健性を検証した．

\begin{figure}[tb]
\centering
\fbox{perturbation setup.png}
\caption{摂動負荷入力の実験セットアップ}
\label{fig:perturbation_setup}
\end{figure}

表\ref{tab:usability}に被験者○名の平均性能を示す．
丁寧入力ではTop-1精度○○\%と高い精度を達成した．
通常入力ではTop-1精度○○\%を維持し，実用的な速度での入力が可能であった．
摂動負荷入力ではTop-1精度が○○\%に低下したものの，
Top-3精度は○○\%を維持し，
誤入力時の救済率は○○\%を示した．
この救済率は，ユーザーが誤ったキーを押下した場合でも，
システムが高い確率で正しい入力意図を推定できることを示している．

\begin{table}[tb]
\caption{入力スタイル別性能評価（被験者○名の平均）}
\label{tab:usability}
\centering
\small
\begin{tabular}{lcccc}\hline\hline
入力スタイル & Top-1 & Top-3 & 時間 & WPM \\\hline
丁寧入力 & 91.9\% & 100.0\% & 2.2秒 & 27.2 \\
通常入力 & 81.1\% & 100.0\% & 1.4秒 & 44.0 \\
摂動負荷入力 & 76.7\% & 93.0\% & 1.7秒 & 34.5 \\
\hline
\multicolumn{5}{l}{\small 摂動負荷入力時の救済率: 73.5\%} \\
\hline
\end{tabular}
\end{table}

以上の評価実験により，
提案システムが異なる入力状況下においても実用的な性能を持つことが確認された．
特に，摂動負荷条件下においても高い救済率を達成したことから，
運動機能障害者のキーボード入力を支援する有効な手段となり得ることが示された．


%5
\section{考察}

\subsection{モデル選択の妥当性}

4.2節のモデル比較実験では，LSTM，CNN，GRU，TCNの4種類を評価した結果，
GRUがオフライン精度98.0\%，リアルタイム精度81.8\%と最も優れた性能を示した．
LSTMもオフライン精度97.5\%と高精度を達成したが，
パラメータ数がGRUの約1.3倍（219K vs 167K）であり，
学習時間およびリアルタイム推論速度の面でGRUが優位であった．
CNNとTCNはオフライン精度がそれぞれ93.6\%，94.2\%にとどまり，
特にリアルタイム評価ではCNN 45.5\%，TCN 36.4\%と大幅に性能が低下した．
これは，畳み込み層による局所的な特徴抽出が，
可変長の時系列パターン全体を捉える上で不十分であったためと考えられる．

GRUの優位性は，
入力ゲートと忘却ゲートを統合した更新ゲートにより，
LSTMよりも少ないパラメータで効率的に時系列依存関係を学習できる点にある．
本研究のような可変長（5-90フレーム）の手指軌跡データに対しては，
この特性が特に有効に働いたと考えられる．

\subsection{実用性評価の考察}

4.3節の実用性評価では，
丁寧入力，通常入力，摂動負荷入力の3種類の入力スタイルで評価を実施した．
丁寧入力でTop-1精度○○\%を達成したことから，
システムの理論的な性能上限が十分に高いことが確認された．
通常入力でTop-1精度○○\%を維持できたことは，
実用的な入力速度においてもシステムが有効に機能することを示している．

特筆すべきは，摂動負荷入力における救済効果である．
物理的な摂動により意図的に入力の揺らぎを発生させた条件下では，
Top-1精度が○○\%に低下したものの，
Top-3精度は○○\%を維持し，
誤入力時の救済率は○○\%を達成した．
この救済率は，ユーザーが押下したキーと入力意図が異なる場合でも，
システムが上位3候補の中に正解を含められる確率が高いことを意味する．
運動機能障害者の支援においては，
この「候補提示による救済機能」が入力効率を大幅に改善する可能性がある．

また，3種類の入力スタイル間でTop-3精度がTop-1精度に比べて相対的に高い値を維持していることから，
提案システムの候補推定機能が頑健であることが示された．

\subsection{特徴量重要度分析}

提案システムで設計した18次元の動的特徴量について，
Permutation Importanceによる重要度分析を実施した．
図\ref{fig:importance}にその結果を示す．
分析の結果，指先の絶対座標（finger\_x: 0.507）と
水平方向速度（vel\_x: 0.505）が圧倒的に高い重要度を示した．
これは，キー入力意図の推定において，
指先の水平方向の位置と動きが最も重要な情報源であることを示している．

次いで重要度が高かったのは，
垂直方向速度（vel\_y: 0.242），最近傍キー2への相対位置（rel\_key2\_y: 0.191），
最近傍キー1への相対位置（rel\_key1\_x: 0.177）であった．
一方，加速度（acc\_x, acc\_y），振幅（amplitude\_x, amplitude\_y），
方向変化（direction\_change）の重要度はほぼゼロまたは負の値を示し，
入力意図推定への寄与が極めて小さいことが明らかになった．

この結果は，手指の「位置」と「速度」が入力意図推定の主要な情報であり，
「加速度」や「揺れの振幅」といった高次の動的特徴は必ずしも必要ではないことを示唆している．
ただし，これは健常者による学習データに基づく分析であり，
実際の運動機能障害者のデータでは異なる傾向を示す可能性がある．
特に，不随意運動の特性を捉えるためには，
振幅や方向変化といった特徴が重要になる可能性も考えられる．

\begin{figure}[tb]
\centering
\includegraphics[width=\linewidth]{importance.png}
\caption{特徴量重要度分析結果（Permutation Importance）}
\label{fig:importance}
\end{figure}

\subsection{システムの限界と今後の課題}

本研究にはいくつかの限界がある．
第一に，学習データおよび評価実験が健常者のみを対象としている点である．
実際の運動機能障害者の手指軌跡は，
不随意運動の種類や程度が個人によって大きく異なるため，
本研究で得られた性能が直接適用できるとは限らない．
今後，倫理審査を経た上で実際の障害者を対象とした評価実験を実施し，
システムの実用性を検証する必要がある．

第二に，個人化機能の欠如である．
現状のシステムは単一の学習済みモデルを全ユーザーで共有しているが，
個々のユーザーの入力特性に適応する個人化機能を実装することで，
さらなる精度向上が期待できる．
特に，少量の個人データを用いた転移学習やオンライン学習の導入が有効と考えられる．

第三に，長文入力における評価が不十分である点である．
本研究ではランダム文字列を用いた評価を中心に実施したが，
実用場面では文脈を持つ長文の入力が必要となる．
今後，言語モデルとの統合により，
文脈情報を活用した入力支援の実現が課題となる．


%6
\section{おわりに}

本研究では，運動機能障害者のキーボード入力を支援するため，
カメラを用いた機械学習による入力意図推定システムを提案した．
提案システムは，4点キャリブレーションによる座標変換，
MediaPipeによる手指軌跡の取得，
18次元動的特徴量の設計，
GRUモデルによる可変長時系列学習により，
不随意運動を伴う手指軌跡から入力意図を推定する．

モデル比較実験では，LSTM，CNN，GRU，TCNの4種類を評価し，
GRUがオフライン精度98.0\%，リアルタイム精度81.8\%と最も優れた性能を示した．
実用性評価では，3種類の入力スタイル（丁寧入力，通常入力，摂動負荷入力）で評価を実施し，
摂動負荷条件下においても誤入力時の救済率○○\%を達成した．
これは，ユーザーが誤ったキーを押下した場合でも，
システムが提示する上位3候補に正解が含まれることを示しており，
運動機能障害者の入力効率を大幅に改善する可能性を示している．

また，特徴量重要度分析により，
指先の位置と速度が入力意図推定の主要な情報源であることが明らかになった．
これらの結果から，一般的なWebカメラのみで実現可能な
低コストな入力支援システムの有効性が示された．

今後の課題として，実際の運動機能障害者を対象とした評価実験の実施，
個々のユーザーの障害特性に適応する個人化機能の開発，
言語モデルとの統合による長文入力支援の実現が挙げられる．



\begin{acknowledgment}
本研究を進めるにあたり，有益な助言をいただいた岩井研究室の皆様に深く感謝いたします．
\end{acknowledgment}



% BibTeX使用（本文中の\citeで自動的に参照リストに追加される）

\bibliographystyle{ipsjunsrt}
\bibliography{references}




\end{document}

